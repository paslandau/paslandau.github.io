<?xml version = "1.0" encoding = "UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>pascallandau.com [codeproject]</title>
        <description>Pascal Landau's Blog - Development related posts only</description>
        <link>https://www.pascallandau.com</link>
        <atom:link href="https://www.pascallandau.com/feed-codeproject-com.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Sun, 01 May 2022 15:53:38 +0000</pubDate>
        <lastBuildDate>Sun, 01 May 2022 15:53:38 +0000</lastBuildDate>
        <language>en</language>
        <category>CodeProject</category>
                    <item>
                <title>CI Pipelines for dockerized PHP Apps with Github &amp; Gitlab [Tutorial Part 7]</title>
                <description><![CDATA[<p>In the seventh part of this tutorial series on developing PHP on Docker we will <strong>setup a CI
(Continuous Integration) pipeline to run code quality tools and tests on Github Actions and Gitlab
Pipelines</strong>.</p>
<div class="center-div">
<iframe width="560" height="315" src="https://www.youtube.com/embed/aGWGJQWtH1I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<p>All code samples are publicly available in my
<a href="https://github.com/paslandau/docker-php-tutorial">Docker PHP Tutorial repository on github</a>.<br />
You find the branch for this tutorial at
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-7-ci-pipeline-docker-php-gitlab-github">part-7-ci-pipeline-docker-php-gitlab-github</a>.</p>
<!-- generated -->
<p><a id='published-parts-of-the-docker-php-tutorial'> </a></p>
<!-- /generated -->
<h2>Published parts of the Docker PHP Tutorial</h2>
<ul>
<li><a href="/blog/php-php-fpm-and-nginx-on-docker-in-windows-10/">Setting up PHP, PHP-FPM and NGINX for local development on Docker</a>
(2018-07-08)</li>
<li><a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
(2018-08-06)</li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
(2019-05-20)</li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
(2022-03-21)</li>
<li><a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>
(2022-03-22)</li>
<li><a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>
(2022-03-23)</li>
<li><a href="/blog/php-qa-tools-make-docker/">Set up PHP QA tools and control them via make</a>
(2022-04-25)</li>
<li><a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
(2022-04-25)</li>
<li><a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
(2022-04-25)</li>
</ul>
<p>If you want to follow along, please subscribe to the <a href="/feed.xml">RSS feed</a>
or <a href="#newsletter">via email</a>
to get automatic notifications when the next part comes out :)</p>
<!-- generated -->
<p><a id='table-of-contents'> </a></p>
<!-- /generated -->
<h2>Table of contents</h2>
<!-- toc -->
<ul>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#recommended-reading">Recommended reading</a></li>
<li><a href="#approach">Approach</a></li>
<li><a href="#try-it-yourself">Try it yourself</a></li>
</ul></li>
<li><a href="#ci-setup">CI setup</a>
<ul>
<li><a href="#general-ci-notes">General CI notes</a>
<ul>
<li><a href="#initialize-make-for-ci">Initialize <code>make</code> for CI</a></li>
<li><a href="#wait-for-service-sh">wait-for-service.sh</a></li>
</ul></li>
<li><a href="#setup-for-a-local-ci-run">Setup for a &quot;local&quot; CI run</a>
<ul>
<li><a href="#run-details">Run details</a></li>
<li><a href="#execution-example">Execution example</a></li>
</ul></li>
<li><a href="#setup-for-github-actions">Setup for Github Actions</a>
<ul>
<li><a href="#the-workflow-file">The Workflow file</a></li>
</ul></li>
<li><a href="#setup-for-gitlab-pipelines">Setup for Gitlab Pipelines</a>
<ul>
<li><a href="#the-gitlab-ci-yml-pipeline-file">The <code>.gitlab-ci.yml</code> pipeline file</a></li>
<li><a href="#performance">Performance</a>
<ul>
<li><a href="#the-caching-problem-on-ci">The caching problem on CI</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#docker-changes">Docker changes</a>
<ul>
<li><a href="#compose-file-updates">Compose file updates</a>
<ul>
<li><a href="#adding-a-health-check-for-mysql">Adding a health check for <code>mysql</code></a></li>
</ul></li>
<li><a href="#build-target-ci">Build target: <code>ci</code></a>
<ul>
<li><a href="#build-stage-ci-in-the-php-base-image">Build stage <code>ci</code> in the <code>php-base</code> image</a>
<ul>
<li><a href="#use-the-whole-codebase-as-build-context">Use the whole codebase as build context</a></li>
<li><a href="#build-the-dependencies">Build the dependencies</a></li>
<li><a href="#create-the-final-image">Create the final image</a></li>
</ul></li>
<li><a href="#build-stage-ci-in-the-application-image">Build stage <code>ci</code> in the <code>application</code> image</a></li>
</ul></li>
<li><a href="#dockerignore">.dockerignore</a></li>
</ul></li>
<li><a href="#makefile-changes">Makefile changes</a>
<ul>
<li><a href="#initialize-the-shared-variables">Initialize the shared variables</a></li>
<li><a href="#env-based-docker-compose-config">ENV based docker compose config</a></li>
</ul></li>
<li><a href="#codebase-changes">Codebase changes</a>
<ul>
<li><a href="#add-a-test-for-encrypted-files">Add a test for encrypted files</a></li>
<li><a href="#add-a-password-protected-secret-gpg-key">Add a password-protected secret <code>gpg</code> key</a></li>
<li><a href="#create-a-junit-report-from-phpunit">Create a JUnit report from PhpUnit</a></li>
</ul></li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
<!-- /toc -->
<!-- generated -->
<p><a id='introduction'> </a></p>
<!-- /generated -->
<h2>Introduction</h2>
<p>CI is short for <strong>C</strong>ontinuous <strong>I</strong>ntegration and to me mostly means <strong>running the code quality
tools and tests of a codebase in an isolated environment</strong> (preferably automatically). This is<br />
particularly important when working in a team, because <strong>the CI system acts as the final
gatekeeper</strong> before features or bugfixes are merged into the main branch.</p>
<p>I initially learned about CI systems when I stubbed my toes into the open source water. Back in the
day I used <a href="https://travis-ci.org/">Travis CI</a> for my own projects and replaced it
with <a href="https://github.com/features/actions">Github Actions</a> at some point. At ABOUT YOU we started
out with a self-hosted <a href="https://www.jenkins.io/">Jenkins</a> server and then moved on to
<a href="https://about.gitlab.com/stages-devops-lifecycle/continuous-integration/">Gitlab CI</a> as a fully
managed solution (though we use <a href="https://docs.gitlab.com/runner/">custom runners</a>).</p>
<!-- generated -->
<p><a id='recommended-reading'> </a></p>
<!-- /generated -->
<h3>Recommended reading</h3>
<p>This tutorial builds on top of the previous parts. I'll do my best to cross-reference the
corresponding articles when necessary, but I would still recommend to do some upfront reading on:</p>
<ul>
<li>the <a href="/blog/structuring-the-docker-setup-for-php-projects/#structuring-the-repository">general folder structure</a>, the
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#docker">update of the <code>.docker/</code> directory</a> and the introduction of a
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#make-mk-includes"><code>.make/</code> directory</a></li>
<li>the <a href="/blog/structuring-the-docker-setup-for-php-projects/#makefile-and-bashrc">general usage of <code>make</code></a>
and <a href="/blog/docker-from-scratch-for-php-applications-in-2022/#makefile">it's evolution</a> as well as
the <a href="/blog/docker-from-scratch-for-php-applications-in-2022/#make-docker-3">connection to <code>docker compose</code> commands</a></li>
<li>the concepts of the <a href="/blog/docker-from-scratch-for-php-applications-in-2022/#docker">docker containers and the <code>docker compose</code> setup</a></li>
</ul>
<p>And as a nice-to-know:</p>
<ul>
<li>the setup of <a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/#install-phpunit">PhpUnit for the <code>test</code> make target</a> as well as the
<a href="/blog/php-qa-tools-make-docker/#qa-make-targets"><code>qa</code> make target</a></li>
<li>the <a href="/blog/git-secret-encrypt-repository-docker/">usage of <code>git-secret</code> to handle secret values</a></li>
</ul>
<!-- generated -->
<p><a id='approach'> </a></p>
<!-- /generated -->
<h3>Approach</h3>
<p>In this tutorial I'm going to explain <strong>how to make our existing docker setup work with Github Actions
and <a href="https://docs.gitlab.com/ee/ci/pipelines/">Gitlab CI/CD Pipelines</a></strong>. As I'm a big fan of a
&quot;progressive enhancement&quot; approach, we will ensure that <strong>all necessary steps can be performed
locally through <code>make</code></strong>. This has the additional benefit of keeping a single source of truth (the
<code>Makefile</code>) which will come in handy when we set up the CI system on two different providers
(Github and Gitlab).</p>
<p>The general process will look very similar to the one for local development:</p>
<ul>
<li>build the docker setup</li>
<li>start the docker setup</li>
<li>run the qa tools</li>
<li>run the tests</li>
</ul>
<p>You can see the final results in the <a href="#ci-setup">CI setup</a> section, including the concrete <code>yml</code>
files and links to the repositories, see</p>
<ul>
<li><a href="#setup-for-a-local-ci-run">Setup for a &quot;local&quot; CI run</a></li>
<li><a href="#setup-for-github-actions">Setup for Github Actions</a></li>
<li><a href="#setup-for-gitlab-pipelines">Setup for Gitlab Pipelines</a></li>
</ul>
<p>On a code level, we will <strong>treat CI as an environment</strong>, configured through the env variable <code>ENV</code>. So
far we only used <code>ENV=local</code> and we will extend that to also use <code>ENV=ci</code>. The necessary changes
are explained after the concrete CI setup instructions in the sections</p>
<ul>
<li><a href="#docker-changes">Docker changes</a></li>
<li><a href="#makefile-changes">Makefile changes</a></li>
<li><a href="#codebase-changes">Codebase changes</a></li>
</ul>
<!-- generated -->
<p><a id='try-it-yourself'> </a></p>
<!-- /generated -->
<h3>Try it yourself</h3>
<p>To get a feeling for what's going on, you can start by
<a href="#setup-for-a-local-ci-run">executing the local CI run</a>: </p>
<ul>
<li>checkout branch
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-7-ci-pipeline-docker-php-gitlab-github">part-7-ci-pipeline-docker-php-gitlab-github</a></li>
<li>initialize <code>make</code></li>
<li>run the <code>.local-ci.sh</code> script </li>
</ul>
<p>This should give you a similar output as presented in the <a href="#execution-example">Execution example</a>.</p>
<pre><code class="language-bash">git checkout part-7-ci-pipeline-docker-php-gitlab-github

# Initialize make
make make-init

# Execute the local CI run
bash .local-ci.sh</code></pre>
<!-- generated -->
<p><a id='ci-setup'> </a></p>
<!-- /generated -->
<h2>CI setup</h2>
<!-- generated -->
<p><a id='general-ci-notes'> </a></p>
<!-- /generated -->
<h3>General CI notes</h3>
<!-- generated -->
<p><a id='initialize-make-for-ci'> </a></p>
<!-- /generated -->
<h4>Initialize <code>make</code> for CI</h4>
<p>As a very first step we need to &quot;configure&quot; the codebase to operate for the <code>ci</code> environment.
This is done through the <code>make-init</code> target as explained later in more detail in the
<a href="#makefile-changes">Makefile changes</a> section via</p>
<pre><code class="language-bash">make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=12345678"</code></pre>
<pre><code class="language-text">$ make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=12345678"
Created a local .make/.env file</code></pre>
<p><code>ENV=ci</code> ensures that we</p>
<ul>
<li>use <a href="#env-based-docker-compose-config">the correct <code>docker compose</code> config files</a></li>
<li>use <a href="#build-target-ci">the <code>ci</code> build target</a></li>
</ul>
<p><code>TAG=latest</code> is just a simplification for now because we don't do anything with the images yet.
In an upcoming tutorial we will push them to a container registry for later usage in production
deployments and then set the <code>TAG</code> to something more meaningful (like the build number).</p>
<p><code>EXECUTE_IN_CONTAINER=true</code> forces every <code>make</code> command that uses a
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#run-commands-in-the-docker-containers"><code>RUN_IN_*_CONTAINER</code> setup</a>
to run in a container. This is important, because <strong>the Gitlab runner will actually run in a
docker container itself</strong>. However, this would cause any affected target <strong>to omit the
<code>$(DOCKER_COMPOSER) exec</code> prefix</strong>.</p>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/execute-always-in-docker.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/execute-always-in-docker.PNG" alt="Execute all targets in the application docker container" /></a></p>
<p><code>GPG_PASSWORD=12345678</code> is the password for the secret <code>gpg</code> key as mentioned in
<a href="#add-a-password-protected-secret-gpg-key">Add a password-protected secret <code>gpg</code> key</a>.</p>
<!-- generated -->
<p><a id='wait-for-service-sh'> </a></p>
<!-- /generated -->
<h4>wait-for-service.sh</h4>
<p>I'll explain the &quot;container is up and running but the underlying service is not&quot; problem
for the <code>mysql</code> service and how we can solve it with a health check later in this article at
<a href="#adding-a-health-check-for-mysql">Adding a health check for <code>mysql</code></a>.
On purpose, we don't want <code>docker compose</code> to take care of the waiting because we can make
&quot;better use of the waiting time&quot; and will instead implement it ourselves with a simple bash
script located at <code>.docker/scripts/wait-for-service.sh</code>:</p>
<pre><code class="language-bash">#!/bin/bash

name=$1
max=$2
interval=$3

[ -z "$1" ] &amp;&amp; echo "Usage example: bash wait-for-service.sh mysql 5 1"
[ -z "$2" ] &amp;&amp; max=30
[ -z "$3" ] &amp;&amp; interval=1

echo "Waiting for service '$name' to become healthy, checking every $interval second(s) for max. $max times"

while true; do 
  ((i++))
  echo "[$i/$max] ..."; 
  status=$(docker inspect --format "{{json .State.Health.Status }}" "$(docker ps --filter name="$name" -q)")
  if echo "$status" | grep -q '"healthy"'; then 
   echo "SUCCESS";
   break
  fi
  if [ $i == $max ]; then 
    echo "FAIL"; 
    exit 1
  fi 
  sleep $interval; 
done</code></pre>
<p>This script waits for a docker <code>$service</code> to become &quot;healthy&quot; by
<a href="https://stackoverflow.com/a/42738182/413531">checking the <code>.State.Health.Status</code> info</a>
of the <code>docker inspect</code> command.</p>
<p><strong>CAUTION:</strong> The script uses <code>$(docker ps --filter name="$name" -q)</code> to determine the id of the
container, i.e. it will &quot;match&quot; all running containers against the <code>$name</code> - this would fail if
there is more than one matching container! I.e. you must ensure that <code>$name</code> is specific
enough to identify one single container uniquely.</p>
<p>The script will check up to <code>$max</code> times
in a interval of <code>$interval</code> seconds. See <a href="https://unix.stackexchange.com/a/82610">these</a>
<a href="https://unix.stackexchange.com/a/137639">answers</a> on the
&quot;How do I write a retry logic in script to keep retrying to run it up to 5 times?&quot; question for
the implementation of the retry logic. To check the health of the <code>mysql</code> service for 5
times with 1 seconds between each try, it can be called via</p>
<pre><code class="language-bash">bash wait-for-service.sh mysql 5 1</code></pre>
<p>Output</p>
<pre><code class="language-text">$ bash wait-for-service.sh mysql 5 1
Waiting for service 'mysql' to become healthy, checking every 1 second(s) for max. 5 times
[1/5] ...
[2/5] ...
[3/5] ...
[4/5] ...
[5/5] ...
FAIL

# OR

$ bash wait-for-service.sh mysql 5 1
Waiting for service 'mysql' to become healthy, checking every 1 second(s) for max. 5 times
[1/5] ...
[2/5] ...
SUCCESS</code></pre>
<p>The problem of &quot;container dependencies&quot; isn't new and there are already some existing solutions
out there, e.g.</p>
<ul>
<li><a href="https://github.com/eficode/wait-for">wait-for</a></li>
<li><a href="https://github.com/vishnubob/wait-for-it">wait-for-it</a></li>
<li><a href="https://github.com/jwilder/dockerize#waiting-for-other-dependencies">dockerize</a></li>
<li><a href="https://github.com/ufoscout/docker-compose-wait">docker-compose-wait</a></li>
</ul>
<p>But unfortunately all of them operate by checking the availability of a <code>host:port</code> combination
and in the case of <code>mysql</code> that didn't help, because the container was up, the port was reachable
but the <code>mysql</code> service in the container was not.</p>
<!-- generated -->
<p><a id='setup-for-a-local-ci-run'> </a></p>
<!-- /generated -->
<h3>Setup for a &quot;local&quot; CI run</h3>
<p>As mentioned under <a href="#approach">Approach</a>, we want to be able to perform all necessary steps
locally and I created a corresponding script at <code>.local-ci.sh</code>:</p>
<pre><code class="language-bash">#!/bin/bash
# fail on any error 
# @see https://stackoverflow.com/a/3474556/413531
set -e

make docker-down ENV=ci || true

start_total=$(date +%s)

# STORE GPG KEY
cp secret-protected.gpg.example secret.gpg

# DEBUG
docker version
docker compose version
cat /etc/*-release || true

# SETUP DOCKER
make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=12345678"
start_docker_build=$(date +%s)
make docker-build
end_docker_build=$(date +%s)
mkdir -p .build &amp;&amp; chmod 777 .build

# START DOCKER
start_docker_up=$(date +%s)
make docker-up
end_docker_up=$(date +%s)
make gpg-init
make secret-decrypt-with-password

# QA
start_qa=$(date +%s)
make qa || FAILED=true
end_qa=$(date +%s)

# WAIT FOR CONTAINERS
start_wait_for_containers=$(date +%s)
bash .docker/scripts/wait-for-service.sh mysql 30 1
end_wait_for_containers=$(date +%s)

# TEST
start_test=$(date +%s)
make test || FAILED=true
end_test=$(date +%s)

end_total=$(date +%s)

# RUNTIMES
echo "Build docker:        " `expr $end_docker_build - $start_docker_build`
echo "Start docker:        " `expr $end_docker_up - $start_docker_up  `
echo "QA:                  " `expr $end_qa - $start_qa`
echo "Wait for containers: " `expr $end_wait_for_containers - $start_wait_for_containers`
echo "Tests:               " `expr $end_test - $start_test`
echo "---------------------"
echo "Total:               " `expr $end_total - $start_total`

# CLEANUP
# reset the default make variables
make make-init
make docker-down ENV=ci || true

# EVALUATE RESULTS
if [ "$FAILED" == "true" ]; then echo "FAILED"; exit 1; fi

echo "SUCCESS"</code></pre>
<!-- generated -->
<p><a id='run-details'> </a></p>
<!-- /generated -->
<h4>Run details</h4>
<ul>
<li>as a preparation step, we first ensure that no outdated <code>ci</code> containers are running (this is
only necessary locally, because runners on a remote CI system will start &quot;from scratch&quot;)
<pre><code class="language-bash">make docker-down ENV=ci || true</code></pre></li>
<li>we take some time measurements to understand how long certain parts take via
<pre><code class="language-bash">start_total=$(date +%s)</code></pre>
<p>to store the current timestamp</p></li>
<li>we need the secret <code>gpg</code> key in order to decrypt the secrets and simply copy the
<a href="#add-a-password-protected-secret-gpg-key">password-protected example key</a>
(in the actual CI systems the key will be configured as a secret value that is injected in
the run)
<pre><code class="language-bash"># STORE GPG KEY
cp secret-protected.gpg.example secret.gpg</code></pre></li>
<li>I like printing some debugging info in order to understand which exact circumstances
we're dealing with (tbh, this is mostly relevant when setting the CI system up or making
modifications to it)
<pre><code class="language-bash"># DEBUG
docker version
docker compose version
cat /etc/*-release || true</code></pre></li>
<li>for the docker setup, we start with
<a href="#initialize-make-for-ci">initializing the environment for <code>ci</code></a>
<pre><code class="language-bash"># SETUP DOCKER
make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=12345678"</code></pre>
<p>then build the docker setup</p>
<pre><code class="language-bash">make docker-build</code></pre>
<p>and finally add a <code>.build/</code> directory to
<a href="#create-a-junit-report-from-phpunit">collect the build artifacts</a></p>
<pre><code class="language-bash">mkdir -p .build &amp;&amp; chmod 777 .build</code></pre></li>
<li>then, the docker setup is started
<pre><code class="language-bash"># START DOCKER
make docker-up</code></pre>
<p>and <code>gpg</code> is initialized so that
<a href="#add-a-password-protected-secret-gpg-key">the secrets can be decrypted</a></p>
<pre><code class="language-bash">make gpg-init
make secret-decrypt-with-password</code></pre>
<p>We don't need to pass a <code>GPG_PASSWORD</code> to <code>secret-decrypt-with-password</code> because we have set
it up in the previous step as a default value via <code>make-init</code></p></li>
<li>once the <code>application</code> container is running, the qa tools are run by invoking the
<a href="/blog/php-qa-tools-make-docker/#the-qa-target"><code>qa</code> make target</a>
<pre><code class="language-bash"># QA
make qa || FAILED=true</code></pre>
<p>The <code>|| FAILED=true</code> part makes sure that the script will not be terminated if the checks fail.
Instead, the fact that a failure happened is &quot;recorded&quot; in the <code>FAILED</code> variable so that we
can evaluate it at the end. We don't want the script to stop here because we want the
following steps to be executed as well (e.g. the tests).</p></li>
<li>to mitigate the
<a href="#adding-a-health-check-for-mysql">&quot;<code>mysql</code> is not ready&quot; problem</a>, we will now apply the
<a href="#wait-for-service-sh">wait-for-service.sh script</a>
<pre><code class="language-bash"># WAIT FOR CONTAINERS
bash .docker/scripts/wait-for-service.sh mysql 30 1</code></pre></li>
<li>once <code>mysql</code> is ready, we can execute the tests via the
<a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/#install-phpunit"><code>test</code> make target</a> and
apply the same <code>|| FAILED=true</code> workaround as for the qa tools
<pre><code class="language-bash"># TEST
make test || FAILED=true</code></pre></li>
<li>finally, all the timers are printed
<pre><code class="language-bash"># RUNTIMES
echo "Build docker:        " `expr $end_docker_build - $start_docker_build`
echo "Start docker:        " `expr $end_docker_up - $start_docker_up  `
echo "QA:                  " `expr $end_qa - $start_qa`
echo "Wait for containers: " `expr $end_wait_for_containers - $start_wait_for_containers`
echo "Tests:               " `expr $end_test - $start_test`
echo "---------------------"
echo "Total:               " `expr $end_total - $start_total`</code></pre></li>
<li>we clean up the resources (this is only necessary when running locally, because the runner of
a CI system would be shut down anyways)
<pre><code class="language-bash"># CLEANUP
make make-init
make docker-down ENV=ci || true</code></pre></li>
<li>
<p>and finally evaluate if any error occurred when running the qa tools or the tests</p>
<pre><code class="language-bash"># EVALUATE RESULTS
if [ "$FAILED" == "true" ]; then echo "FAILED"; exit 1; fi

echo "SUCCESS"</code></pre>
</li>
</ul>
<!-- generated -->
<p><a id='execution-example'> </a></p>
<!-- /generated -->
<h4>Execution example</h4>
<p>Executing the script via</p>
<pre><code class="language-bash">bash .local-ci.sh</code></pre>
<p>yields the following (shortened) output:</p>
<pre><code class="language-text">$ bash .local-ci.sh
Container dofroscra_ci-redis-1  Stopping
# Stopping all other `ci` containers ...
# ...

Client:
 Cloud integration: v1.0.22
 Version:           20.10.13
# Print more debugging info ...
# ...

Created a local .make/.env file
ENV=ci TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker compose -p dofroscra_ci --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose-php-base.yml build php-base
#1 [internal] load build definition from Dockerfile
# Output from building the docker containers 
# ...

ENV=ci TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker compose -p dofroscra_ci --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.local.ci.yml -f ./.docker/docker-compose/docker-compose.ci.yml up -d
Network dofroscra_ci_network  Creating
# Starting all `ci` containers ...
# ...

"C:/Program Files/Git/mingw64/bin/make" -s gpg-import GPG_KEY_FILES="secret.gpg"
gpg: directory '/home/application/.gnupg' created
gpg: keybox '/home/application/.gnupg/pubring.kbx' created
gpg: /home/application/.gnupg/trustdb.gpg: trustdb created
gpg: key D7A860BBB91B60C7: public key "Alice Doe protected &lt;alice.protected@example.com&gt;" imported
# Output of importing the secret and public gpg keys
# ...

"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="reveal -f -p 12345678"
git-secret: done. 1 of 1 files are revealed.
"C:/Program Files/Git/mingw64/bin/make" -j 8 -k --no-print-directory --output-sync=target qa-exec NO_PROGRESS=true
phplint                             done   took 4s
phpcs                               done   took 4s
phpstan                             done   took 8s
composer-require-checker            done   took 8s
Waiting for service 'mysql' to become healthy, checking every 1 second(s) for max. 30 times
[1/30] ...
SUCCESS
PHPUnit 9.5.19 #StandWithUkraine

........                                                            8 / 8 (100%)

Time: 00:03.077, Memory: 28.00 MB

OK (8 tests, 15 assertions)
Build docker:         12
Start docker:         2
QA:                   9
Wait for containers:  3
Tests:                5
---------------------
Total:                46
Created a local .make/.env file

Container dofroscra_ci-application-1  Stopping
Container dofroscra_ci-mysql-1  Stopping
# Stopping all other `ci` containers ...
# ...

SUCCESS</code></pre>
<!-- generated -->
<p><a id='setup-for-github-actions'> </a></p>
<!-- /generated -->
<h3>Setup for Github Actions</h3>
<ul>
<li><a href="https://github.com/paslandau/docker-php-tutorial/tree/part-7-ci-pipeline-docker-php-gitlab-github">Repository (branch <code>part-7-ci-pipeline-docker-php-gitlab-github</code>)</a></li>
<li><a href="https://github.com/paslandau/docker-php-tutorial/actions">CI/CD overview (Actions)</a></li>
<li><a href="https://github.com/paslandau/docker-php-tutorial/runs/5866235820?check_suite_focus=true">Example of a successful job</a></li>
<li><a href="https://github.com/paslandau/docker-php-tutorial/runs/5867485802?check_suite_focus=true">Example of a failed job</a></li>
</ul>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/github-action-example.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/github-action-example.PNG" alt="Github Action example" /></a></p>
<p>If you are completely new to Github Actions, I recommend to start with the
<a href="https://docs.github.com/en/actions/quickstart">official Quickstart Guide for GitHub Actions</a>
and the
<a href="https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions">Understanding GitHub Actions</a>
article. In short:</p>
<ul>
<li>Github Actions are based on so called <strong>Workflows</strong>
<ul>
<li>Workflows are <code>yaml</code> files that  live in the special <code>.github/workflows</code> directory in the
repository</li>
</ul></li>
<li>a Workflow can contain multiple <strong>Jobs</strong></li>
<li>each Job consists of a series of <strong>Steps</strong></li>
<li>each Step needs a <code>run:</code> element that represents a command that is executed by a new shell
<ul>
<li>multi-line commands that should use the same shell are written as
<pre><code class="language-yaml">- run : |
    echo "line 1"
    echo "line 2"</code></pre>
<p>See also <a href="https://stackoverflow.com/a/59536836/413531">difference between &quot;run |&quot; and multiple runs in github actions</a></p></li>
</ul></li>
</ul>
<!-- generated -->
<p><a id='the-workflow-file'> </a></p>
<!-- /generated -->
<h4>The Workflow file</h4>
<p>Github Actions are triggered automatically based on the files in the <code>.github/workflows</code> directory.
I have added the file <code>.github/workflows/ci.yml</code> with the following content:</p>
<pre><code class="language-yaml">name: CI build and test

on:
  # automatically run for pull request and for pushes to branch "part-7-ci-pipeline-docker-php-gitlab-github"
  # @see https://stackoverflow.com/a/58142412/413531
  push:
    branches:
      - part-7-ci-pipeline-docker-php-gitlab-github
  pull_request: {}
  # enable to trigger the action manually
  # @see https://github.blog/changelog/2020-07-06-github-actions-manual-triggers-with-workflow_dispatch/
  # CAUTION: there is a known bug that makes the "button to trigger the run" not show up
  # @see https://github.community/t/workflow-dispatch-workflow-not-showing-in-actions-tab/130088/29
  workflow_dispatch: {}

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v1

      - name: start timer
        run: |
          echo "START_TOTAL=$(date +%s)" &gt; $GITHUB_ENV

      - name: STORE GPG KEY
        run: |
          # Note: make sure to wrap the secret in double quotes (")
          echo "${{ secrets.GPG_KEY }}" &gt; ./secret.gpg

      - name: SETUP TOOLS
        run : |
          DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}
          # install docker compose
          # @see https://docs.docker.com/compose/cli-command/#install-on-linux
          # @see https://github.com/docker/compose/issues/8630#issuecomment-1073166114
          mkdir -p $DOCKER_CONFIG/cli-plugins 
          curl -sSL https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-$(uname -m) -o $DOCKER_CONFIG/cli-plugins/docker-compose
          chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose

      - name: DEBUG
        run: |
          docker compose version
          docker --version
          cat /etc/*-release

      - name: SETUP DOCKER
        run: |
          make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=${{ secrets.GPG_PASSWORD }}"
          make docker-build
          mkdir .build &amp;&amp; chmod 777 .build

      - name: START DOCKER
        run: |
          make docker-up
          make gpg-init
          make secret-decrypt-with-password

      - name: QA
        run: |
          # Run the tests and qa tools but only store the error instead of failing immediately
          # @see https://stackoverflow.com/a/59200738/413531
          make qa || echo "FAILED=qa" &gt;&gt; $GITHUB_ENV

      - name: WAIT FOR CONTAINERS
        run: |
          # We need to wait until mysql is available.
          bash .docker/scripts/wait-for-service.sh mysql 30 1 

      - name: TEST
        run: |
          make test || echo "FAILED=test $FAILED" &gt;&gt; $GITHUB_ENV

      - name: RUNTIMES
        run: |
          echo `expr $(date +%s) - $START_TOTAL`

      - name: EVALUATE
        run: |
          # Check if $FAILED is NOT empty
          if [ ! -z "$FAILED" ]; then echo "Failed at $FAILED" &amp;&amp; exit 1; fi

      - name: upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: ./.build</code></pre>
<p>The steps are essentially the same as explained before at
<a href="#run-details">Run details for the local run</a>. Some additional notes:</p>
<ul>
<li>I want the Action to be triggered automatically only when I
<a href="https://stackoverflow.com/a/58142412/413531">push to branch <code>part-7-ci-pipeline-docker-php-gitlab-github</code></a>
OR when a pull request is created (via <code>pull_request</code>). In addition, I want to be able to
<a href="https://github.blog/changelog/2020-07-06-github-actions-manual-triggers-with-workflow_dispatch/">trigger the Action manually on any branch</a>
(via <code>workflow_dispatch</code>).
<pre><code class="language-yaml">on:
push:
  branches:
    - part-7-ci-pipeline-docker-php-gitlab-github
pull_request: {}
workflow_dispatch: {}</code></pre>
<p>For a real project, I would let the action only run automatically on long-living branches like
<code>main</code> or <code>develop</code>. The manual trigger is helpful if you just want to test your current work
without putting it up for review. <strong>CAUTION:</strong> There is a
<a href="https://github.community/t/workflow-dispatch-workflow-not-showing-in-actions-tab/130088/29">known issue that &quot;hides&quot; the &quot;Trigger workflow&quot; button to trigger the action manually</a>.</p></li>
<li>a new shell is started for each <code>run:</code> instruction, thus we must store our timer in the &quot;global&quot;
<a href="https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-an-environment-variable">environment variable <code>$GITHUB_ENV</code></a>
<pre><code class="language-yaml">  - name: start timer
  run: |
    echo "START_TOTAL=$(date +%s)" &gt; $GITHUB_ENV </code></pre>
<p>This will be the only timer we use, because the job uses multiple steps that are timed
automatically - so we don't need to take timestamps manually:
<a href="/img/ci-pipeline-docker-php-gitlab-github/github-action-step-times.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/github-action-step-times.PNG" alt="Github Action step times" /></a></p></li>
<li>
<p>the <code>gpg</code> key is configured as an
<a href="https://docs.github.com/en/actions/security-guides/encrypted-secrets">encrypted secret</a> named
<code>GPG_KEY</code> and is stored in <code>./secret.gpg</code>. The value is the content of the
<code>secret-protected.gpg.example</code> file</p>
<pre><code class="language-yaml">  - name: STORE GPG KEY
    run: |
      echo "${{ secrets.GPG_KEY }}" &gt; ./secret.gpg</code></pre>
<p>Secrets are configured in the Github repository under <code>Settings &gt; Secrets &gt; Actions</code> at</p>
<pre><code class="language-text">https://github.com/$user/$repository/settings/secrets/actions

e.g.

https://github.com/paslandau/docker-php-tutorial/settings/secrets/actions</code></pre>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/github-secrets-ui.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/github-secrets-ui.PNG" alt="Github Action Secrets UI" /></a></p>
</li>
<li>the <code>ubuntu-latest</code> image doesn't contain the <code>docker compose</code> plugin, thus we need to
<a href="https://docs.docker.com/compose/cli-command/#install-on-linux">install it manually</a>
<pre><code class="language-yaml">  - name: SETUP TOOLS
  run : |
    DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker}
    mkdir -p $DOCKER_CONFIG/cli-plugins 
    curl -sSL https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-$(uname -m) -o $DOCKER_CONFIG/cli-plugins/docker-compose
    chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose</code></pre></li>
<li>for the <code>make</code> initialization we need the second secret named <code>GPG_PASSWORD</code> - which is
configured as <code>12345678</code> in our case, see
<a href="#add-a-password-protected-secret-gpg-key">Add a password-protected secret gpg key</a>
<pre><code class="language-yaml">  - name: SETUP DOCKER
    run: |
      make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=${{ secrets.GPG_PASSWORD }}"</code></pre></li>
<li>because the runner will be shutdown after the run, we need to move the build artifacts to a
permanent location, using the
<a href="https://github.com/actions/upload-artifact#upload-an-entire-directory">actions/upload-artifact@v3 action</a>
<pre><code class="language-yaml">  - name: upload build artifacts
    uses: actions/upload-artifact@v3
    with:
      name: build-artifacts
      path: ./.build</code></pre>
<p>You can
<a href="https://github.com/actions/upload-artifact#where-does-the-upload-go">download the artifacts in the Run overview UI</a>
<a href="/img/ci-pipeline-docker-php-gitlab-github/github-action-run-overview-build-artifacts.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/github-action-run-overview-build-artifacts.PNG" alt="Github Actions: Run overview UI shows build-artifacts" /></a></p></li>
</ul>
<!-- generated -->
<p><a id='setup-for-gitlab-pipelines'> </a></p>
<!-- /generated -->
<h3>Setup for Gitlab Pipelines</h3>
<ul>
<li><a href="https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/tree/part-7-ci-pipeline-docker-php-gitlab-github">Repository (branch <code>part-7-ci-pipeline-docker-php-gitlab-github</code>)</a></li>
<li><a href="https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/pipelines">CI/CD overview (Pipelines)</a></li>
<li><a href="https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/pipelines/511339886">Example of a successful job</a></li>
<li><a href="https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/pipelines/511341545">Example of a failed job</a></li>
</ul>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/gitlab-pipeline-example.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/gitlab-pipeline-example.PNG" alt="Gitlab Pipeline example" /></a></p>
<p>If you are completely new to Gitlab Pipelines, I recommend to start with the
<a href="https://docs.gitlab.com/ee/ci/quick_start/">official Get started with GitLab CI/CD guide</a>. In
short:</p>
<ul>
<li>the core concept of Gitlab Pipelines is the <strong>Pipeline</strong>
<ul>
<li>it is defined in the <code>yaml</code> file <code>.gitlab-ci.yml</code> that lives in the root of the repository</li>
</ul></li>
<li>a Pipeline can contain multiple <strong>Stages</strong></li>
<li>each Stage consists of a series of <strong>Jobs</strong></li>
<li>each Job contains a <a href="https://docs.gitlab.com/ee/ci/yaml/index.html#script"><strong><code>script</code></strong> section</a></li>
<li>the <code>script</code> section consists of a series of shell commands</li>
</ul>
<!-- generated -->
<p><a id='the-gitlab-ci-yml-pipeline-file'> </a></p>
<!-- /generated -->
<h4>The <code>.gitlab-ci.yml</code> pipeline file</h4>
<p>Gitlab Pipelines are triggered automatically based on a <code>.gitlab-ci.yml</code> file located at the
root of the repository. It has the following content:</p>
<pre><code class="language-yaml">stages:
  - build_test

QA and Tests:
  stage: build_test

  rules:
    # automatically run for pull request and for pushes to branch "part-7-ci-pipeline-docker-php-gitlab-github"
    - if: '($CI_PIPELINE_SOURCE == "merge_request_event" || $CI_COMMIT_BRANCH == "part-7-ci-pipeline-docker-php-gitlab-github")'

  # see https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker
  image: docker:20.10.12

  services:
    - name: docker:dind

  script:
    - start_total=$(date +%s)

    ## STORE GPG KEY
    - cp $GPG_KEY_FILE ./secret.gpg

    ## SETUP TOOLS
    - start_install_tools=$(date +%s)
    # "curl" is required to download docker compose
    - apk add --no-cache make bash curl
    # install docker compose
    # @see https://docs.docker.com/compose/cli-command/#install-on-linux
    - mkdir -p ~/.docker/cli-plugins/
    - curl -sSL https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose
    - chmod +x ~/.docker/cli-plugins/docker-compose
    - end_install_tools=$(date +%s)

    ## DEBUG
    - docker version
    - docker compose version
    # show linux distro info
    - cat /etc/*-release

    ## SETUP DOCKER
    # Pass default values to the make-init command - otherwise we would have to pass those as arguments to every make call
    - make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=$GPG_PASSWORD"
    - start_docker_build=$(date +%s)
    - make docker-build
    - end_docker_build=$(date +%s)
    - mkdir .build &amp;&amp; chmod 777 .build

    ## START DOCKER
    - start_docker_up=$(date +%s)
    - make docker-up
    - end_docker_up=$(date +%s)
    - make gpg-init
    - make secret-decrypt-with-password

    ## QA
    # Run the tests and qa tools but only store the error instead of failing immediately
    # @see https://stackoverflow.com/a/59200738/413531
    - start_qa=$(date +%s)
    - make qa ENV=ci || FAILED=true
    - end_qa=$(date +%s)

    ## WAIT FOR CONTAINERS
    # We need to wait until mysql is available.
    - start_wait_for_containers=$(date +%s)
    - bash .docker/scripts/wait-for-service.sh mysql 30 1
    - end_wait_for_containers=$(date +%s)

    ## TEST
    - start_test=$(date +%s)
    - make test ENV=ci || FAILED=true
    - end_test=$(date +%s)

    - end_total=$(date +%s)

    # RUNTIMES
    - echo "Tools:" `expr $end_install_tools - $start_install_tools`
    - echo "Build docker:" `expr $end_docker_build - $start_docker_build`
    - echo "Start docker:" `expr $end_docker_up - $start_docker_up  `
    - echo "QA:" `expr $end_qa - $start_qa`
    - echo "Wait for containers:" `expr $end_wait_for_containers - $start_wait_for_containers`
    - echo "Tests:" `expr $end_test - $start_test`
    - echo "Total:" `expr $end_total - $start_total`

    # EVALUATE RESULTS
    # Use if-else constructs in Gitlab pipelines
    # @see https://stackoverflow.com/a/55464100/413531
    - if [ "$FAILED" == "true" ]; then exit 1; fi

  # Save the build artifact, e.g. the JUNIT report.xml file, so we can download it later
  # @see https://docs.gitlab.com/ee/ci/pipelines/job_artifacts.html
  artifacts:
    when: always
    paths:
      # the quotes are required
      # @see https://stackoverflow.com/questions/38009869/how-to-specify-wildcard-artifacts-subdirectories-in-gitlab-ci-yml#comment101411265_38055730
      - ".build/*"
    expire_in: 1 week</code></pre>
<p>The steps are essentially the same as explained before under
<a href="#run-details">Run details for the local run</a>. Some additional notes:</p>
<ul>
<li>we start by defining the stages of the pipeline - though that's currently just one (<code>build_test</code>)
<pre><code class="language-yaml">stages:
- build_test</code></pre></li>
<li>then we define the job <code>QA and Tests</code> and assign it to the <code>build_test</code> stage
<pre><code class="language-yaml">QA and Tests:
stage: build_test</code></pre></li>
<li>I want the Pipeline to be triggered automatically only when I
<a href="https://stackoverflow.com/a/66812732/413531">push to branch <code>part-7-ci-pipeline-docker-php-gitlab-github</code></a>
OR <a href="https://docs.gitlab.com/ee/ci/pipelines/merge_request_pipelines.html#use-rules-to-add-jobs">when a pull request is created</a>
<a href="https://www.shellhacks.com/gitlab-ci-cd-trigger-pipeline-manually-api/">Triggering the Pipeline manually on any branch is possible by default</a>.
<pre><code class="language-yaml">rules:
- if: '($CI_PIPELINE_SOURCE == "merge_request_event" || $CI_COMMIT_BRANCH == "part-7-ci-pipeline-docker-php-gitlab-github")'</code></pre></li>
<li>
<p>since we want to build and run docker images, we need to use a docker base image and activate the
<code>docker:dind</code> service. See <a href="https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker">Use Docker to build Docker images: Use Docker-in-Docker</a></p>
<pre><code class="language-yaml">image: docker:20.10.12

services:
- name: docker:dind</code></pre>
</li>
<li>
<p>we store the secret <code>gpg</code> key as a secret file (using the
<a href="https://docs.gitlab.com/ee/ci/variables/#cicd-variable-types">&quot;file&quot; type</a>) in the
<a href="https://docs.gitlab.com/ee/ci/variables/#custom-cicd-variables">CI/CD variables configuration of the Gitlab repository</a>
and move it to <code>./secret.gpg</code> in order to decrypt the secrets later</p>
<pre><code class="language-yaml">## STORE GPG KEY
- cp $GPG_KEY_FILE ./secret.gpg</code></pre>
<p>Secrets can be configured under <code>Settings &gt; CI/CD &gt; Variables</code> at</p>
<pre><code class="language-text">https://gitlab.com/$project/$repository/-/settings/ci_cd

e.g.

https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/settings/ci_cd</code></pre>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/gitlab-ci-cd-variables-ui.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/gitlab-ci-cd-variables-ui.PNG" alt="Gitlab CI/CD Variables UI" /></a></p>
</li>
<li>the docker base image doesn't come with all required tools, thus we need to install the
missing ones (<code>make</code>, <code>bash</code>, <code>curl</code> and <code>docker compose</code>)
<pre><code class="language-yaml">  ## SETUP TOOLS
  - apk add --no-cache make bash curl
  - mkdir -p ~/.docker/cli-plugins/
  - curl -sSL https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose
  - chmod +x ~/.docker/cli-plugins/docker-compose</code></pre></li>
<li>for the initialization of <code>make</code> we use the <code>$GPG_PASSWORD</code> variable that we defined in the
CI/CD settings
<pre><code class="language-yaml">## SETUP DOCKER
- make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=$GPG_PASSWORD"</code></pre>
<p>Note: I have <a href="https://docs.gitlab.com/ee/ci/variables/#mask-a-cicd-variable">marked the variable as &quot;masked&quot;</a>
so it won't show up in any logs</p></li>
<li>finally, we store <a href="https://docs.gitlab.com/ee/ci/pipelines/job_artifacts.html">the job artifacts</a>
<pre><code class="language-yaml">artifacts:
when: always
paths:
  - ".build/*"
expire_in: 1 week </code></pre>
<p>They can be accessed in the <a href="https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/pipelines">Pipeline overview UI</a>
<a href="/img/ci-pipeline-docker-php-gitlab-github/gitlab-pipeline-build-artifacts.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/gitlab-pipeline-build-artifacts.PNG" alt="Gitlab Pipeline overview UI" /></a></p></li>
</ul>
<!-- generated -->
<p><a id='performance'> </a></p>
<!-- /generated -->
<h4>Performance</h4>
<p><strong>Performance isn't an issue right now</strong>, because the CI runs take only about ~1 min (Github Actions)
and ~2 min (Gitlab Pipelines), but that's mostly because we only ship a super minimal
application and those times <em>will go up</em> when things get more complex. For the local setup I
used all 8 cores of my laptop. The time breakdown is roughly as follows:</p>
<table>
<thead>
<tr>
<th>Step</th>
<th>Gitlab</th>
<th>Github</th>
<th>local <br /> without cache</th>
<th>local <br /> with cached images</th>
<th>local <br /> with cached images + layers</th>
</tr>
</thead>
<tbody>
<tr>
<td>SETUP TOOLS</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>SETUP DOCKER</td>
<td>33</td>
<td>17</td>
<td>39</td>
<td>39</td>
<td>5</td>
</tr>
<tr>
<td>START DOCKER</td>
<td>17</td>
<td>11</td>
<td>34</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>QA</td>
<td>17</td>
<td>5</td>
<td>10</td>
<td>13</td>
<td>1</td>
</tr>
<tr>
<td>WAIT FOR CONTAINERS</td>
<td>5</td>
<td>5</td>
<td>3</td>
<td>2</td>
<td>13</td>
</tr>
<tr>
<td>TESTS</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>6</td>
<td>3</td>
</tr>
<tr>
<td><strong>total <br /> (excl. runner startup)</strong></td>
<td>78</td>
<td>43</td>
<td>97</td>
<td>70</td>
<td>36</td>
</tr>
<tr>
<td><strong>total <br /> (incl. runner startup)</strong></td>
<td>139</td>
<td>54</td>
<td>97</td>
<td>70</td>
<td>36</td>
</tr>
</tbody>
</table>
<p>Times taken from</p>
<ul>
<li><a href="https://github.com/paslandau/docker-php-tutorial/actions/runs/2108659089">&quot;CI build and test #83&quot; Github Action run</a></li>
<li><a href="https://gitlab.com/docker-php-tutorial/docker-php-tutorial/-/pipelines/511355192">&quot;Pipeline #511355192&quot; Gitlab Pipeline run</a></li>
<li>&quot;local without cache&quot; via <code>bash .local-ci.sh</code> with no local images at all</li>
<li>&quot;local with cached images&quot; via <code>bash .local-ci.sh</code> with cached images for <code>mysql</code> and <code>redis</code></li>
<li>&quot;local with cached images + layers&quot; via <code>bash .local-ci.sh</code> with cached images for <code>mysql</code> and
<code>redis</code> and a <a href="#build-the-dependencies">&quot;warm&quot; layer cache for the <code>application</code> image</a></li>
</ul>
<p><strong>Optimizing the performance is out of scope for this tutorial</strong>, but I'll at least document my
current findings.</p>
<!-- generated -->
<p><a id='the-caching-problem-on-ci'> </a></p>
<!-- /generated -->
<h5>The caching problem on CI</h5>
<p>A good chunk of time is <strong>usually spent on building the docker images</strong>. We did our best to optimize
the process by leveraging the layer cache and using cache mounts
(see section <a href="#build-stage-ci-in-the-php-base-image">Build stage <code>ci</code> in the <code>php-base</code> image</a>).
But those steps are futile on CI systems, because the corresponding <strong>runners will start &quot;from
scratch&quot; for every CI run</strong> - i.e. <strong>there is no local cache</strong> that they could use. In
consequence, <strong>the full docker setup is also built &quot;from scratch&quot;</strong> on every run.</p>
<p>There are ways to mitigate that e.g.</p>
<ul>
<li>pushing images to a container registry and pulling them before building the images to leverage
the layer cache via the <a href="https://docs.docker.com/compose/compose-file/compose-file-v3/#cache_from"><code>cache_from</code> option</a>
of <code>docker compose</code></li>
<li>exporting and importing the images as <code>tar</code> archives via
<a href="https://docs.docker.com/engine/reference/commandline/save/"><code>docker save</code></a> and<br />
<a href="https://docs.docker.com/engine/reference/commandline/load/"><code>docker load</code></a>,
storing them either in the built-in cache of
<a href="https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows">Github</a>
or <a href="https://docs.gitlab.com/ee/ci/caching/">Gitlab</a>
<ul>
<li>see also the <a href="https://github.com/marketplace/actions/docker-layer-caching">satackey/action-docker-layer-caching@v0.0.11 Github Action</a>
and the official <a href="https://github.com/actions/cache">actions/cache@v3 Github Action</a></li>
</ul></li>
<li>using the <a href="https://docs.docker.com/engine/reference/commandline/buildx_build/#cache-from"><code>--cache-from</code></a>
and <a href="https://docs.docker.com/engine/reference/commandline/buildx_build/#cache-to"><code>--cache-to</code></a> options of
<a href="https://docs.docker.com/buildx/working-with-buildx/"><code>buildx</code></a>
<ul>
<li>see also the <a href="https://github.com/docker/build-push-action/blob/master/docs/advanced/cache.md">&quot;cache&quot; docu of the docker/build-push-action@v2 Github Action</a></li>
</ul></li>
</ul>
<p>But: None of that worked for me out-of-the-box :( We will take a closer look in an upcoming
tutorial. Some reading material that I found valuable so far:</p>
<ul>
<li><a href="https://dev.to/dtinth/caching-docker-builds-in-github-actions-which-approach-is-the-fastest-a-research-18ei">Caching Docker builds in GitHub Actions: Which approach is the fastest?  A research.</a></li>
<li><a href="https://seankhliao.com/blog/12021-01-23-docker-buildx-caching/">Caching strategies for CI systems</a></li>
<li><a href="https://evilmartians.com/chronicles/build-images-on-github-actions-with-docker-layer-caching">Build images on GitHub Actions with Docker layer caching</a></li>
<li><a href="https://testdriven.io/blog/faster-ci-builds-with-docker-cache/">Faster CI Builds with Docker Layer Caching and BuildKit</a></li>
<li><a href="https://www.docker.com/blog/image-rebase-and-improved-remote-cache-support-in-new-buildkit/">Image rebase and improved remote cache support in new BuildKit</a></li>
</ul>
<!-- generated -->
<p><a id='docker-changes'> </a></p>
<!-- /generated -->
<h2>Docker changes</h2>
<p>As a first step we need to decide <strong>which containers are required</strong> and <strong>how to provide the
codebase</strong>.</p>
<p>Since our goal is running the qa tools and tests, we only need the <code>application</code> php container. The
tests also need a database and a queue, i.e. the <code>mysql</code> and <code>redis</code> containers are required as
well - whereas <code>nginx</code>, <code>php-fpm</code> and <code>php-worker</code> are not required. We'll handle that through
dedicated <code>docker compose</code> configuration files that only contain the necessary services. This is
explained in more detail in section <a href="#compose-file-updates">Compose file updates</a>.</p>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/build-ci-images.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/build-ci-images.PNG" alt="Build images for CI" /></a></p>
<p>In our local setup, we have <strong>shared the codebase between the host system and docker</strong> - mainly
because we wanted our changes to be reflected immediately in docker. <strong>This isn't necessary for the
CI</strong> use case. In fact we want our <strong>CI images as close as possible to our production images</strong> - and
those should &quot;contain everything to run independently&quot;. I.e. <strong>the codebase should live in the
image</strong> - not on the host system. This will be explained in section
<a href="#use-the-whole-codebase-as-build-context">Use the whole codebase as build context</a>.</p>
<!-- generated -->
<p><a id='compose-file-updates'> </a></p>
<!-- /generated -->
<h3>Compose file updates</h3>
<p>We will not only have some differences between the CI docker setup and the local docker setup
(=different containers), but also in the configuration of the individual services. To accommodate
for that, we will use the following <code>docker compose</code> config files in the
<code>.docker/docker-compose/</code> directory: </p>
<ul>
<li><code>docker-compose.local.ci.yml</code>:
<ul>
<li>holds configuration that is valid for <code>local</code> and <code>ci</code>, trying to keep the config files
<a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY</a></li>
</ul></li>
<li><code>docker-compose.ci.yml</code>:
<ul>
<li>holds configuration that is only valid for <code>ci</code></li>
</ul></li>
<li><code>docker-compose.local.yml</code>:
<ul>
<li>holds configuration that is only valid for <code>local</code></li>
</ul></li>
</ul>
<p>When using <code>docker compose</code> we then need to make sure to include only the required files, e.g. for
<code>ci</code>:</p>
<pre><code class="language-bash">docker compose -f docker-compose.local.ci.yml -f docker-compose.ci.yml</code></pre>
<p>I'll explain  the logic for that later in
section <a href="#env-based-docker-compose-config">ENV based docker compose config</a>. In short:</p>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/assemble-docker-compose-files.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/assemble-docker-compose-files.PNG" alt="Assemble docker-compose config files for CI" /></a></p>
<p>When comparing <code>ci</code> with <code>local</code>, for <code>ci</code></p>
<ul>
<li>we <strong>don't need to share the codebase</strong> with the host system
<pre><code class="language-yaml">application:
  volumes:
  - ${APP_CODE_PATH_HOST?}:${APP_CODE_PATH_CONTAINER?}</code></pre></li>
<li>
<p>we <strong>don't need persistent volumes</strong> for the redis and mysql data</p>
<pre><code class="language-yaml">mysql:
  volumes:
    - mysql:/var/lib/mysql

redis:
  volumes:
    - redis:/data</code></pre>
</li>
<li>
<p>we <strong>don't need to share ports</strong> with the host system</p>
<pre><code class="language-yaml">application:
  ports:
    - "${APPLICATION_SSH_HOST_PORT:-2222}:22"

redis:
  ports:
    - "${REDIS_HOST_PORT:-6379}:6379"</code></pre>
</li>
<li>we <strong>don't need any settings for local dev tools</strong> like <code>xdebug</code> or <code>strace</code>
<pre><code class="language-yaml">application:
  environment:
    - PHP_IDE_CONFIG=${PHP_IDE_CONFIG?}
  cap_add:
    - "SYS_PTRACE"
  security_opt:
    - "seccomp=unconfined"
  extra_hosts:
    - host.docker.internal:host-gateway  </code></pre></li>
</ul>
<p>So all of those config values will only live in the <code>docker-compose.local.yml</code> file. In fact, there
are only two things that <code>ci</code> needs that <code>local</code> doesn't:</p>
<ul>
<li>a volume mount to <strong>share only the secret gpg key from the host with the <code>application</code> container</strong>
<pre><code class="language-yaml">application:
  volumes:
    - ${APP_CODE_PATH_HOST?}/secret.gpg:${APP_CODE_PATH_CONTAINER?}/secret.gpg:ro</code></pre>
<p>This
is <a href="/blog/git-secret-encrypt-repository-docker/#local-git-secret-and-gpg-setup">required to decrypt the secrets</a>:</p>
<blockquote>
<p>[...] the private key has to be named <code>secret.gpg</code> and put in the root of the codebase,
so that the import can be be simplified with <code>make</code> targets</p>
</blockquote></li>
<li>a volume mount to <strong>share a <code>.build</code> folder for build artifacts with the <code>application</code> container</strong>
<pre><code class="language-yaml">application:
  volumes:
    - ${APP_CODE_PATH_HOST?}/.build:${APP_CODE_PATH_CONTAINER?}/.build</code></pre>
<p>This will be used to collect any files we want to retain from a build (e.g. code coverage
information, log files, etc.)</p></li>
</ul>
<!-- generated -->
<p><a id='adding-a-health-check-for-mysql'> </a></p>
<!-- /generated -->
<h4>Adding a health check for <code>mysql</code></h4>
<p>When running the tests for the first time on a CI system, I noticed some weird errors related to the
database:</p>
<pre><code class="language-text">1) Tests\Feature\App\Http\Controllers\HomeControllerTest::test___invoke with data set "default" (array(), '    &lt;li&gt;&lt;a href="?dispatch=fo...&gt;&lt;/li&gt;')
PDOException: SQLSTATE[HY000] [2002] Connection refused</code></pre>
<p>As it turned out, the <code>mysql</code> container itself was up and running - but the <code>mysql</code> process
<em>within</em> the container was not yet ready to accept connections. Locally, this hasn't been a problem,
because we usually would not run the tests &quot;immediately&quot; after starting the containers - but on CI
this is the case.</p>
<p>Fortunately, <code>docker compose</code> has us covered here and provides a
<a href="https://docs.docker.com/compose/compose-file/#healthcheck"><code>healtcheck</code> configuration option</a>:</p>
<blockquote>
<p><code>healthcheck</code> declares a check thats run to determine whether or not containers for this service are &quot;healthy&quot;.</p>
</blockquote>
<p>Since this <code>healthcheck</code> is also &quot;valid&quot; for <code>local</code>, I defined it in the combined
<code>docker-compose.local.ci.yml</code> file:</p>
<pre><code class="language-yaml">  mysql:
    healthcheck:
      # Only mark the service as healthy if mysql is ready to accept connections
      # Check every 2 seconds for 30 times, each check has a timeout of 1s
      test: mysqladmin ping -h 127.0.0.1 -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
      timeout: 1s
      retries: 30
      interval: 2s</code></pre>
<p>The script in <code>test</code> was taken
from <a href="https://stackoverflow.com/a/54854239/413531">SO: Docker-compose check if mysql connection is ready</a>.</p>
<p>When starting the docker setup, <code>docker ps</code> will now add a health info to the <code>STATUS</code>:</p>
<pre><code class="language-text">$ make docker-up

$ docker ps
CONTAINER ID   IMAGE                            STATUS                           NAMES
b509eb2f99c0   dofroscra/application-ci:latest  Up 1 seconds                     dofroscra_ci-application-1
503e52fd9e68   mysql:8.0.28                     Up 1 seconds (health: starting)  dofroscra_ci-mysql-1

# a couple of seconds later

$ docker ps
CONTAINER ID   IMAGE                            STATUS                   NAMES
b509eb2f99c0   dofroscra/application-ci:latest  Up 13 seconds            dofroscra_ci-application-1
503e52fd9e68   mysql:8.0.28                     Up 13 seconds (healthy)  dofroscra_ci-mysql-1</code></pre>
<p>Note the <code>(health: starting)</code> and <code>(healthy)</code> infos for the <code>mysql</code> service.</p>
<p>We can also get this info from <code>docker inspect</code> (used by our
<a href="#wait-for-service-sh">wait-for-service.sh script</a>) via:</p>
<pre><code class="language-text">$ docker inspect --format "{{json .State.Health.Status }}" dofroscra_ci-mysql-1
"healthy"</code></pre>
<p>FYI: We could also use the
<a href="https://docs.docker.com/compose/compose-file/#depends_on"><code>depends_on</code> property</a> with a
<code>condition: service_healthy</code> on the <code>application</code> container so that <code>docker compose</code> would
only start the container once the <code>mysql</code> service is healthy:</p>
<pre><code class="language-yaml">application:
  depends_on:
    mysql: 
      condition: service_healthy</code></pre>
<p>However, this would &quot;block&quot; the <code>make docker-up</code> until <code>mysql</code> is actually up and running. In
our case this is not desirable, because we can do &quot;other stuff&quot; in the meantime (namely: run the
<code>qa</code> checks, because they don't require a database) and thus save a couple of seconds on each CI
run.</p>
<!-- generated -->
<p><a id='build-target-ci'> </a></p>
<!-- /generated -->
<h3>Build target: <code>ci</code></h3>
<p>We've already introduced build targets in
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#environments-and-build-targets">Environments and build targets</a>
and how to &quot;choose&quot;
them <a href="/blog/docker-from-scratch-for-php-applications-in-2022/#shared-variables-make-env">through <code>make</code> with the <code>ENV</code> variable defined in a shared <code>.make/.env</code> file</a>.
Short recap:</p>
<ul>
<li>create a <code>.make/.env</code> file via <code>make make-init</code> that contains the <code>ENV</code>, e.g. 
<pre><code class="language-makefile">ENV=ci</code></pre></li>
<li>the <code>.make/.env</code> file is included in the main <code>Makefile</code>, making the <code>ENV</code> variables available
to <code>make</code></li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/#make-docker-3">configure a <code>$DOCKER_COMPOSE</code> variable</a>
that passes the <code>ENV</code> as an environment variable, i.e. via
<pre><code class="language-bash">ENV=$(ENV) docker-compose</code></pre></li>
</ul>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/make-init-ci-docker-commands.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/make-init-ci-docker-commands.PNG" alt="Initialize make to run docker commands with ENV=ci" /></a></p>
<ul>
<li>use the <code>ENV</code> variable in the <code>docker compose</code> configuration file to determine the
<code>build.target</code> property. E.g. in <code>.docker/docker-compose/docker-compose-php-base.yml</code>
<pre><code class="language-yaml">php-base:
  build:
    target: ${ENV?}</code></pre></li>
</ul>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/build-ci-images.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/build-ci-images.PNG" alt="Build images for CI" /></a></p>
<ul>
<li>in the <code>Dockerfile</code> of a service, define the <code>ENV</code> as a build stage. E.g. in
<code>.docker/images/php/base/Dockerfile</code>
<pre><code class="language-Dockerfile">FROM base as ci
# ...</code></pre></li>
</ul>
<p>So to enable the new <code>ci</code> environment, we need to modify the Dockerfiles for the <code>php-base</code> and
the <code>application</code> image.</p>
<!-- generated -->
<p><a id='build-stage-ci-in-the-php-base-image'> </a></p>
<!-- /generated -->
<h4>Build stage <code>ci</code> in the <code>php-base</code> image</h4>
<!-- generated -->
<p><a id='use-the-whole-codebase-as-build-context'> </a></p>
<!-- /generated -->
<h5>Use the whole codebase as build context</h5>
<p>As mentioned in section <a href="#docker-changes">Docker changes</a> we want to &quot;bake&quot; the codebase into
the <code>ci</code> image of the <code>php-base</code> container. Thus, we must change the <code>context</code> property in
<code>.docker/docker-compose/docker-compose-php-base.yml</code> <strong>to not only use the <code>.docker/</code> directory
but instead the whole codebase</strong>. I.e. &quot;dont use <code>../</code> but <code>../../</code>&quot;:</p>
<pre><code class="language-yaml"># File: .docker/docker-compose/docker-compose-php-base.yml

  php-base:
    build:
      # pass the full codebase to docker for building the image
      context: ../../</code></pre>
<!-- generated -->
<p><a id='build-the-dependencies'> </a></p>
<!-- /generated -->
<h5>Build the dependencies</h5>
<p>The composer dependencies must be set up in the image as well, so we introduce a new stage
stage in <code>.docker/images/php/base/Dockerfile</code>. The most trivial solution would look like this:</p>
<ul>
<li>copy the whole codebase</li>
<li>run <code>composer install</code></li>
</ul>
<pre><code class="language-Dockerfile">FROM base as ci

COPY . /codebase

RUN composer install --no-scripts --no-plugins --no-progress -o</code></pre>
<p>However, this approach has some downsides:</p>
<ul>
<li>if <em>any</em> file in the codebase changes, the <code>COPY . /codebase</code> layer will be invalidated. I.e.
docker could <em>not</em> use the <a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#leverage-build-cache">layer cache</a>
which also means <strong>that every layer afterwards cannot use the cache</strong> as well. In consequence the
<code>composer install</code> would run every time - even when the <code>composer.json</code> file doesn't change.</li>
<li><a href="https://getcomposer.org/doc/06-config.md#cache-dir"><code>composer</code> itself uses a cache</a> for
storing dependencies locally so it doesn't have to download dependencies that haven't changed.
But since we run <code>composer install</code> <em>in Docker</em>, this cache would be &quot;thrown away&quot; every time
a build finishes. To mitigate that, we can use
<a href="https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/syntax.md#run---mounttypecache"><code>--mount=type=cache</code></a>
to define a directory that docker will re-use between builds:
<blockquote>
<p>Contents of the cache directories persists between builder invocations without invalidating
the instruction cache.</p>
</blockquote></li>
</ul>
<p>Keeping those points in mind, we end up with the following instructions:</p>
<pre><code class="language-Dockerfile"># File: .docker/images/php/base/Dockerfile
# ...

FROM base as ci

# By only copying the composer files required to run composer install
# the layer will be cached and only invalidated when the composer dependencies are changed
COPY ./composer.json /dependencies/
COPY ./composer.lock /dependencies/

# use a cache mount to cache the composer dependencies
# this is essentially a cache that lives in Docker BuildKit (i.e. has nothing to do with the host system) 
RUN --mount=type=cache,target=/tmp/.composer \
    cd /dependencies &amp;&amp; \
    # COMPOSER_HOME=/tmp/.composer sets the home directory of composer that
    # also controls where composer looks for the cache 
    # so we don't have to download dependencies again (if they are cached)
    COMPOSER_HOME=/tmp/.composer composer install --no-scripts --no-plugins --no-progress -o 

# copy the full codebase
COPY . /codebase

RUN mv /dependencies/vendor /codebase/vendor &amp;&amp; \
    cd /codebase &amp;&amp; \
    # remove files we don't require in the image to keep the image size small
    rm -rf .docker/ &amp;&amp; \
    # we need a git repository for git-secret to work (can be an empty one)
    git init</code></pre>
<p>FYI: The <code>COPY . /codebase</code> step doesn't actually copy &quot;everything in the repository&quot;, because we
have also introduced a <code>.dockerignore</code> file to exclude some files from being included in the
build context - see section <a href="#dockerignore"><code>.dockerignore</code></a>.</p>
<p>Some notes on the final <code>RUN</code> step:</p>
<ul>
<li><code>rm -rf .docker/</code> doesn't really save &quot;that much&quot; in the current setup - please take it more
as an example to remove any files that shouldn't end up in the final image (e.g. &quot;tests in a
production image&quot;)</li>
<li>the <code>git init</code> part is required because we need to decrypt the secrets later - and
<code>git-secret</code> requires a <code>git</code> repository (which can be empty). We can't decrypt the secrets
during the build, because we do not want decrypted secret files to end up in the image.</li>
</ul>
<p>When tested locally, the difference between the trivial solution and the one that makes use of
layer caching is ~35 seconds, see the results in the <a href="#performance">Performance</a> section.</p>
<!-- generated -->
<p><a id='create-the-final-image'> </a></p>
<!-- /generated -->
<h5>Create the final image</h5>
<p>As a final step, we will rename the current stage to <code>codebase</code> and copy the &quot;build
artifact&quot; from that stage into our final <code>ci</code> build stage:</p>
<pre><code class="language-Dockerfile">FROM base as codebase

# build the composer dependencies and clean up the copied files
# ...

FROM base as ci

COPY --from=codebase --chown=$APP_USER_NAME:$APP_GROUP_NAME /codebase $APP_CODE_PATH</code></pre>
<p>Why are we not just using the previous stage directly as <code>ci</code>? </p>
<p>Because using <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multistage-builds</a>
is a
<a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#use-multi-stage-builds">good practice to keep the final layers of an image to a minimum</a>:
Everything that &quot;happened&quot; in the previous <code>codebase</code> stage will be &quot;forgotten&quot;, i.e. not
exported as layers. </p>
<p>That does not only save us some layers, but also allows us to get rid of
files like the <code>.docker/</code> directory. We needed that directory in the build context because
some files where required in other parts of the <code>Dockerfile</code> (e.g. the php ini files), so we
can't exclude it via <code>.dockerignore</code>. But we can remove it in the <code>codebase</code> stage - so it will NOT
be copied over and thus not end up in the final image. If we wouldn't have the <code>codebase</code> stage,
the folder would be part of the layer created when <code>COPY</code>ing all the files from the build context
and removing it via <code>rm -rf .docker/</code> would have no effect on the image size.</p>
<p>Currently, that doesn't really matter, because the building step is super simple (just a
<code>composer install</code>) - but in a growing and more complex codebase you can easily
save a couple MB.</p>
<p>To be concrete, the <strong>multistage build has 31 layers</strong> and the final layer containing the
codebase has a size of <strong>65.1MB</strong>.</p>
<pre><code class="language-text">$ docker image history -H dofroscra/application-ci
IMAGE          CREATED          CREATED BY                                      SIZE      COMMENT
d778c2ee8d5e   17 minutes ago   COPY /codebase /var/www/app # buildkit          65.1MB    buildkit.dockerfile.v0
                                                                                ^^^^^^
&lt;missing&gt;      17 minutes ago   WORKDIR /var/www/app                            0B        buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   COPY /usr/bin/composer /usr/local/bin/compos   2.36MB    buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   COPY ./.docker/images/php/base/.bashrc /root   395B      buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   COPY ./.docker/images/php/base/.bashrc /home   395B      buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   COPY ./.docker/images/php/base/conf.d/zz-app   196B      buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   COPY ./.docker/images/php/base/conf.d/zz-app   378B      buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    1.28kB    buildkit.dockerfile.v0
&lt;missing&gt;      17 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    41MB      buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ADD https://php.hernandev.com/key/php-alpine   451B      buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    62.1MB    buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ADD https://gitsecret.jfrog.io/artifactory/a   450B      buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    4.74kB    buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV ENV=ci                                      0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV ALPINE_VERSION=3.15                         0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV TARGET_PHP_VERSION=8.1                      0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV APP_CODE_PATH=/var/www/app                  0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV APP_GROUP_NAME=application                  0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV APP_USER_NAME=application                   0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV APP_GROUP_ID=10001                          0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ENV APP_USER_ID=10000                           0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG ENV                                         0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG ALPINE_VERSION                              0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG TARGET_PHP_VERSION                          0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG APP_CODE_PATH                               0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG APP_GROUP_NAME                              0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG APP_USER_NAME                               0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG APP_GROUP_ID                                0B        buildkit.dockerfile.v0
&lt;missing&gt;      18 minutes ago   ARG APP_USER_ID                                 0B        buildkit.dockerfile.v0
&lt;missing&gt;      2 days ago       /bin/sh -c #(nop)  CMD ["/bin/sh"]              0B
&lt;missing&gt;      2 days ago       /bin/sh -c #(nop) ADD file:5d673d25da3a14ce1   5.57MB</code></pre>
<p>The <strong>non-multistage build has 32 layers</strong> and the final layer(s) containing the
codebase have a combined size of <strong>65.15MB</strong> (60.3MB + 4.85MB).</p>
<pre><code class="language-text">$ docker image history -H dofroscra/application-ci
IMAGE          CREATED          CREATED BY                                      SIZE      COMMENT
94ba50438c9a   2 minutes ago    RUN /bin/sh -c COMPOSER_HOME=/tmp/.composer    60.3MB    buildkit.dockerfile.v0
&lt;missing&gt;      2 minutes ago    COPY . /var/www/app # buildkit                  4.85MB    buildkit.dockerfile.v0
                                                                                ^^^^^^
&lt;missing&gt;      31 minutes ago   WORKDIR /var/www/app                            0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   COPY /usr/bin/composer /usr/local/bin/compos   2.36MB    buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   COPY ./.docker/images/php/base/.bashrc /root   395B      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   COPY ./.docker/images/php/base/.bashrc /home   395B      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   COPY ./.docker/images/php/base/conf.d/zz-app   196B      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   COPY ./.docker/images/php/base/conf.d/zz-app   378B      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    1.28kB    buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    41MB      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ADD https://php.hernandev.com/key/php-alpine   451B      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    62.1MB    buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ADD https://gitsecret.jfrog.io/artifactory/a   450B      buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   RUN |8 APP_USER_ID=10000 APP_GROUP_ID=10001    4.74kB    buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV ENV=ci                                      0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV ALPINE_VERSION=3.15                         0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV TARGET_PHP_VERSION=8.1                      0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV APP_CODE_PATH=/var/www/app                  0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV APP_GROUP_NAME=application                  0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV APP_USER_NAME=application                   0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV APP_GROUP_ID=10001                          0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ENV APP_USER_ID=10000                           0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG ENV                                         0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG ALPINE_VERSION                              0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG TARGET_PHP_VERSION                          0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG APP_CODE_PATH                               0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG APP_GROUP_NAME                              0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG APP_USER_NAME                               0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG APP_GROUP_ID                                0B        buildkit.dockerfile.v0
&lt;missing&gt;      31 minutes ago   ARG APP_USER_ID                                 0B        buildkit.dockerfile.v0
&lt;missing&gt;      2 days ago       /bin/sh -c #(nop)  CMD ["/bin/sh"]              0B
&lt;missing&gt;      2 days ago       /bin/sh -c #(nop) ADD file:5d673d25da3a14ce1   5.57MB</code></pre>
<p>Again: It is expected that the differences aren't big, because the only size savings come from
the <code>.docker/</code> directory with a size of ~70kb.</p>
<pre><code class="language-text">$ du -hd 0 .docker
73K     .docker</code></pre>
<p>Finally, we are also using the <a href="https://docs.docker.com/engine/reference/builder/#copy"><code>--chown</code> option of the <code>RUN</code> instruction</a>
to ensure that the files have the correct permissions.</p>
<!-- generated -->
<p><a id='build-stage-ci-in-the-application-image'> </a></p>
<!-- /generated -->
<h4>Build stage <code>ci</code> in the <code>application</code> image</h4>
<p>There is actually &quot;nothing&quot; to be done here. We don't need SSH any longer because it is only
required for the <a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/#ssh-configuration">SSH Configuration of PhpStorm</a>.
So the build stage is simply &quot;empty&quot;:</p>
<pre><code class="language-Dockerfile">ARG BASE_IMAGE
FROM ${BASE_IMAGE} as base

FROM base as ci

FROM base as local
# ...</code></pre>
<p>Though there is one thing to keep in mind: In the <code>local</code> image we used <code>sshd</code> as the entrypoint,
i.e. we had a long running process that would keep the container running. To keep the
<code>ci</code> application container running, we must</p>
<ul>
<li>start it via the <code>-d</code> flag of <code>docker compose</code> (already done in the <code>make docker-up</code> target)
<pre><code class="language-makefile">.PHONY: docker-up
docker-up: validate-docker-variables
    $(DOCKER_COMPOSE) up -d $(DOCKER_SERVICE_NAME) </code></pre></li>
<li><a href="https://stackoverflow.com/a/55953120">allocate a <code>tty</code> via <code>tty: true</code></a>
in the <code>docker-compose.local.ci.yml</code> file
<pre><code class="language-yaml">application:
  tty: true</code></pre></li>
</ul>
<!-- generated -->
<p><a id='dockerignore'> </a></p>
<!-- /generated -->
<h3>.dockerignore</h3>
<p>The <a href="https://docs.docker.com/engine/reference/builder/#dockerignore-file"><code>.dockerignore</code> file</a>
is located in the root of the repository and ensures that certain files are kept out of the
Docker <code>build context</code>. This will </p>
<ul>
<li>speed up the build (because less files need to be transmitted to the docker daemon)</li>
<li>keep images smaller (because irrelevant files are kept out of the image)</li>
</ul>
<p>The syntax is quite similar to the <code>.gitignore</code> file - in fact I've found it to be quite often
the case that the contents of the <code>.gitignore</code> file are a subset of the <code>.dockerignore</code> file. This
makes kinda sense, because you <strong>typically wouldn't want files that are excluded from the
repository to end up in a docker image</strong> (e.g. unencrypted secret files). This has also been
noticed by others, see e.g.</p>
<ul>
<li><a href="https://www.reddit.com/r/docker/comments/evrfgp/any_way_to_copy_gitignore_contents_to_dockerignore/">Reddit: Any way to copy .gitignore contents to .dockerignore</a></li>
<li><a href="https://stackoverflow.com/q/58707272/413531">SO: Should .dockerignore typically be a superset of .gitignore?</a></li>
</ul>
<p>but to my knowledge there is currently (2022-04-24) no way to &quot;keep the two files in sync&quot;.</p>
<p>In our case, the content of the <code>.dockerignore</code> file looks like this:</p>
<pre><code class="language-.docker"># gitignore
!.env.example
.env
.idea
.phpunit.result.cache
vendor/
secret.gpg
.gitsecret/keys/random_seed
.gitsecret/keys/pubring.kbx~
!*.secret
passwords.txt
.build

# additionally ignored files
.git</code></pre>
<!-- generated -->
<p><a id='makefile-changes'> </a></p>
<!-- /generated -->
<h2>Makefile changes</h2>
<!-- generated -->
<p><a id='initialize-the-shared-variables'> </a></p>
<!-- /generated -->
<h3>Initialize the shared variables</h3>
<p>We have introduced the concept of <a href="/blog/docker-from-scratch-for-php-applications-in-2022/#shared-variables-make-env">shared variables via <code>.make/.env</code></a>
previously. It allows us to <strong>define variables in one place</strong> (=single source
of truth) that are then used as &quot;defaults&quot; so we <strong>don't have to define them explicitly</strong> when
invoking certain <code>make</code> targets (like <code>make docker-build</code>). We'll make use of this concept by
setting the environment to <code>ci</code>via<code>ENV=ci</code> and thus making sure that all docker commands use
<code>ci</code> &quot;automatically&quot; as well.</p>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/make-init-ci-docker-commands.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/make-init-ci-docker-commands.PNG" alt="Initialize make to run docker commands with ENV=ci" /></a></p>
<p>In addition, I made a small modification by <strong>introducing a second file at <code>.make/variables.env</code></strong>
that is also included in the main <code>Makefile</code> and <strong>holds the &quot;default&quot; shared variables</strong>. Those
are neither &quot;secret&quot; nor are they likely to be be changed for environment adjustments. The file
is NOT ignored by <code>.gitignore</code> and is basically just the previous <code>.make/.env.example</code> file without
the environment specific variables:</p>
<pre><code class="language-text"># File .make/variables.env

DOCKER_REGISTRY=docker.io
DOCKER_NAMESPACE=dofroscra
APP_USER_NAME=application
APP_GROUP_NAME=application</code></pre>
<p>The <code>.make/.env</code> file is still <code>.gitignore</code>d and can be initialized with the <code>make-init</code>
target using the <code>ENVS</code> variable:</p>
<pre><code class="language-bash">make make-init ENVS="ENV=ci SOME_OTHER_DEFAULT_VARIABLE=foo"</code></pre>
<p>which would create a <code>.make/.env</code> file with the content</p>
<pre><code>ENV=ci
SOME_OTHER_DEFAULT_VARIABLE=foo</code></pre>
<p>If necessary, we could also <strong>override variables defined in the <code>.make/variables.env</code> file</strong>,
because the <code>.make/.env</code> is included last in the <code>Makefile</code>:</p>
<pre><code class="language-makefile"># File: Makefile
# ...

# include the default variables
include .make/variables.env
# include the local variables
-include .make/.env</code></pre>
<p>The default value for <code>ENVS</code> is <code>ENV=local TAG=latest</code> to retain the same default behavior as
before when <code>ENVS</code> is omitted. The corresponding <code>make-init</code> target is defined in the main
<code>Makefile</code> and now looks like this:</p>
<pre><code class="language-makefile">ENVS?=ENV=local TAG=latest
.PHONY: make-init
make-init: ## Initializes the local .makefile/.env file with ENV variables for make. Use via ENVS="KEY_1=value1 KEY_2=value2"
    @$(if $(ENVS),,$(error ENVS is undefined))
    @rm -f .make/.env
    for variable in $(ENVS); do \
      echo $$variable | tee -a .make/.env &gt; /dev/null 2&gt;&amp;1; \
    done
    @echo "Created a local .make/.env file" </code></pre>
<!-- generated -->
<p><a id='env-based-docker-compose-config'> </a></p>
<!-- /generated -->
<h3>ENV based docker compose config</h3>
<p>As mentioned in section <a href="#compose-file-updates">Compose file updates</a> we need to select the
&quot;correct&quot; <code>docker compose</code> configuration files based on the <code>ENV</code> value. This is done in
<code>.make/02-00-docker.mk</code>:</p>
<pre><code class="language-makefile"># File .make/02-00-docker.mk

# ...

DOCKER_COMPOSE_DIR:=...
DOCKER_COMPOSE_COMMAND:=...

DOCKER_COMPOSE_FILE_LOCAL_CI:=$(DOCKER_COMPOSE_DIR)/docker-compose.local.ci.yml
DOCKER_COMPOSE_FILE_CI:=$(DOCKER_COMPOSE_DIR)/docker-compose.ci.yml
DOCKER_COMPOSE_FILE_LOCAL:=$(DOCKER_COMPOSE_DIR)/docker-compose.local.yml

# we need to "assemble" the correct combination of docker-compose.yml config files
ifeq ($(ENV),ci)
    DOCKER_COMPOSE_FILES:=-f $(DOCKER_COMPOSE_FILE_LOCAL_CI) -f $(DOCKER_COMPOSE_FILE_CI)
else ifeq ($(ENV),local)
    DOCKER_COMPOSE_FILES:=-f $(DOCKER_COMPOSE_FILE_LOCAL_CI) -f $(DOCKER_COMPOSE_FILE_LOCAL)
endif

DOCKER_COMPOSE:=$(DOCKER_COMPOSE_COMMAND) $(DOCKER_COMPOSE_FILES)</code></pre>
<p>When we now take a look at a full recipe when using <code>ENV=ci</code> with a docker target (e.g.
<code>docker-up</code>), we can see that the correct files are chosen, e.g. </p>
<pre><code class="language-text">$ make docker-up ENV=ci -n
ENV=ci TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker compose -p dofroscra_ci --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.local.ci.yml -f ./.docker/docker-compose/docker-compose.ci.yml up -d

# =&gt;
# -f ./.docker/docker-compose/docker-compose.local.ci.yml 
# -f ./.docker/docker-compose/docker-compose.ci.yml</code></pre>
<p><a href="/img/ci-pipeline-docker-php-gitlab-github/assemble-docker-compose-files.PNG"><img src="/img/ci-pipeline-docker-php-gitlab-github/assemble-docker-compose-files.PNG" alt="Assemble docker-compose config files for CI" /></a></p>
<!-- generated -->
<p><a id='codebase-changes'> </a></p>
<!-- /generated -->
<h2>Codebase changes</h2>
<p><a id='add-a-test-for-encrypted-files'> </a></p>
<!-- /generated -->
<!-- generated -->
<p><a id='add-a-test-for-encrypted-files'> </a></p>
<!-- /generated -->
<h3>Add a test for encrypted files</h3>
<p>We've introduced <code>git-secret</code> in the previous tutorial
<a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
and used it to store the file <code>passwords.txt</code> encrypted in the codebase. To make sure that the
decryption works as expected on the CI systems, I've added a test at
<code>tests/Feature/EncryptionTest.php</code> to check if the file exists and if the content is correct.</p>
<pre><code class="language-php">class EncryptionTest extends TestCase
{
    public function test_ensure_that_the_secret_passwords_file_was_decrypted()
    {
        $pathToSecretFile = __DIR__."/../../passwords.txt";

        $this-&gt;assertFileExists($pathToSecretFile);

        $expected = "my_secret_password\n";
        $actual   = file_get_contents($pathToSecretFile);

        $this-&gt;assertEquals($expected, $actual);
    }
}</code></pre>
<p>Of course this doesn't make sense in a &quot;real world scenario&quot;, because the secret value would now
be exposed in a test - but it suffices for now as proof of a working secret decryption.</p>
<!-- generated -->
<p><a id='add-a-password-protected-secret-gpg-key'> </a></p>
<!-- /generated -->
<h3>Add a password-protected secret <code>gpg</code> key</h3>
<p>I've mentioned in
<a href="/blog/git-secret-encrypt-repository-docker/#decrypt-files">Scenario: Decrypt file</a>
that it is also possible <strong>to use a password-protected secret <code>gpg</code> key for
an additional layer of security</strong>. I have created such a key and stored it in the repository at
<code>secret-protected.gpg.example</code> (in a &quot;real world scenario&quot; I wouldn't do that - but since this
is a public tutorial I want you to be able to follow along completely). The password for that
key is <code>12345678</code>.</p>
<p>The corresponding public key is located at <code>.dev/gpg-keys/alice-protected-public.gpg</code> and
belongs to the email address <code>alice.protected@example.com</code>. I've
<a href="/blog/git-secret-encrypt-repository-docker/#adding-new-team-members">added this address</a> and
<a href="/blog/git-secret-encrypt-repository-docker/#adding-and-encrypting-files">re-encrypted the secrets</a> afterwards via</p>
<pre><code class="language-bash">make gpg-init
make secret-add-user EMAIL="alice.protected@example.com"
make secret-encrypt</code></pre>
<p>When I now import the <code>secret-protected.gpg.example</code> key, I can decrypt the secrets, though I
cannot use the usual <code>secret-decrypt</code> target but must instead use <code>secret-decrypt-with-password</code></p>
<pre><code class="language-bash">make secret-decrypt-with-password GPG_PASSWORD=12345678</code></pre>
<p>or store the <code>GPG_PASSWORD</code> in the <code>.make/.env</code> file when it is initialized for CI</p>
<pre><code class="language-bash">make make-init ENVS="ENV=ci TAG=latest EXECUTE_IN_CONTAINER=true GPG_PASSWORD=12345678"
make secret-decrypt-with-password</code></pre>
<!-- generated -->
<p><a id='create-a-junit-report-from-phpunit'> </a></p>
<!-- /generated -->
<h3>Create a JUnit report from PhpUnit</h3>
<p>I've added the
<a href="https://phpunit.readthedocs.io/en/9.5/textui.html?highlight=junit#command-line-options"><code>--log-junit</code> option</a>
to the <code>phpunit</code> configuration of the <code>test</code> make target in order to create an XML report in the
<code>.build/</code> directory in the <code>.make/01-02-application-qa.mk</code> file:</p>
<pre><code class="language-makefile"># File: .make/01-02-application-qa.mk
# ...

PHPUNIT_CMD=php vendor/bin/phpunit
PHPUNIT_ARGS= -c phpunit.xml --log-junit .build/report.xml</code></pre>
<p>I.e. each run of the tests will now create a
<a href="https://stackoverflow.com/questions/442556/spec-for-junit-xml-output">Junit XML report</a> at
<code>.build/report.xml</code>. The file is used as an example of a build artifact, i.e.
&quot;something that we would like to keep&quot; from a CI run.</p>
<!-- generated -->
<p><a id='wrapping-up'> </a></p>
<!-- /generated -->
<h2>Wrapping up</h2>
<p>Congratulations, you made it! If some things are not completely clear by now, don't hesitate to
leave a comment. You should now have a working CI pipeline for Github (via Github Actions)
and/or Gitlab (via Gitlab pipelines) that runs automatically on each push.</p>
<p>In the next part of this tutorial, we will use terraform to create an infrastructure for
production deployments on GCP and deploy the docker containers there.</p>
<p>Please subscribe to the <a href="/feed.xml">RSS feed</a> or <a href="#newsletter">via email</a> to get automatic
notifications when this next part comes out :)</p>]]></description>
                <pubDate>Mon, 25 Apr 2022 07:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/blog/ci-pipeline-docker-php-gitlab-github/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/blog/ci-pipeline-docker-php-gitlab-github/</guid>
            </item>
                    <item>
                <title>Use git-secret to encrypt secrets in the repository [Tutorial Part 6]</title>
                <description><![CDATA[<p>In the sixth part of this tutorial series on developing PHP on Docker we will <strong>setup <code>git-secret</code>
to store secrets directly in the repository</strong>. Everything will be handled through Docker and
added as make targets for a convenient workflow.</p>
<p><a href="/img/git-secret-encrypt-repository-docker/git-secret-example.gif"><img src="/img/git-secret-encrypt-repository-docker/git-secret-example.gif" alt="git-secret example" title="git-secret example" /></a></p>
<p><small>
FYI:
This tutorial is a precursor to the next a part
<a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
because dealing with secrets is an important aspect when setting up a CI system (and later when
deploying to production) - but I feel it's complex enough to warrant its own article.
</small></p>
<p>All code samples are publicly available in my
<a href="https://github.com/paslandau/docker-php-tutorial">Docker PHP Tutorial repository on github</a>.<br />
You find the branch with the final result of this tutorial at
<a href="https://github.com/paslandau/docker-php-tutorial/tree/git-secret-encrypt-repository-docker">part-6-git-secret-encrypt-repository-docker</a>.</p>
<!-- generated -->
<p><a id='published-parts-of-the-docker-php-tutorial'> </a></p>
<!-- /generated -->
<h2>Published parts of the Docker PHP Tutorial</h2>
<ul>
<li><a href="/blog/php-php-fpm-and-nginx-on-docker-in-windows-10/">Setting up PHP, PHP-FPM and NGINX for local development on Docker</a>
(2018-07-08)</li>
<li><a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
(2018-08-06)</li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
(2019-05-20)</li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
(2022-03-21)</li>
<li><a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>
(2022-03-22)</li>
<li><a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>
(2022-03-23)</li>
<li><a href="/blog/php-qa-tools-make-docker/">Set up PHP QA tools and control them via make</a>
(2022-04-25)</li>
<li><a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
(2022-04-25)</li>
<li><a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
(2022-04-25)</li>
</ul>
<p>If you want to follow along, please subscribe to the <a href="/feed.xml">RSS feed</a>
or <a href="#newsletter">via email</a>
to get automatic notifications when the next part comes out :)</p>
<!-- generated -->
<p><a id='table-of-contents'> </a></p>
<!-- /generated -->
<h2>Table of contents</h2>
<!-- toc -->
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#tooling">Tooling</a>
<ul>
<li><a href="#gpg">gpg</a>
<ul>
<li><a href="#gpg-installation">gpg installation</a></li>
<li><a href="#gpg-usage">gpg usage</a>
<ul>
<li><a href="#create-gpg-key-pair">Create GPG key pair</a></li>
<li><a href="#export-list-and-import-private-gpg-keys">Export, list and import private GPG keys</a></li>
<li><a href="#export-list-and-import-public-gpg-keys">Export, list and import public GPG keys</a></li>
</ul></li>
</ul></li>
<li><a href="#git-secret">git-secret</a>
<ul>
<li><a href="#git-secret-installation">git-secret installation</a></li>
<li><a href="#git-secret-usage">git-secret usage</a>
<ul>
<li><a href="#initialize-git-secret">Initialize git-secret</a>
<ul>
<li><a href="#the-git-secret-directory-and-the-gpg-agent-socket">The <code>git-secret</code> directory and the <code>gpg-agent</code> socket</a></li>
</ul></li>
<li><a href="#adding-listing-and-removing-users">Adding, listing and removing users</a>
<ul>
<li><a href="#reminder-rotate-the-encrypted-secrets">Reminder: Rotate the encrypted secrets</a></li>
</ul></li>
<li><a href="#adding-listing-and-removing-files-for-encryption">Adding, listing and removing files for encryption</a></li>
<li><a href="#encrypt-files">Encrypt files</a></li>
<li><a href="#decrypting-files">Decrypting files</a></li>
<li><a href="#show-changes-between-encrypted-and-decrypted-files">Show changes between encrypted and decrypted files</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#makefile-adjustments">Makefile adjustments</a></li>
<li><a href="#workflow">Workflow</a>
<ul>
<li><a href="#process-challenges">Process challenges</a>
<ul>
<li><a href="#updating-secrets">Updating secrets</a></li>
<li><a href="#code-reviews-and-merge-conflicts">Code reviews and merge conflicts</a></li>
<li><a href="#local-git-secret-and-gpg-setup">Local <code>git-secret</code> and <code>gpg</code> setup</a></li>
</ul></li>
<li><a href="#scenarios">Scenarios</a>
<ul>
<li><a href="#initial-setup-of-gpg-keys">Initial setup of <code>gpg</code> keys</a></li>
<li><a href="#initial-setup-of-git-secret">Initial setup of <code>git-secret</code></a></li>
<li><a href="#initialize-gpg-after-container-startup">Initialize <code>gpg</code> after container startup</a></li>
<li><a href="#adding-new-team-members">Adding (new) team members</a></li>
<li><a href="#adding-and-encrypting-files">Adding and encrypting files</a></li>
<li><a href="#decrypt-files">Decrypt files</a></li>
<li><a href="#removing-files">Removing files</a></li>
<li><a href="#removing-team-members">Removing team members</a></li>
</ul></li>
</ul></li>
<li><a href="#pros-and-cons">Pros and cons</a>
<ul>
<li><a href="#pro">Pro</a></li>
<li><a href="#cons">Cons</a></li>
</ul></li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
<!-- /toc -->
<!-- generated -->
<p><a id='introduction'> </a></p>
<!-- /generated -->
<h2>Introduction</h2>
<p>Dealing with secrets (passwords, tokens, key files, etc.) is close to &quot;naming things&quot;
when it comes to hard problems in software engineering. Some things to consider:</p>
<ul>
<li><strong>security is paramount</strong> - but high security often goes hand in hand with high inconvenience
<ul>
<li>and if things get too complicated, people look for shortcuts...</li>
</ul></li>
<li>in a team, <strong>sharing certain secret values</strong> is often mandatory
<ul>
<li>so now we need to think about secure ways to distribute and update secrets across multiple
people</li>
</ul></li>
<li>concrete secret values often <strong>depend on the environment</strong>
<ul>
<li>inherently tricky to &quot;test&quot; or even &quot;review&quot;, because those values are &quot;by definition&quot;
different on &quot;your machine&quot; than on &quot;production&quot;</li>
</ul></li>
</ul>
<p>In fact, entire products have been build around dealing with secrets, e.g.
<a href="https://www.vaultproject.io/">HashiCorp Vault</a>,
<a href="https://aws.amazon.com/secrets-manager/">AWS Secrets Manager</a> or the
<a href="https://cloud.google.com/secret-manager">GCP Secret Manager</a>. Introducing those in a project comes
with a certain overhead as it's yet another service that needs to be integrated and<br />
maintained. Maybe it is the exactly right decision for your use-case - maybe it's overkill.
By the end of this article you'll at least be aware of an alternative with a lower barrier to entry.
See also the <a href="#pros-and-cons">Pros and cons</a> section in the end for an overview.</p>
<p>Even though it's
<a href="https://withblue.ink/2021/05/07/storing-secrets-and-passwords-in-git-is-bad.html">generally not advised to store secrets in a repository</a>,
I'll propose exactly that in this tutorial:</p>
<ul>
<li>identify files that contain secret values</li>
<li>make sure they are added to <code>.gitignore</code></li>
<li>encrypt them via <code>git-secret</code></li>
<li>commit the encrypted files to the repository</li>
</ul>
<p>In the end, we will be able to call</p>
<pre><code class="language-bash">make secret-decrypt</code></pre>
<p>to reveal secrets in the codebase, make modifications to them if necessary and then run</p>
<pre><code class="language-bash">make secret-encrypt</code></pre>
<p>to encrypt them again so that they can be committed (and pushed to the remote repository). To
see it in action, check out branch
<a href="https://github.com/paslandau/docker-php-tutorial/tree/git-secret-encrypt-repository-docker">part-6-git-secret-encrypt-repository-docker</a>
and run the following commands:</p>
<pre><code class="language-bash"># checkout the branch
git checkout part-6-git-secret-encrypt-repository-docker

# build and start the docker setup
make make-init
make docker-build
make docker-up

# "create" the secret key - the file "secret.gpg.example" would usually NOT live in the repo!
cp secret.gpg.example secret.gpg

# initialize gpg
make gpg-init

# ensure that the decrypted secret file does not exist
ls passwords.txt

# decrypt the secret file
make secret-decrypt

# show the content of the secret file
cat passwords.txt</code></pre>
<!-- generated -->
<p><a id='tooling'> </a></p>
<!-- /generated -->
<h2>Tooling</h2>
<p>We will set up <code>gpg</code> and <code>git-secret</code> in the php <code>base</code> image, so that the tools become available in
all other containers. Please refer to
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
for an in-depth explanation of the docker images.</p>
<div class="panel panel-default">
  <div class="panel-heading">
    <strong>Caution</strong>
  </div>
  <div class="panel-body bg-danger">
    All following commands are 
    <strong>executed <em>in</em> the <code>application</code> container.</strong>
    <br>
    <br>
    <strong>Tip:</strong>
    <br>
    See <a href="/blog/structuring-the-docker-setup-for-php-projects/#easy-container-access-via%20-din-bashrc-helper">Easy container access via din .bashrc helper</a>
    for a convenient shortcut to log into docker containers.
  </div>
</div>
<p>Please note, that there is a caveat when using <code>git-secret</code> in a folder that is shared between
the host system and a docker container. I'll explain that in more detail (including a workaround)
in section
<a href="#the-git-secret-directory-and-the-gpg-agent-socket">The <code>git-secret</code> directory and the <code>gpg-agent</code> socket</a>.</p>
<!-- generated -->
<p><a id='gpg'> </a></p>
<!-- /generated -->
<h3>gpg</h3>
<p><code>gpg</code> is short for <a href="https://gnupg.org/">The GNU Privacy Guard</a> and is an open source implementation
of the OpenPGP standard. In short, it allows us to create a personal key file pair
(similar to SSH keys) with a private secret key and a public
key that can be shared with other parties whose messages you want to decrypt.</p>
<!-- generated -->
<p><a id='gpg-installation'> </a></p>
<!-- /generated -->
<h4>gpg installation</h4>
<p>To install it, we can simply run <code>apk add gnupg</code> and thus update
<code>.docker/images/php/base/Dockerfile</code> accordingly</p>
<pre><code class="language-Dockerfile"># File: .docker/images/php/base/Dockerfile

RUN apk add --update --no-cache \
        bash \
        gnupg \
        make \
#...</code></pre>
<!-- generated -->
<p><a id='gpg-usage'> </a></p>
<!-- /generated -->
<h4>gpg usage</h4>
<p>I'll only cover the strictly necessary <code>gpg</code> commands here. Please refer to
<a href="https://git-secret.io/#using-gpg">the &quot;Using GPG&quot; section in the <code>git-secret</code> docu</a>
and/or <a href="https://linuxhint.com/generate-gpg-keys-gpg/">How to generate PGP keys with GPG</a>
for further information.</p>
<!-- generated -->
<p><a id='create-gpg-key-pair'> </a></p>
<!-- /generated -->
<h5>Create GPG key pair</h5>
<p>We need <code>gpg</code> to <strong>create the gpg key pair</strong> via</p>
<pre><code class="language-bash">name="Pascal Landau"
email="pascal.landau@example.com"
gpg --batch --gen-key &lt;&lt;EOF
Key-Type: 1
Key-Length: 2048
Subkey-Type: 1
Subkey-Length: 2048
Name-Real: $name
Name-Email: $email
Expire-Date: 0
%no-protection
EOF</code></pre>
<p>The <code>%no-protection</code> will create a key without password, see
also <a href="https://gist.github.com/woods/8970150">this gist to &quot;Creating gpg keys non-interactively&quot;</a>.</p>
<p>Output:</p>
<pre><code class="language-text">$ name="Pascal Landau"
$ email="pascal.landau@example.com"
$ gpg --batch --gen-key &lt;&lt;EOF
&gt; Key-Type: 1
&gt; Key-Length: 2048
&gt; Subkey-Type: 1
&gt; Subkey-Length: 2048
&gt; Name-Real: $name
&gt; Name-Email: $email
&gt; Expire-Date: 0
&gt; %no-protection
&gt; EOF
gpg: key E1E734E00B611C26 marked as ultimately trusted
gpg: revocation certificate stored as '/root/.gnupg/opengpg-revocs.d/74082D81525723F5BF5B2099E1E734E00B611C26.rev'</code></pre>
<p>You could also run <code>gpg --gen-key</code> without the <code>--batch</code> flag to be guided interactively through the
process.</p>
<!-- generated -->
<p><a id='export-list-and-import-private-gpg-keys'> </a></p>
<!-- /generated -->
<h5>Export, list and import private GPG keys</h5>
<p>The <strong>private key can be exported</strong> via</p>
<pre><code class="language-bash">email="pascal.landau@example.com"
path="secret.gpg"
gpg --output "$path" --armor --export-secret-key "$email"</code></pre>
<p><strong>This secret key must never be shared</strong>!</p>
<p>It looks like this:</p>
<pre><code class="language-text">-----BEGIN PGP PRIVATE KEY BLOCK-----

lQOYBF7VVBwBCADo9un+SySu/InHSkPDpFVKuZXg/s4BbZmqFtYjvUUSoRAeSejv
G21nwttQGut+F+GdpDJL6W4pmLS31Kxpt6LCAxhID+PRYiJQ4k3inJfeUx7Ws339
XDPO3Rys+CmnZchcEgnbOfQlEqo51DMj6mRF2Ra/6svh7lqhrixGx1BaKn6VlHkC
...
ncIcHxNZt7eK644nWDn7j52HsRi+wcWsZ9mjkUgZLtyMPJNB5qlKQ18QgVdEAhuZ
xT3SieoBPd+tZikhu3BqyIifmLnxOJOjOIhbQrgFiblvzU1iOUOTOcSIB+7A
=YmRm
-----END PGP PRIVATE KEY BLOCK-----</code></pre>
<p>All <strong>secret keys can be listed</strong> via</p>
<pre><code class="language-bash">gpg --list-secret-keys</code></pre>
<p>Output:</p>
<pre><code class="language-text">$ gpg --list-secret-keys
/root/.gnupg/pubring.kbx
------------------------
sec   rsa2048 2022-03-27 [SCEA]
      74082D81525723F5BF5B2099E1E734E00B611C26
uid           [ultimate] Pascal Landau &lt;pascal.landau@example.com&gt;
ssb   rsa2048 2022-03-27 [SEA]
</code></pre>
<p>You can <strong>import the private key</strong> via</p>
<pre><code class="language-bash">path="secret.gpg"
gpg --import "$path"</code></pre>
<p>and get the following output:</p>
<pre><code class="language-text">$ path="secret.gpg"
$ gpg --import "$path"
gpg: key E1E734E00B611C26: "Pascal Landau &lt;pascal.landau@example.com&gt;" not changed
gpg: key E1E734E00B611C26: secret key imported
gpg: Total number processed: 1
gpg:              unchanged: 1
gpg:       secret keys read: 1
gpg:  secret keys unchanged: 1</code></pre>
<p><strong>Caution:</strong> If the secret key requires a password, you would now be prompted for it. We can
circumvent the prompt by using <code>--batch --yes --pinentry-mode loopback</code>:</p>
<pre><code class="language-bash">path="secret.gpg"
gpg --import --batch --yes --pinentry-mode loopback "$path"</code></pre>
<p>See also <a href="https://betakuang.medium.com/using-command-line-passphrase-input-for-gpg-with-git-for-windows-f78ae2c7cd2e">Using Command-Line Passphrase Input for GPG</a>.
In doing so, we don't need to provide the password just yet - but we must pass it later when we
attempt to <a href="#decrypting-files">decrypt files</a>.</p>
<!-- generated -->
<p><a id='export-list-and-import-public-gpg-keys'> </a></p>
<!-- /generated -->
<h5>Export, list and import public GPG keys</h5>
<p>The <strong>public key can be exported</strong> to <code>public.gpg</code> via</p>
<pre><code class="language-bash">email="pascal.landau@example.com"
path="public.gpg"
gpg --armor --export "$email" &gt; "$path"</code></pre>
<p>It looks like this:</p>
<pre><code class="language-text">-----BEGIN PGP PUBLIC KEY BLOCK-----

mQENBF7VVBwBCADo9un+SySu/InHSkPDpFVKuZXg/s4BbZmqFtYjvUUSoRAeSejv
G21nwttQGut+F+GdpDJL6W4pmLS31Kxpt6LCAxhID+PRYiJQ4k3inJfeUx7Ws339
...
3LLbK7Qxz0cV12K7B+n2ei466QAYXo03a7WlsPWn0JTFCsHoCOphjaVsncIcHxNZ
t7eK644nWDn7j52HsRi+wcWsZ9mjkUgZLtyMPJNB5qlKQ18QgVdEAhuZxT3SieoB
Pd+tZikhu3BqyIifmLnxOJOjOIhbQrgFiblvzU1iOUOTOcSIB+7A
=g0hF
-----END PGP PUBLIC KEY BLOCK-----</code></pre>
<p><strong>List all public keys</strong> via</p>
<pre><code class="language-bash">gpg --list-keys</code></pre>
<p>Output:</p>
<pre><code class="language-text">$ gpg --list-keys
/root/.gnupg/pubring.kbx
------------------------
pub   rsa2048 2022-03-27 [SCEA]
      74082D81525723F5BF5B2099E1E734E00B611C26
uid           [ultimate] Pascal Landau &lt;pascal.landau@example.com&gt;
sub   rsa2048 2022-03-27 [SEA]</code></pre>
<p>The <strong>public key can be imported</strong> in the same way as private keys via</p>
<pre><code class="language-bash">path="public.gpg"
gpg --import "$path"</code></pre>
<p>Example:</p>
<pre><code class="language-text">$ gpg --import /var/www/app/public.gpg
gpg: key E1E734E00B611C26: "Pascal Landau &lt;pascal.landau@example.com&gt;" not changed
gpg: Total number processed: 1
gpg:              unchanged: 1</code></pre>
<!-- generated -->
<p><a id='git-secret'> </a></p>
<!-- /generated -->
<h3>git-secret</h3>
<p>The official website of <a href="https://git-secret.io/">git-secret</a> is already doing a great job of
introducing the tool. In short, it allows us to <strong>declare certain files as &quot;secrets&quot;</strong> and <strong>encrypt
them via <code>gpg</code></strong> - using the keys of all trusted parties. The encrypted file can then by <strong>stored
safely directly in the git repository</strong> and <strong>decrypted if required</strong>.</p>
<p>In this tutorial I'm using <code>git-secret v0.4.0</code></p>
<pre><code class="language-text">$ git secret --version
0.4.0</code></pre>
<!-- generated -->
<p><a id='git-secret-installation'> </a></p>
<!-- /generated -->
<h4>git-secret installation</h4>
<p>The <a href="https://git-secret.io/installation#alpine">installation instructions for Alpine</a> read as
follows:</p>
<pre><code class="language-bash">sh -c "echo 'https://gitsecret.jfrog.io/artifactory/git-secret-apk/all/main'" &gt;&gt; /etc/apk/repositories
wget -O /etc/apk/keys/git-secret-apk.rsa.pub 'https://gitsecret.jfrog.io/artifactory/api/security/keypair/public/repositories/git-secret-apk'
apk add --update --no-cache git-secret</code></pre>
<p>We update the <code>.docker/images/php/base/Dockerfile</code> accordingly:</p>
<pre><code class="language-Dockerfile"># File: .docker/images/php/base/Dockerfile

# install git-secret
# @see https://git-secret.io/installation#alpine
ADD https://gitsecret.jfrog.io/artifactory/api/security/keypair/public/repositories/git-secret-apk /etc/apk/keys/git-secret-apk.rsa.pub

RUN echo "https://gitsecret.jfrog.io/artifactory/git-secret-apk/all/main" &gt;&gt; /etc/apk/repositories  &amp;&amp; \
    apk add --update --no-cache \
        bash \
        git-secret \
        gnupg \
        make \
#...</code></pre>
<!-- generated -->
<p><a id='git-secret-usage'> </a></p>
<!-- /generated -->
<h4>git-secret usage</h4>
<!-- generated -->
<p><a id='initialize-git-secret'> </a></p>
<!-- /generated -->
<h5>Initialize git-secret</h5>
<p><code>git-secret</code> is initialized via the following command <em>run in the root of the git repository</em></p>
<pre><code class="language-bash">git secret init</code></pre>
<pre><code class="language-text">$ git secret init
git-secret: init created: '/var/www/app/.gitsecret/'</code></pre>
<p>We only need to do this once, because we'll commit the folder to git later. It contains the
following files:</p>
<pre><code class="language-text">$ git status | grep ".gitsecret"
        new file:   .gitsecret/keys/pubring.kbx
        new file:   .gitsecret/keys/pubring.kbx~
        new file:   .gitsecret/keys/trustdb.gpg
        new file:   .gitsecret/paths/mapping.cfg</code></pre>
<p>The <code>pubring.kbx~</code> file (with the trailing tilde <code>~</code>) is only a temporary file and can safely be
git-ignored. See also
<a href="https://github.com/sobolevn/git-secret/issues/566#issuecomment-570059374">Can't find any docs about keyring.kbx~ file</a>.</p>
<!-- generated -->
<p><a id='the-git-secret-directory-and-the-gpg-agent-socket'> </a></p>
<!-- /generated -->
<h6>The <code>git-secret</code> directory and the <code>gpg-agent</code> socket</h6>
<p>To use <code>git-secret</code> in a directory that is <strong>shared between the host system and docker</strong>, we need to
also run the following commands:</p>
<pre><code class="language-bash">tee .gitsecret/keys/S.gpg-agent &lt;&lt;EOF
%Assuan%
socket=/tmp/S.gpg-agent
EOF

tee .gitsecret/keys/S.gpg-agent.ssh &lt;&lt;EOF
%Assuan%
socket=/tmp/S.gpg-agent.ssh
EOF

tee .gitsecret/keys/gpg-agent.conf &lt;&lt;EOF
extra-socket /tmp/S.gpg-agent.extra
browser-socket /tmp/S.gpg-agent.browser
EOF</code></pre>
<p>This is necessary because there is an issue <strong>when <code>git-secret</code> is used in a setup where the
codebase is shared between the host system and a docker container</strong>.
I've explained the details in the Github issue
<a href="https://github.com/sobolevn/git-secret/issues/806">&quot;gpg: can't connect to the agent: IPC connect call failed&quot; error in docker alpine on shared volume</a>.</p>
<p>In short:</p>
<ul>
<li><code>gpg</code> uses a <code>gpg-agent</code> to perform its tasks and the two tools communicate through sockets
that are created in the <code>--home-directory</code> of the <code>gpg-agent</code></li>
<li>the agent is started implicitly through a <code>gpg</code> command used by <code>git-secret</code>, using the
<code>.gitsecret/keys</code> directories as a <code>--home-directory</code></li>
<li>because the location of the <code>--home-directory</code> is shared with the host system, the socket
creation fails (potentially only an issue for Docker Desktop, see the related discussion in
Github issue <a href="https://github.com/docker/for-mac/issues/483#issuecomment-647325015">Support for sharing unix sockets</a>)</li>
</ul>
<p>The corresponding error messages are</p>
<pre><code class="language-text">gpg: can't connect to the agent: IPC connect call failed

gpg-agent: error binding socket to '/var/www/app/.gitsecret/keys/S.gpg-agent': I/O error</code></pre>
<p>The <strong>workaround for this problem</strong> can be found in
<a href="https://askubuntu.com/a/1053594/1583296">this thread</a>: Configure <code>gpg</code> to use different
locations for the sockets by
<a href="https://github.com/sobolevn/git-secret/issues/806#issuecomment-1084202671">placing additional <code>gpg</code> configuration files in the <code>.gitsecret/keys</code> directory</a>:</p>
<p><strong>S.gpg-agent</strong></p>
<pre><code class="language-text">%Assuan%
socket=/tmp/S.gpg-agent</code></pre>
<p><strong>S.gpg-agent.ssh</strong></p>
<pre><code class="language-text">%Assuan%
socket=/tmp/S.gpg-agent.ssh</code></pre>
<p><strong>gpg-agent.conf</strong></p>
<pre><code class="language-text">extra-socket /tmp/S.gpg-agent.extra
browser-socket /tmp/S.gpg-agent.browser</code></pre>
<!-- generated -->
<p><a id='adding-listing-and-removing-users'> </a></p>
<!-- /generated -->
<h5>Adding, listing and removing users</h5>
<p>To <strong>add a new user</strong>, you must first <a href="#export-list-and-import-public-gpg-keys">import its public gpg key</a>. Then
run:</p>
<pre><code class="language-bash">email="pascal.landau@example.com"
git secret tell "$email"</code></pre>
<p>In this case, the user <code>pascal.landau@example.com</code> will now be able to decrypt the secrets.</p>
<p>To <strong>show the users</strong> run</p>
<pre><code class="language-bash">git secret whoknows</code></pre>
<pre><code class="language-text">$ git secret whoknows
pascal.landau@example.com</code></pre>
<p><strong>To remove a user</strong>, run</p>
<pre><code class="language-bash">email="pascal.landau@example.com"
git secret killperson "$email"</code></pre>
<p>FYI: This command was renamed to <code>removeperson</code> in <code>git-secret &gt;= 0.5.0</code></p>
<pre><code class="language-text">$ git secret killperson pascal.landau@example.com
git-secret: removed keys.
git-secret: now [pascal.landau@example.com] do not have an access to the repository.
git-secret: make sure to hide the existing secrets again.</code></pre>
<p>User <code>pascal.landau@example.com</code> will no longer be able to decrypt the secrets.</p>
<p><strong>Caution: The secrets need to be re-encrypted after removing a user!</strong></p>
<!-- generated -->
<p><a id='reminder-rotate-the-encrypted-secrets'> </a></p>
<!-- /generated -->
<h6>Reminder: Rotate the encrypted secrets</h6>
<p>Please be aware that <strong>not only your secrets are stored in git, but who had access as well</strong>. I.e.
even if you remove a user and re-encrypt the secrets, that user would <strong>still be able to decrypt
the secrets of a previous commit</strong> (when the user was still added). In consequence, <strong>you need
to rotate the encrypted secrets themselves as well after removing a user</strong>.</p>
<p>But isn't that a great flaw in the system, making it a bad idea to use <code>git-secret</code> in general? </p>
<p>In my opinion: No. </p>
<p>If the removed user had access to the secrets at <strong>any</strong> point in time (no
matter where they have been stored), he could very well have just created a local copy or simply
&quot;written them down&quot;. In terms of security there is really no &quot;added downside&quot; due to <code>git-secret</code>.
It just makes it <em>very</em> clear that you <em>must</em> rotate the secrets \_()_/</p>
<p>See also this
<a href="https://news.ycombinator.com/item?id=11663403">lengthy discussion on <code>git-secret</code> on Hacker News</a>.</p>
<!-- generated -->
<p><a id='adding-listing-and-removing-files-for-encryption'> </a></p>
<!-- /generated -->
<h5>Adding, listing and removing files for encryption</h5>
<p>Run <code>git secret add [filenames...]</code> for <strong>files you want to encrypt</strong>. Example:</p>
<pre><code class="language-bash">git secret add .env</code></pre>
<p>If <code>.env</code> is not added in <code>.gitignore</code>, <code>git-secret</code> will display a warning and add it
automatically.</p>
<pre><code class="language-text">git-secret: these files are not in .gitignore: .env
git-secret: auto adding them to .env
git-secret: 1 item(s) added.</code></pre>
<p>Otherwise, the file is added with no warning.</p>
<pre><code class="language-text">$ git secret add .env
git-secret: 1 item(s) added.</code></pre>
<p>You only need to add files once. They are then stored in <code>.gitsecret/paths/mapping.cfg</code>:</p>
<pre><code class="language-text">$ cat .gitsecret/paths/mapping.cfg
.env:505070fc20233cb426eac6a3414399d0f466710c993198b1088e897fdfbbb2d5</code></pre>
<p>You can also show the added files via</p>
<pre><code class="language-bash">git secret list</code></pre>
<pre><code class="language-text">$ git secret list
.env</code></pre>
<p><strong>Caution: The files are not yet encrypted!</strong></p>
<p>If you want to <strong>remove a file from being encrypted</strong>, run</p>
<pre><code class="language-bash">git secret remove .env</code></pre>
<p>Output</p>
<pre><code class="language-text">$ git secret remove .env
git-secret: removed from index.
git-secret: ensure that files: [.env] are now not ignored.</code></pre>
<!-- generated -->
<p><a id='encrypt-files'> </a></p>
<!-- /generated -->
<h5>Encrypt files</h5>
<p>To actually <strong>encrypt the files</strong>, run:</p>
<pre><code class="language-bash">git secret hide</code></pre>
<p>Output:</p>
<pre><code class="language-text">$ git secret hide
git-secret: done. 1 of 1 files are hidden.</code></pre>
<p>The encrypted (binary) file is stored at <code>$filename.secret</code>, i.e. <code>.env.secret</code> in this case:</p>
<pre><code class="language-text">$ cat .env.secret
H~B"FlCsS@MHWse{L s1J$;Za\u&amp; V 6
;&lt;d:}D%.;&amp;GvWW]&gt;;D+RsSY!&amp;J8Ff*$&amp;RC8z hZ0MT&gt;</code></pre>
<p>The encrypted files are de-cryptable <strong>for all users that have been added via <code>git secret tell</code></strong>.
That also means that you need to <strong>run this command again whenever a new user is added</strong>.</p>
<!-- generated -->
<p><a id='decrypting-files'> </a></p>
<!-- /generated -->
<h5>Decrypting files</h5>
<p>You can <strong>decrypt files</strong> via</p>
<pre><code class="language-bash">git secret reveal</code></pre>
<p>Output:</p>
<pre><code class="language-text">$ git secret reveal
File '/var/www/app/.env' exists. Overwrite? (y/N) y
git-secret: done. 1 of 1 files are revealed.</code></pre>
<ul>
<li>the files are decrypted and will overwrite the current, unencrypted files (if they already exist)
<ul>
<li>use the <code>-f</code> option to force the overwrite and run non-interactively</li>
</ul></li>
<li>if you only want to check the content of an encrypted file, you can use
<code>git secret cat $filename</code> (e.g. <code>git secret cat .env</code>)</li>
</ul>
<p>In case the secret <code>gpg</code> key is password protected, you must pass the password
<a href="https://git-secret.io/git-secret-reveal">via the <code>-p</code> option</a>. E.g. for password <code>123456</code></p>
<pre><code class="language-bash">git secret reveal -p 123456</code></pre>
<!-- generated -->
<p><a id='show-changes-between-encrypted-and-decrypted-files'> </a></p>
<!-- /generated -->
<h5>Show changes between encrypted and decrypted files</h5>
<p>One problem that comes with encrypted files: <strong>You can't review them during a code review in a
remote tool</strong>. So in order to understand what changes have been made, it is helpful to
<strong>show the changes between the encrypted and the decrypted files</strong>. This can be done via</p>
<pre><code class="language-bash">git secret changes</code></pre>
<p>Output:</p>
<pre><code class="language-text">$ echo "foo" &gt;&gt; .env
$ git secret changes
git-secret: changes in /var/www/app/.env:
--- /dev/fd/63
+++ /var/www/app/.env
@@ -34,3 +34,4 @@
 MAIL_ENCRYPTION=null
 MAIL_FROM_ADDRESS=null
 MAIL_FROM_NAME="${APP_NAME}"
+foo</code></pre>
<p>Note the <code>+foo</code> at the bottom of the output. It was added in the first line via
<code>echo "foo"&gt; &gt;&gt; .env</code>. </p>
<!-- generated -->
<p><a id='makefile-adjustments'> </a></p>
<!-- /generated -->
<h2>Makefile adjustments</h2>
<p>Since I won't be able to remember all the commands for <code>git-secret</code> and <code>gpg</code>, I've added them to
the Makefile at <code>.make/01-00-application-setup.mk</code>:</p>
<pre><code class="language-makefile"># File: .make/01-00-application-setup.mk

#...

# gpg

DEFAULT_SECRET_GPG_KEY?=secret.gpg
DEFAULT_PUBLIC_GPG_KEYS?=.dev/gpg-keys/*

.PHONY: gpg
gpg: ## Run gpg commands. Specify the command e.g. via ARGS="--list-keys"
    $(EXECUTE_IN_APPLICATION_CONTAINER) gpg $(ARGS)

.PHONY: gpg-export-public-key
gpg-export-public-key: ## Export a gpg public key e.g. via EMAIL="john.doe@example.com" PATH=".dev/gpg-keys/john-public.gpg"
    @$(if $(PATH),,$(error PATH is undefined))
    @$(if $(EMAIL),,$(error EMAIL is undefined))
    "$(MAKE)" -s gpg ARGS="gpg --armor --export $(EMAIL) &gt; $(PATH)"

.PHONY: gpg-export-private-key
gpg-export-private-key: ## Export a gpg private key e.g. via EMAIL="john.doe@example.com" PATH="secret.gpg"
    @$(if $(PATH),,$(error PATH is undefined))
    @$(if $(EMAIL),,$(error EMAIL is undefined))
    "$(MAKE)" -s gpg ARGS="--output $(PATH) --armor --export-secret-key $(EMAIL)"

.PHONY: gpg-import
gpg-import: ## Import a gpg key file e.g. via GPG_KEY_FILES="/path/to/file /path/to/file2"
    @$(if $(GPG_KEY_FILES),,$(error GPG_KEY_FILES is undefined))
    "$(MAKE)" -s gpg ARGS="--import --batch --yes --pinentry-mode loopback $(GPG_KEY_FILES)"

.PHONY: gpg-import-default-secret-key
gpg-import-default-secret-key: ## Import the default secret key
    "$(MAKE)" -s gpg-import GPG_KEY_FILES="$(DEFAULT_SECRET_GPG_KEY)"

.PHONY: gpg-import-default-public-keys
gpg-import-default-public-keys: ## Import the default public keys
    "$(MAKE)" -s gpg-import GPG_KEY_FILES="$(DEFAULT_PUBLIC_GPG_KEYS)" 

.PHONY: gpg-init
gpg-init: gpg-import-default-secret-key gpg-import-default-public-keys ## Initialize gpg in the container, i.e. import all public and private keys

# git-secret

.PHONY: git-secret
git-secret: ## Run git-secret commands. Specify the command e.g. via ARGS="hide"
    $(EXECUTE_IN_APPLICATION_CONTAINER) git-secret $(ARGS)

.PHONY: secret-init
secret-init: ## Initialize git-secret in the repository via `git-secret init`
    "$(MAKE)" -s git-secret ARGS="init"

.PHONY: secret-init-gpg-socket-config
secret-init-gpg-socket-config: ## Initialize the config files to change the gpg socket locations
    echo "%Assuan%" &gt; .gitsecret/keys/S.gpg-agent
    echo "socket=/tmp/S.gpg-agent" &gt;&gt; .gitsecret/keys/S.gpg-agent
    echo "%Assuan%" &gt; .gitsecret/keys/S.gpg-agent.ssh
    echo "socket=/tmp/S.gpg-agent.ssh" &gt;&gt; .gitsecret/keys/S.gpg-agent.ssh
    echo "extra-socket /tmp/S.gpg-agent.extra" &gt; .gitsecret/keys/gpg-agent.conf
    echo "browser-socket /tmp/S.gpg-agent.browser" &gt;&gt; .gitsecret/keys/gpg-agent.conf

.PHONY: secret-encrypt
secret-encrypt: ## Decrypt secret files via `git-secret hide`
    "$(MAKE)" -s git-secret ARGS="hide"

.PHONY: secret-decrypt
secret-decrypt: ## Decrypt secret files via `git-secret reveal -f`
    "$(MAKE)" -s git-secret ARGS="reveal -f" 

.PHONY: secret-decrypt-with-password
secret-decrypt-with-password: ## Decrypt secret files using a password for gpg via `git-secret reveal -f -p $(GPG_PASSWORD)`
    @$(if $(GPG_PASSWORD),,$(error GPG_PASSWORD is undefined))
    "$(MAKE)" -s git-secret ARGS="reveal -f -p $(GPG_PASSWORD)" 

.PHONY: secret-add
secret-add: ## Add a file to git secret via `git-secret add $FILE`
    @$(if $(FILE),,$(error FILE is undefined))
    "$(MAKE)" -s git-secret ARGS="add $(FILE)"

.PHONY: secret-cat
secret-cat: ## Show the contents of file to git secret via `git-secret cat $FILE`
    @$(if $(FILE),,$(error FILE is undefined))
    "$(MAKE)" -s git-secret ARGS="cat $(FILE)"

.PHONY: secret-list
secret-list: ## List all files added to git secret `git-secret list`
    "$(MAKE)" -s git-secret ARGS="list"

.PHONY: secret-remove
secret-remove: ## Remove a file from git secret via `git-secret remove $FILE`
    @$(if $(FILE),,$(error FILE is undefined))
    "$(MAKE)" -s git-secret ARGS="remove $(FILE)"

.PHONY: secret-add-user
secret-add-user: ## Remove a user from git secret via `git-secret tell $EMAIL`
    @$(if $(EMAIL),,$(error EMAIL is undefined))
    "$(MAKE)" -s git-secret ARGS="tell $(EMAIL)"

.PHONY: secret-show-users
secret-show-users: ## Show all users that have access to git secret via `git-secret whoknows`
    "$(MAKE)" -s git-secret ARGS="whoknows"

.PHONY: secret-remove-user
secret-remove-user: ## Remove a user from git secret via `git-secret killperson $EMAIL`
    @$(if $(EMAIL),,$(error EMAIL is undefined))
    "$(MAKE)" -s git-secret ARGS="killperson $(EMAIL)"

.PHONY: secret-diff
secret-diff: ## Show the diff between the content of encrypted and decrypted files via `git-secret changes`
    "$(MAKE)" -s git-secret ARGS="changes"</code></pre>
<!-- generated -->
<p><a id='workflow'> </a></p>
<!-- /generated -->
<h2>Workflow</h2>
<p>Working with <code>git-secret</code> is pretty straight forward:</p>
<ul>
<li>initialize <code>git-secret</code></li>
<li>add all users</li>
<li>add all secret files and make sure they are ignored via <code>.gitignore</code></li>
<li>encrypt the files</li>
<li>commit the encrypted files like &quot;any other file&quot;</li>
<li>if any changes were made by other team members to the files:
<ul>
<li>=&gt; decrypt to get the most up-to-date ones</li>
</ul></li>
<li>if any modifications are required from your side:
<ul>
<li>=&gt; make the changes to the decrypted files and then re-encrypt them again</li>
</ul></li>
</ul>
<p>But: The devil is in the details. The <a href="#process-challenges">Process challenges</a> section explains
some of the pitfalls that we have encountered and the <a href="#scenarios">Scenarios</a> section gives some
concrete examples for common scenarios.</p>
<!-- generated -->
<p><a id='process-challenges'> </a></p>
<!-- /generated -->
<h3>Process challenges</h3>
<p>From a process perspective we've encountered some challenges that I'd like to mention - including
how we deal with them.</p>
<!-- generated -->
<p><a id='updating-secrets'> </a></p>
<!-- /generated -->
<h4>Updating secrets</h4>
<p>When updating secrets you must ensure to always <strong>decrypt the files first</strong> in order to avoid
using &quot;stale&quot; files that you might still have locally. I usually check out the latest <code>main</code>
branch and run <code>git secret reveal</code> to have the most up-to-date versions of the secret files. You
could also use a <a href="https://stackoverflow.com/a/4185449/413531"><code>post-merge</code> git hook</a> to do
this automatically, but I personally don't want to risk overwriting my local secret files by
accident.</p>
<!-- generated -->
<p><a id='code-reviews-and-merge-conflicts'> </a></p>
<!-- /generated -->
<h4>Code reviews and merge conflicts</h4>
<p>Since the <strong>encrypted files cannot be diffed meaningfully</strong>, the code reviews become more difficult
when secrets are involved. We use Gitlab for reviews and I usually first check the diff of
the <code>.gitsecret/paths/mapping.cfg</code> file to see &quot;which files have changed&quot; directly in the UI.</p>
<p>In addition, I will</p>
<ul>
<li>checkout the <code>main</code> branch</li>
<li>decrypt the secrets via <code>git secret reveal -f</code></li>
<li>checkout the <code>feature-branch</code></li>
<li>run <code>git secret changes</code> to see the differences between the decrypted files from <code>main</code> and the
encrypted files from <code>feature-branch</code></li>
</ul>
<p>Things get even more complicated when multiple team members need to modify secret files at the same
time on different branches, as <strong>the encrypted files cannot be compared - i.e. git cannot be smart
about delta updates</strong>.
The only way around this is coordinating the pull requests, i.e. merge the first, update the
secrets of the second and then merge the second.</p>
<p>Fortunately, this has only happened very rarely so far.</p>
<!-- generated -->
<p><a id='local-git-secret-and-gpg-setup'> </a></p>
<!-- /generated -->
<h4>Local <code>git-secret</code> and <code>gpg</code> setup</h4>
<p>Currently, all developers in our team have <code>git-secret</code> installed locally (instead of using it
through docker) and use their own <code>gpg</code> keys.</p>
<p>This means more onboarding overhead, because</p>
<ul>
<li>a new dev must
<ul>
<li>install <code>git-secret</code> locally (*)</li>
<li>install and setup <code>gpg</code> locally (*)</li>
<li>create a <code>gpg</code> key pair</li>
</ul></li>
<li>the public key must be added by every other team member (*)</li>
<li>the user of the key must be added via <code>git secret tell</code></li>
<li>the secrets must be re-encrypted</li>
</ul>
<p>And for offboarding</p>
<ul>
<li>the public key must be removed by every other team member (*)</li>
<li>the user of the key must be removed via <code>git secret killperson</code></li>
<li>the secrets must be re-encrypted</li>
</ul>
<p>Plus, we need to ensure that the <code>git-secret</code> and <code>gpg</code> versions are kept up-to-date for everyone to
not run into any compatibility issues.</p>
<p>As an alternative, I'm currently leaning more towards <strong>handling everything through docker</strong> (as
presented in this tutorial). All steps marked with (*) are then obsolete, i.e. there is no need
to setup <code>git-secret</code> and <code>gpg</code> locally. </p>
<p>But the approach also comes with some downsides, because</p>
<ul>
<li>the <strong>secret key and all public keys have to be imported every time the container is started</strong></li>
<li><strong>each dev needs to put his private <code>gpg</code> key &quot;in the codebase&quot;</strong> (ignored by <code>.gitignore</code>) so it
can be shared with docker and imported by <code>gpg</code> (in docker). The alternative would be using
a single secret key that is   shared within the team - which feels very wrong :P</li>
</ul>
<p>To make this a little more convenient, <strong>we put the public gpg keys of every dev in the
repository</strong> under <code>.dev/gpg-keys/</code> and <strong>the private key has to be named <code>secret.gpg</code> and put
in the root of the codebase</strong>. </p>
<p>In this setup, <code>secret.gpg</code> must also be added to the<code>.gitignore</code> file. </p>
<pre><code class="language-gitignore"># File: .gitignore
#...
vendor/
secret.gpg</code></pre>
<p>The import can now be be simplified with <code>make</code> targets:</p>
<pre><code class="language-makefile"># gpg

DEFAULT_SECRET_GPG_KEY?=secret.gpg
DEFAULT_PUBLIC_GPG_KEYS?=.dev/gpg-keys/*

.PHONY: gpg
gpg: ## Run gpg commands. Specify the command e.g. via ARGS="--list-keys"
    $(EXECUTE_IN_APPLICATION_CONTAINER) gpg $(ARGS)

.PHONY: gpg-import
gpg-import: ## Import a gpg key file e.g. via GPG_KEY_FILES="/path/to/file /path/to/file2"
    @$(if $(GPG_KEY_FILES),,$(error GPG_KEY_FILES is undefined))
    "$(MAKE)" -s gpg ARGS="--import --batch --yes --pinentry-mode loopback $(GPG_KEY_FILES)"

.PHONY: gpg-import-default-secret-key
gpg-import-default-secret-key: ## Import the default secret key
    "$(MAKE)" -s gpg-import GPG_KEY_FILES="$(DEFAULT_SECRET_GPG_KEY)"

.PHONY: gpg-import-default-public-keys
gpg-import-default-public-keys: ## Import the default public keys
    "$(MAKE)" -s gpg-import GPG_KEY_FILES="$(DEFAULT_PUBLIC_GPG_KEYS)" 

.PHONY: gpg-init
gpg-init: gpg-import-default-secret-key gpg-import-default-public-keys ## Initialize gpg in the container, i.e. import all public and private keys</code></pre>
<p>&quot;Everything&quot; can now be handled via </p>
<pre><code class="language-bash">make gpg-init</code></pre>
<p>that needs to be run one single time after a container has been started. </p>
<!-- generated -->
<p><a id='scenarios'> </a></p>
<!-- /generated -->
<h3>Scenarios</h3>
<p>The scenarios assume the following preconditions:</p>
<ul>
<li>You have checked out branch <a href="https://github.com/paslandau/docker-php-tutorial/tree/git-secret-encrypt-repository-docker">part-6-git-secret-encrypt-repository-docker</a>
<pre><code class="language-bash">git checkout part-6-git-secret-encrypt-repository-docker</code></pre>
<p>and no running docker containers </p>
<pre><code class="language-bash">make docker-down</code></pre></li>
<li>You have deleted the existing <code>git-secret</code> folder, the keys in <code>.dev/gpg-keys</code>, the
<code>secret.gpg</code> key and the <code>passwords.*</code> files 
<pre><code class="language-bash">rm -rf .gitsecret/ .dev/gpg-keys/* secret.gpg passwords.*</code></pre></li>
</ul>
<!-- generated -->
<p><a id='initial-setup-of-gpg-keys'> </a></p>
<!-- /generated -->
<h4>Initial setup of <code>gpg</code> keys</h4>
<p>Unfortunately, I didn't find a way to create and export <code>gpg</code> keys through <code>make</code> and <code>docker</code>. You
need to either run the commands interactively OR pass a string with newlines to it. Both things are
horribly complicated with <code>make</code> and docker. Thus, you need to log into the <code>application</code>
container and run the commands in there directly. Not great - but this needs to be done only
once when a new developer is onboarded anyways.</p>
<p>FYI: I usually log into containers via
<a href="/blog/structuring-the-docker-setup-for-php-projects/#easy-container-access-via-din-bashrc-helper">Easy container access via din .bashrc helper</a>.</p>
<p>The secret key is exported to <code>secret.gpg</code> and the public key to <code>.dev/gpg-keys/alice-public.gpg</code>.</p>
<pre><code class="language-bash"># start the docker setup
make docker-up

# log into the container ('winpty' is only required on Windows)
winpty docker exec -ti dofroscra_local-application-1 bash

# export key pair
name="Alice Doe"
email="alice@example.com"
gpg --batch --gen-key &lt;&lt;EOF
Key-Type: 1
Key-Length: 2048
Subkey-Type: 1
Subkey-Length: 2048
Name-Real: $name
Name-Email: $email
Expire-Date: 0
%no-protection
EOF

# export the private key
gpg --output secret.gpg --armor --export-secret-key $email

# export the public key
gpg --armor --export $email &gt; .dev/gpg-keys/alice-public.gpg</code></pre>
<pre><code class="language-text">$ make docker-up
ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml up -d
Container dofroscra_local-application-1  Created
...
Container dofroscra_local-application-1  Started
$ docker ps
CONTAINER ID   IMAGE                                COMMAND                  CREATED          STATUS          PORTS                NAMES
...
95f740607586   dofroscra/application-local:latest   "/usr/sbin/sshd -D"      21 minutes ago   Up 21 minutes   0.0.0.0:2222-&gt;22/tcp dofroscra_local-application-1

$ winpty docker exec -ti dofroscra_local-application-1 bash
root:/var/www/app# name="Alice Doe"
root:/var/www/app# email="alice@example.com"
gpg --batch --gen-key &lt;&lt;EOF
Key-Type: 1
Key-Length: 2048
Subkey-Type: 1
Subkey-Length: 2048
Name-Real: $name
Name-Email: $email
Expire-Date: 0
%no-protection
EOF
root:/var/www/app# gpg --batch --gen-key &lt;&lt;EOF
&gt; Key-Type: 1
&gt; Key-Length: 2048
&gt; Subkey-Type: 1
&gt; Subkey-Length: 2048
&gt; Name-Real: $name
&gt; Name-Email: $email
&gt; Expire-Date: 0
&gt; %no-protection
&gt; EOF
gpg: directory '/root/.gnupg' created
gpg: keybox '/root/.gnupg/pubring.kbx' created
gpg: /root/.gnupg/trustdb.gpg: trustdb created
gpg: key BBBE654440E720C1 marked as ultimately trusted
gpg: directory '/root/.gnupg/openpgp-revocs.d' created
gpg: revocation certificate stored as '/root/.gnupg/openpgp-revocs.d/225C736E0E70AC222C072B70BBBE654440E720C1.rev'

root:/var/www/app# gpg --output secret.gpg --armor --export-secret-key $email
root:/var/www/app# head secret.gpg
-----BEGIN PGP PRIVATE KEY BLOCK-----

lQOYBGJD+bwBCADBGKySV5PINc5MmQB3PNvCG7Oa1VMBO8XJdivIOSw7ykv55PRP
3g3R+ERd1Ss5gd5KAxLc1tt6PHGSPTypUJjCng2plwD8Jy5A/cC6o2x8yubOslLa
x1EC9fpcxUYUNXZavtEr+ylOaTaRz6qwSabsAgkg2NZ0ey/QKmFOZvhL8NlK9lTI
GgZPTiqPCsr7hiNg0WRbT5h8nTmfpl/DdTgwfPsDn5Hn0TEMa79WsrPnnq16jsq0
Uusuw3tOmdSdYnT8j7m1cpgcSj0hRF1eh4GVE0o62GqeLTWW9mfpcuv7n6mWaCB8
DCH6H238gwUriq/aboegcuBktlvSY21q/MIXABEBAAEAB/wK/M2buX+vavRgDRgR
hjUrsJTXO3VGLYcIetYXRhLmHLxBriKtcBa8OxLKKL5AFEuNourOBdcmTPiEwuxH
5s39IQOTrK6B1UmUqXvFLasXghorv8o8KGRL4ABM4Bgn6o+KBAVLVIwvVIhQ4rlf

root:/var/www/app# gpg --armor --export $email &gt; .dev/gpg-keys/alice-public.gpg
root:/var/www/app# head .dev/gpg-keys/alice-public.gpg
-----BEGIN PGP PUBLIC KEY BLOCK-----

mQENBGJD+bwBCADBGKySV5PINc5MmQB3PNvCG7Oa1VMBO8XJdivIOSw7ykv55PRP
3g3R+ERd1Ss5gd5KAxLc1tt6PHGSPTypUJjCng2plwD8Jy5A/cC6o2x8yubOslLa
x1EC9fpcxUYUNXZavtEr+ylOaTaRz6qwSabsAgkg2NZ0ey/QKmFOZvhL8NlK9lTI
GgZPTiqPCsr7hiNg0WRbT5h8nTmfpl/DdTgwfPsDn5Hn0TEMa79WsrPnnq16jsq0
Uusuw3tOmdSdYnT8j7m1cpgcSj0hRF1eh4GVE0o62GqeLTWW9mfpcuv7n6mWaCB8
DCH6H238gwUriq/aboegcuBktlvSY21q/MIXABEBAAG0HUFsaWNlIERvZSA8YWxp
Y2VAZXhhbXBsZS5jb20+iQFOBBMBCgA4FiEEIlxzbg5wrCIsBytwu75lREDnIMEF
AmJD+bwCGy8FCwkIBwIGFQoJCAsCBBYCAwECHgECF4AACgkQu75lREDnIMEN4Af+</code></pre>
<p>That's it. We now have a new secret and private key for <code>alice@example.com</code> and have exported it to
<code>secret.gpg</code> resp. <code>.dev/gpg-keys/alice-public.gpg</code> (and thus shared it with the host system).
The remaining commands can now be run outside of the <code>application</code> container directly on the
host system.</p>
<!-- generated -->
<p><a id='initial-setup-of-git-secret'> </a></p>
<!-- /generated -->
<h4>Initial setup of <code>git-secret</code></h4>
<p>Let's say we want to introduce <code>git-secret</code> &quot;from scratch&quot; to a new codebase. Then you would run
the following commands:</p>
<p><strong>Initialize <code>git-secret</code></strong></p>
<pre><code class="language-bash">make secret-init</code></pre>
<pre><code class="language-text">$ make secret-init
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="init";
git-secret: init created: '/var/www/app/.gitsecret/'</code></pre>
<p><strong>Apply the <code>gpg</code> fix for shared directories</strong></p>
<p>See <a href="#the-git-secret-directory-and-the-gpg-agent-socket">The <code>git-secret</code> directory and the <code>gpg-agent</code> socket</a>.</p>
<pre><code class="language-bash">$ make secret-init-gpg-socket-config</code></pre>
<pre><code class="language-text">$ make secret-init-gpg-socket-config
echo "%Assuan%" &gt; .gitsecret/keys/S.gpg-agent
echo "socket=/tmp/S.gpg-agent" &gt;&gt; .gitsecret/keys/S.gpg-agent
echo "%Assuan%" &gt; .gitsecret/keys/S.gpg-agent.ssh
echo "socket=/tmp/S.gpg-agent.ssh" &gt;&gt; .gitsecret/keys/S.gpg-agent.ssh
echo "extra-socket /tmp/S.gpg-agent.extra" &gt; .gitsecret/keys/gpg-agent.conf
echo "browser-socket /tmp/S.gpg-agent.browser" &gt;&gt; .gitsecret/keys/gpg-agent.conf</code></pre>
<!-- generated -->
<p><a id='initialize-gpg-after-container-startup'> </a></p>
<!-- /generated -->
<h4>Initialize <code>gpg</code> after container startup</h4>
<p>After restarting the containers, we need to initialize <code>gpg</code>, i.e. import all public keys from
<code>.dev/gpg-keys/*</code> and the private key from <code>secret.gpg</code>. Otherwise we will not be able to en-
and decrypt the files.</p>
<pre><code class="language-bash">make gpg-init</code></pre>
<pre><code class="language-text">$ make gpg-init
"C:/Program Files/Git/mingw64/bin/make" -s gpg-import GPG_KEY_FILES="secret.gpg"
gpg: directory '/home/application/.gnupg' created
gpg: keybox '/home/application/.gnupg/pubring.kbx' created
gpg: /home/application/.gnupg/trustdb.gpg: trustdb created
gpg: key BBBE654440E720C1: public key "Alice Doe &lt;alice@example.com&gt;" imported
gpg: key BBBE654440E720C1: secret key imported
gpg: Total number processed: 1
gpg:               imported: 1
gpg:       secret keys read: 1
gpg:   secret keys imported: 1
"C:/Program Files/Git/mingw64/bin/make" -s gpg-import GPG_KEY_FILES=".dev/gpg-keys/*"
gpg: key BBBE654440E720C1: "Alice Doe &lt;alice@example.com&gt;" not changed
gpg: Total number processed: 1
gpg:              unchanged: 1</code></pre>
<!-- generated -->
<p><a id='adding-new-team-members'> </a></p>
<!-- /generated -->
<h4>Adding (new) team members</h4>
<p>Let's start by adding our own user to <code>git-secret</code></p>
<pre><code class="language-bash">make secret-add-user EMAIL="alice@example.com"</code></pre>
<pre><code class="language-text">$ make secret-add-user EMAIL="alice@example.com"
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="tell alice@example.com"
git-secret: done. alice@example.com added as user(s) who know the secret.</code></pre>
<p>And verify that it worked via</p>
<pre><code class="language-bash">make secret-show-users</code></pre>
<pre><code class="language-text">$ make secret-show-users
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="whoknows"
alice@example.com</code></pre>
<!-- generated -->
<p><a id='adding-and-encrypting-files'> </a></p>
<!-- /generated -->
<h4>Adding and encrypting files</h4>
<p>Let's add a new encrypted file <code>secret_password.txt</code>.</p>
<p>Create the file </p>
<pre><code class="language-bash">echo "my_new_secret_password" &gt; secret_password.txt</code></pre>
<p>Add it to <code>.gitignore</code></p>
<pre><code class="language-bash">echo "secret_password.txt" &gt;&gt; .gitignore</code></pre>
<p>Add it to <code>git-secret</code></p>
<pre><code class="language-bash">make secret-add FILE="secret_password.txt"</code></pre>
<pre><code class="language-text">$ make secret-add FILE="secret_password.txt"
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="add secret_password.txt"
git-secret: 1 item(s) added.</code></pre>
<p>Encrypt all files</p>
<pre><code class="language-bash">make secret-encrypt</code></pre>
<pre><code class="language-text">$ make secret-encrypt
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="hide"
git-secret: done. 1 of 1 files are hidden.

$ ls secret_password.txt.secret
secret_password.txt.secret</code></pre>
<!-- generated -->
<p><a id='decrypt-files'> </a></p>
<!-- /generated -->
<h4>Decrypt files</h4>
<p>Let's first remove the &quot;plain&quot; <code>secret_password.txt</code> file</p>
<pre><code class="language-bash">rm secret_password.txt</code></pre>
<pre><code class="language-text">$ rm secret_password.txt

$ ls secret_password.txt
ls: cannot access 'secret_password.txt': No such file or directory</code></pre>
<p>and then decrypt the encrypted one.</p>
<pre><code class="language-bash">make secret-decrypt</code></pre>
<pre><code class="language-text">$ make secret-decrypt
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="reveal -f"
git-secret: done. 1 of 1 files are revealed.

$ cat secret_password.txt
my_new_secret_password</code></pre>
<p><strong>Caution:</strong> If the secret <code>gpg</code> key is password protected (e.g. <code>123456</code>), run</p>
<pre><code class="language-bash">make secret-decrypt-with-password GPG_PASSWORD=123456</code></pre>
<p>You could also add the <code>GPG_PASSWORD</code> variable to the
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#shared-variables-make-env"><code>.make/.env</code></a>
file as a local default value so that you wouldn't have to specify the value every time and
could then simply run</p>
<pre><code class="language-bash">make secret-decrypt-with-password</code></pre>
<p>without passing <code>GPG_PASSWORD</code></p>
<!-- generated -->
<p><a id='removing-files'> </a></p>
<!-- /generated -->
<h4>Removing files</h4>
<p>Remove the <code>secret_password.txt</code> file we added previously:</p>
<pre><code class="language-bash">make secret-remove FILE="secret_password.txt"</code></pre>
<pre><code class="language-text">$ make secret-remove FILE="secret_password.txt"
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="remove secret_password.txt"
git-secret: removed from index.
git-secret: ensure that files: [secret_password.txt] are now not ignored.</code></pre>
<p><strong>Caution: this will neither remove the <code>secret_password.txt</code> file nor
the <code>secret_password.txt.secret</code> file automatically&quot;</strong></p>
<pre><code class="language-text">$ ls -l | grep secret_password.txt
-rw-r--r-- 1 Pascal 197121     19 Mar 31 14:03 secret_password.txt
-rw-r--r-- 1 Pascal 197121    358 Mar 31 14:02 secret_password.txt.secret</code></pre>
<p>But even though the encrypted <code>secret_password.txt.secret</code> file still exists, it will not be
decrypted:</p>
<pre><code class="language-text">$ make secret-decrypt
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="reveal -f"
git-secret: done. 0 of 0 files are revealed.</code></pre>
<!-- generated -->
<p><a id='removing-team-members'> </a></p>
<!-- /generated -->
<h4>Removing team members</h4>
<p>Removing a team member can be done via</p>
<pre><code class="language-bash">make secret-remove-user EMAIL="alice@example.com"</code></pre>
<pre><code class="language-text">$ make secret-remove-user EMAIL="alice@example.com"
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="killperson alice@example.com"
git-secret: removed keys.
git-secret: now [alice@example.com] do not have an access to the repository.
git-secret: make sure to hide the existing secrets again.</code></pre>
<p>If there are any users left, we must make sure to re-encrypt the secrets via</p>
<pre><code class="language-bash">make secret-encrypt</code></pre>
<p>Otherwise (if no more users are left) <code>git-secret</code> would simply error out</p>
<pre><code class="language-text">$ make secret-decrypt
"C:/Program Files/Git/mingw64/bin/make" -s git-secret ARGS="reveal -f"
git-secret: abort: no public keys for users found. run 'git secret tell email@address'.
make[1]: *** [.make/01-00-application-setup.mk:57: git-secret] Error 1
make: *** [.make/01-00-application-setup.mk:69: secret-decrypt] Error 2</code></pre>
<p><strong>Caution</strong>: Please keep in mind to
<a href="#reminder-rotate-the-encrypted-secrets">rotate the secrets themselves as well</a>!</p>
<!-- generated -->
<p><a id='pros-and-cons'> </a></p>
<!-- /generated -->
<h2>Pros and cons</h2>
<!-- generated -->
<p><a id='pro'> </a></p>
<!-- /generated -->
<h3>Pro</h3>
<ul>
<li>very low barrier to entry:
<ul>
<li>no third party service required</li>
<li>easy to integrate in existing codebases, because the secrets are located directly in
the codebase</li>
<li>everything can be handled through docker (no additional local software necessary)</li>
</ul></li>
<li>once set up, it is very easy/convenient to use and can be integrated in a team workflow</li>
<li>changes to secrets can be reviewed before they are merged
<ul>
<li>this leads to less fuck-ups on deployments</li>
</ul></li>
<li>&quot;everything&quot; is in the repository, which brings a lot of familiar benefits like
<ul>
<li>version control</li>
<li>a single <code>git pull</code> is the only thing you need to get everything (=&gt; good dev experience)</li>
</ul></li>
</ul>
<!-- generated -->
<p><a id='cons'> </a></p>
<!-- /generated -->
<h3>Cons</h3>
<ul>
<li>some overhead during onboarding and offboarding</li>
<li>the secret key must be put in the root of the repository at <code>./secret.gpg</code></li>
<li>no fine grained permissions for different secrets, e.g. the mysql password on production and
staging can not be treated differently
<ul>
<li>if somebody can decrypt secrets, ALL of them are exposed</li>
</ul></li>
<li>if the a secret key ever gets leaked, all secrets are compromised
<ul>
<li>=&gt; can be mitigated (to a degree) by using a passphrase on the secret key</li>
<li>=&gt; this is kinda true for any other system that stores secrets as well BUT third parties
could probably implement additional measures like multi factor authentication</li>
</ul></li>
<li>secrets are versioned alongside the users that have access, i.e. even if a user is removed at
some point, he can still decrypt a previous version of the encrypted secrets
<ul>
<li>=&gt; must be mitigated by
<a href="#reminder-rotate-the-encrypted-secrets">rotating the secrets themselves as well</a></li>
</ul></li>
</ul>
<!-- generated -->
<p><a id='wrapping-up'> </a></p>
<!-- /generated -->
<h2>Wrapping up</h2>
<p>Congratulations, you made it! If some things are not completely clear by now, don't hesitate to
leave a comment. You are now able to encrypt and decrypt secret files so that they can be stored
directly in the git repository.</p>
<p>In the next part of this tutorial, we will
<a href="/blog/ci-pipeline-docker-php-gitlab-github/">set up a CI pipeline for dockerized PHP Apps on Github and Gitlab</a>
that decrypts all necessary secrets and then runs our tests and qa tools.</p>
<p>Please subscribe to the <a href="/feed.xml">RSS feed</a> or <a href="#newsletter">via email</a> to get automatic
notifications when this next part comes out :)</p>]]></description>
                <pubDate>Mon, 25 Apr 2022 06:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/blog/git-secret-encrypt-repository-docker/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/blog/git-secret-encrypt-repository-docker/</guid>
            </item>
                    <item>
                <title>Set up PHP QA tools and control them via make [Tutorial Part 5]</title>
                <description><![CDATA[<p>In the fifth part of this tutorial series on developing PHP on Docker we will <strong>setup some PHP code
quality tools</strong> and provide a convenient way to control them via GNU make.</p>
<p><a href="/img/php-qa-tools-make-docker/run-qa-tools.gif"><img src="/img/php-qa-tools-make-docker/run-qa-tools.gif" alt="Run QA tools" /></a></p>
<p><small>
FYI: Originally I wanted
this tutorial to be a part of
<a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
because QA checks are imho vital part of a CI setup - but it kinda grew &quot;too big&quot; and took a way
too much space from, well, actually setting up the CI pipelines :)
</small></p>
<p>All code samples are publicly available in my
<a href="https://github.com/paslandau/docker-php-tutorial">Docker PHP Tutorial repository on github</a>.<br />
You find the branch with the final result of this tutorial at
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-5-php-qa-tools-make-docker">part-5-php-qa-tools-make-docker</a>.</p>
<!-- generated -->
<p><a id='published-parts-of-the-docker-php-tutorial'> </a></p>
<!-- /generated -->
<h2>Published parts of the Docker PHP Tutorial</h2>
<ul>
<li><a href="/blog/php-php-fpm-and-nginx-on-docker-in-windows-10/">Setting up PHP, PHP-FPM and NGINX for local development on Docker</a>
(2018-07-08)</li>
<li><a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
(2018-08-06)</li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
(2019-05-20)</li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
(2022-03-21)</li>
<li><a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>
(2022-03-22)</li>
<li><a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>
(2022-03-23)</li>
<li><a href="/blog/php-qa-tools-make-docker/">Set up PHP QA tools and control them via make</a>
(2022-04-25)</li>
<li><a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
(2022-04-25)</li>
<li><a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
(2022-04-25)</li>
</ul>
<p>If you want to follow along, please subscribe to the <a href="/feed.xml">RSS feed</a>
or <a href="#newsletter">via email</a>
to get automatic notifications when the next part comes out :)</p>
<!-- generated -->
<p><a id='table-of-contents'> </a></p>
<!-- /generated -->
<h2>Table of contents</h2>
<!-- toc -->
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-qa-tools">The QA tools</a>
<ul>
<li><a href="#phpcs-and-phpcbf">phpcs and phpcbf</a></li>
<li><a href="#phpstan">phpstan</a></li>
<li><a href="#php-parallel-lint">php-parallel-lint</a></li>
<li><a href="#composer-require-checker">composer-require-checker</a></li>
<li><a href="#additional-tools-out-of-scope">Additional tools (out of scope)</a></li>
</ul></li>
<li><a href="#qa-make-targets">QA make targets</a>
<ul>
<li><a href="#the-qa-target">The <code>qa</code> target</a></li>
<li><a href="#the-execute-function">The <code>execute</code> &quot;function&quot;</a></li>
<li><a href="#parallel-execution-and-a-helper-target">Parallel execution and a helper target</a></li>
<li><a href="#sprinkle-some-color-on-top">Sprinkle some color on top</a></li>
</ul></li>
<li><a href="#further-updates-in-the-codebase">Further updates in the codebase</a></li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
<!-- /toc -->
<!-- generated -->
<p><a id='introduction'> </a></p>
<!-- /generated -->
<h2>Introduction</h2>
<p>Code quality tools ensure a <strong>baseline of code quality</strong> by automatically checking certain rules,
e.g. <strong>code style definitions</strong>, proper <strong>usage of types</strong>, proper <strong>declaration of dependencies</strong>,
etc. When run regularly they are a great way to enforce better code and are thus a
<strong>perfect fit for a CI pipeline</strong>. For this tutorial, I'm going to setup the following tools:</p>
<ul>
<li><a href="#phpcs-and-phpcbf">Style Checker: phpcs</a></li>
<li><a href="#phpstan">Static Analyzer: phpstan</a></li>
<li><a href="#php-parallel-lint">Code Linter: php-parallel-lint</a></li>
<li><a href="#composer-require-checker">Dependency Checker: composer-require-checker</a></li>
</ul>
<p>and provide convenient access through a <a href="#the-qa-target"><code>qa</code> make target</a>. The end result will look
like this:</p>
<p><a href="/img/php-qa-tools-make-docker/qa-tool-output.PNG"><img src="/img/php-qa-tools-make-docker/qa-tool-output.PNG" alt="QA tool output" /></a></p>
<p>FYI: When we started out with using code quality tools in general, we have used
<a href="https://github.com/phpro/grumphp">GrumPHP</a> - and I would still recommend it. We have only
transitioned away from it because <code>make</code> gives us a little more flexibility and control.</p>
<p>You can find the &quot;final&quot; makefile
at <a href="https://github.com/paslandau/docker-php-tutorial/blob/part-5-php-qa-tools-make-docker/.make/01-02-application-qa.mk"><code>.make/01-02-application-qa.mk</code></a>.</p>
<p><strong>CAUTION</strong>: The <code>Makefile</code> is build on top of the setup that I introduced in
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>,
so please refer to that tutorial if anything is not clear.</p>
<pre><code class="language-Makefile">##@ [Application: QA]

# variables
CORES?=$(shell (nproc  || sysctl -n hw.ncpu) 2&gt; /dev/null)

# constants
 ## files
ALL_FILES=./
APP_FILES=app/
TEST_FILES=tests/

 ## bash colors
RED:=\033[0;31m
GREEN:=\033[0;32m
YELLOW:=\033[0;33m
NO_COLOR:=\033[0m

# Tool CLI config
PHPUNIT_CMD=php vendor/bin/phpunit
PHPUNIT_ARGS= -c phpunit.xml
PHPUNIT_FILES=
PHPSTAN_CMD=php vendor/bin/phpstan analyse
PHPSTAN_ARGS=--level=9
PHPSTAN_FILES=$(APP_FILES) $(TEST_FILES)
PHPCS_CMD=php vendor/bin/phpcs
PHPCS_ARGS=--parallel=$(CORES) --standard=psr12
PHPCS_FILES=$(APP_FILES)
PHPCBF_CMD=php vendor/bin/phpcbf
PHPCBF_ARGS=$(PHPCS_ARGS)
PHPCBF_FILES=$(PHPCS_FILES)
PARALLEL_LINT_CMD=php vendor/bin/parallel-lint
PARALLEL_LINT_ARGS=-j 4 --exclude vendor/ --exclude .docker --exclude .git
PARALLEL_LINT_FILES=$(ALL_FILES)
COMPOSER_REQUIRE_CHECKER_CMD=php vendor/bin/composer-require-checker
COMPOSER_REQUIRE_CHECKER_ARGS=--ignore-parse-errors

# call with NO_PROGRESS=true to hide tool progress (makes sense when invoking multiple tools together)
NO_PROGRESS?=false
ifeq ($(NO_PROGRESS),true)
    PHPSTAN_ARGS+= --no-progress
    PARALLEL_LINT_ARGS+= --no-progress
else
    PHPCS_ARGS+= -p
    PHPCBF_ARGS+= -p
endif

# Use NO_PROGRESS=false when running individual tools.
# On  NO_PROGRESS=true  the corresponding tool has no output on success
#                       apart from its runtime but it will still print 
#                       any errors that occured. 
define execute
    if [ "$(NO_PROGRESS)" = "false" ]; then \
        eval "$(EXECUTE_IN_APPLICATION_CONTAINER) $(1) $(2) $(3) $(4)"; \
    else \
        START=$$(date +%s); \
        printf "%-35s" "$@"; \
        if OUTPUT=$$(eval "$(EXECUTE_IN_APPLICATION_CONTAINER) $(1) $(2) $(3) $(4)" 2&gt;&amp;1); then \
            printf " $(GREEN)%-6s$(NO_COLOR)" "done"; \
            END=$$(date +%s); \
            RUNTIME=$$((END-START)) ;\
            printf " took $(YELLOW)$${RUNTIME}s$(NO_COLOR)\n"; \
        else \
            printf " $(RED)%-6s$(NO_COLOR)" "fail"; \
            END=$$(date +%s); \
            RUNTIME=$$((END-START)) ;\
            printf " took $(YELLOW)$${RUNTIME}s$(NO_COLOR)\n"; \
            echo "$$OUTPUT"; \
            printf "\n"; \
            exit 1; \
        fi; \
    fi
endef

.PHONY: test
test: ## Run all tests
    @$(EXECUTE_IN_APPLICATION_CONTAINER) $(PHPUNIT_CMD) $(PHPUNIT_ARGS) $(ARGS)

.PHONY: phplint
phplint: ## Run phplint on all files
    @$(call execute,$(PARALLEL_LINT_CMD),$(PARALLEL_LINT_ARGS),$(PARALLEL_LINT_FILES), $(ARGS))

.PHONY: phpcs
phpcs: ## Run style check on all application files
    @$(call execute,$(PHPCS_CMD),$(PHPCS_ARGS),$(PHPCS_FILES), $(ARGS))

.PHONY: phpcbf
phpcbf: ## Run style fixer on all application files
    @$(call execute,$(PHPCBF_CMD),$(PHPCBF_ARGS),$(PHPCBF_FILES), $(ARGS))

.PHONY: phpstan
phpstan:  ## Run static analyzer on all application and test files 
    @$(call execute,$(PHPSTAN_CMD),$(PHPSTAN_ARGS),$(PHPSTAN_FILES), $(ARGS))

.PHONY: composer-require-checker
composer-require-checker: ## Run dependency checker
    @$(call execute,$(COMPOSER_REQUIRE_CHECKER_CMD),$(COMPOSER_REQUIRE_CHECKER_ARGS),"", $(ARGS))

.PHONY: qa
qa: ## Run code quality tools on all files
    @"$(MAKE)" -j $(CORES) -k --no-print-directory --output-sync=target qa-exec NO_PROGRESS=true

.PHONY: qa-exec
qa-exec: phpstan \
    phplint \
    composer-require-checker \
    phpcs</code></pre>
<!-- generated -->
<p><a id='the-qa-tools'> </a></p>
<!-- /generated -->
<h2>The QA tools</h2>
<!-- generated -->
<p><a id='phpcs-and-phpcbf'> </a></p>
<!-- /generated -->
<h3>phpcs and phpcbf</h3>
<p><code>phpcs</code> is the CLI tool of the style checker
<a href="https://github.com/squizlabs/PHP_CodeSniffer">squizlabs/PHP_CodeSniffer</a>. It also comes with
<code>phpcbf</code> - a tool to automatically fix style errors.</p>
<p>Installation via composer:</p>
<pre><code class="language-shell">make composer ARGS="require --dev squizlabs/php_codesniffer"</code></pre>
<p>For now we will simply use the pre-configured ruleset for
<a href="https://www.php-fig.org/psr/psr-12/">PSR-12: Extended Coding Style</a>. When run in the <code>application</code>
container for the first time on the <code>app</code> directory via</p>
<pre><code class="language-text">vendor/bin/phpcs --standard=PSR12 --parallel=4 -p app</code></pre>
<p>i.e.</p>
<pre><code class="language-text">--standard=PSR12 =&gt; use the PSR12 ruleset
--parallel=4     =&gt; run with 4 parallel processes
-p               =&gt; show the progress</code></pre>
<p>we get the following result:</p>
<pre><code class="language-text">root:/var/www/app# vendor/bin/phpcs --standard=PSR12 --parallel=4 -p app

FILE: /var/www/app/app/Console/Kernel.php
----------------------------------------------------------------------
FOUND 2 ERRORS AFFECTING 1 LINE
----------------------------------------------------------------------
 28 | ERROR | [x] Expected at least 1 space before "."; 0 found
 28 | ERROR | [x] Expected at least 1 space after "."; 0 found
----------------------------------------------------------------------
PHPCBF CAN FIX THE 2 MARKED SNIFF VIOLATIONS AUTOMATICALLY
----------------------------------------------------------------------

FILE: /var/www/app/app/Http/Controllers/HomeController.php
----------------------------------------------------------------------
FOUND 4 ERRORS AFFECTING 2 LINES
----------------------------------------------------------------------
 37 | ERROR | [x] Expected at least 1 space before "."; 0 found
 37 | ERROR | [x] Expected at least 1 space after "."; 0 found
 45 | ERROR | [x] Expected at least 1 space before "."; 0 found
 45 | ERROR | [x] Expected at least 1 space after "."; 0 found
----------------------------------------------------------------------
PHPCBF CAN FIX THE 4 MARKED SNIFF VIOLATIONS AUTOMATICALLY
----------------------------------------------------------------------

FILE: /var/www/app/app/Jobs/InsertInDbJob.php
-------------------------------------------------------------------------------
FOUND 1 ERROR AFFECTING 1 LINE
-------------------------------------------------------------------------------
 13 | ERROR | [x] Each imported trait must have its own "use" import statement
-------------------------------------------------------------------------------
PHPCBF CAN FIX THE 1 MARKED SNIFF VIOLATIONS AUTOMATICALLY
-------------------------------------------------------------------------------

FILE: /var/www/app/app/Models/User.php
-------------------------------------------------------------------------------
FOUND 1 ERROR AFFECTING 1 LINE
-------------------------------------------------------------------------------
 13 | ERROR | [x] Each imported trait must have its own "use" import statement
-------------------------------------------------------------------------------
PHPCBF CAN FIX THE 1 MARKED SNIFF VIOLATIONS AUTOMATICALLY
-------------------------------------------------------------------------------</code></pre>
<p>All errors can be fixed automatically with <code>phpcbf</code>:</p>
<pre><code class="language-text">root:/var/www/app# vendor/bin/phpcbf --standard=PSR12 --parallel=4 -p app

PHPCBF RESULT SUMMARY
-------------------------------------------------------------------------
FILE                                                     FIXED  REMAINING
-------------------------------------------------------------------------
/var/www/app/app/Console/Kernel.php                      2      0
/var/www/app/app/Http/Controllers/HomeController.php     4      0
/var/www/app/app/Jobs/InsertInDbJob.php                  1      0
/var/www/app/app/Models/User.php                         1      0
-------------------------------------------------------------------------
A TOTAL OF 8 ERRORS WERE FIXED IN 4 FILES
-------------------------------------------------------------------------

Time: 411ms; Memory: 8MB</code></pre>
<p>and a follow-up run of <code>phpcs</code> doesn't show any more errors:</p>
<pre><code class="language-text">root:/var/www/app# vendor/bin/phpcs --standard=PSR12 --parallel=4 -p app
.................... 20 / 20 (100%)

Time: 289ms; Memory: 8MB</code></pre>
<!-- generated -->
<p><a id='phpstan'> </a></p>
<!-- /generated -->
<h3>phpstan</h3>
<p><code>phpstan</code> is the CLI tool of the static code analyzer
<a href="https://github.com/phpstan/phpstan">phpstan/phpstan</a> (see also the
<a href="https://phpstan.org/user-guide/getting-started">full PHPStan documentation</a>). It provides some
default &quot;levels&quot; of increasing strictness to report potential bugs based on the AST of the analyzed
PHP code.</p>
<p>Installation via composer:</p>
<pre><code class="language-shell">make composer ARGS="require --dev phpstan/phpstan"</code></pre>
<p>Since this is a &quot;fresh&quot; codebase with very little code let's go for the
<a href="https://phpstan.org/user-guide/rule-levels">highest level 9</a> (as of 2022-04-24) and run it in the
<code>application</code> container on the <code>app</code> and <code>tests</code> directories via:</p>
<pre><code class="language-text">vendor/bin/phpstan analyse app tests --level=9

--level=9        =&gt; use level 9</code></pre>
<pre><code class="language-text">root:/var/www/app# vendor/bin/phpstan analyse app tests --level=9
 25/25 [] 100%

 ------ ------------------------------------------------------------------------------------------------------------------
  Line   app/Commands/SetupDbCommand.php
 ------ ------------------------------------------------------------------------------------------------------------------
  22     Method App\Commands\SetupDbCommand::getOptions() return type has no value type specified in iterable type array.
          See: https://phpstan.org/blog/solving-phpstan-no-value-type-specified-in-iterable-type
  34     Method App\Commands\SetupDbCommand::handle() has no return type specified.
 ------ ------------------------------------------------------------------------------------------------------------------

 ------ -------------------------------------------------------------------------------------------------------
  Line   app/Http/Controllers/HomeController.php
 ------ -------------------------------------------------------------------------------------------------------
  22     Parameter #1 $jobId of class App\Jobs\InsertInDbJob constructor expects string, mixed given.
  25     Part $jobId (mixed) of encapsed string cannot be cast to string.
  35     Call to an undefined method Illuminate\Redis\Connections\Connection::lRange().
  62     Call to an undefined method Illuminate\Contracts\View\Factory|Illuminate\Contracts\View\View::with().
 ------ -------------------------------------------------------------------------------------------------------

 ------ ------------------------------------------------------------------------------------------------------------------
  Line   app/Http/Middleware/Authenticate.php
 ------ ------------------------------------------------------------------------------------------------------------------
  17     Method App\Http\Middleware\Authenticate::redirectTo() should return string|null but return statement is missing.
 ------ ------------------------------------------------------------------------------------------------------------------

 ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Line   app/Http/Middleware/RedirectIfAuthenticated.php
 ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  26     Method App\Http\Middleware\RedirectIfAuthenticated::handle() should return Illuminate\Http\RedirectResponse|Illuminate\Http\Response but returns Illuminate\Http\RedirectResponse|Illuminate\Routing\Redirector.
 ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

 ------ -----------------------------------------------------------------------
  Line   app/Jobs/InsertInDbJob.php
 ------ -----------------------------------------------------------------------
  22     Method App\Jobs\InsertInDbJob::handle() has no return type specified.
 ------ -----------------------------------------------------------------------

 ------ -------------------------------------------------
  Line   app/Providers/RouteServiceProvider.php
 ------ -------------------------------------------------
  36     PHPDoc tag @var above a method has no effect.
  36     PHPDoc tag @var does not specify variable name.
  60     Cannot access property $id on mixed.
 ------ -------------------------------------------------

 ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------
  Line   tests/Feature/App/Http/Controllers/HomeControllerTest.php
 ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------
  24     Method Tests\Feature\App\Http\Controllers\HomeControllerTest::test___invoke() has parameter $params with no value type specified in iterable type array.
          See: https://phpstan.org/blog/solving-phpstan-no-value-type-specified-in-iterable-type
  38     Method Tests\Feature\App\Http\Controllers\HomeControllerTest::__invoke_dataProvider() return type has no value type specified in iterable type array.
          See: https://phpstan.org/blog/solving-phpstan-no-value-type-specified-in-iterable-type
 ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------

 ------ ---------------------------------------------------------------------------------------------------------------------
  Line   tests/TestCase.php
 ------ ---------------------------------------------------------------------------------------------------------------------
  68     Cannot access offset 'database' on mixed.
  71     Parameter #1 $config of method Illuminate\Database\Connectors\MySqlConnector::connect() expects array, mixed given.
 ------ ---------------------------------------------------------------------------------------------------------------------

 [ERROR] Found 16 errors</code></pre>
<p>After fixing (or ignoring :P) all errors, we now get</p>
<pre><code class="language-text">root:/var/www/app# vendor/bin/phpstan analyse app tests --level=9
25/25 [] 100%

[OK] No errors</code></pre>
<!-- generated -->
<p><a id='php-parallel-lint'> </a></p>
<!-- /generated -->
<h3>php-parallel-lint</h3>
<p><code>php-parallel-lint</code> is the CLI tool of the PHP code linter
<a href="https://github.com/php-parallel-lint/PHP-Parallel-Lint">php-parallel-lint/PHP-Parallel-Lint</a>. It
ensures that all PHP files are syntactically correct.</p>
<p>Installation via composer:</p>
<pre><code class="language-shell">make composer ARGS="require --dev php-parallel-lint/php-parallel-lint"</code></pre>
<p>&quot;Parallel&quot; is already in the name, so we run it on the full codebase <code>./</code> with 4 parallel processes
and exclude the <code>.git</code> and <code>vendor</code> directories to speed up the execution via</p>
<pre><code class="language-text">vendor/bin/parallel-lint -j 4 --exclude .git --exclude vendor ./</code></pre>
<p>i.e.</p>
<pre><code class="language-text">-j 4                              =&gt; use 4 parallel processes
--exclude .git --exclude vendor   =&gt; ignore the .git/ and vendor/ directories</code></pre>
<p>we get </p>
<pre><code class="language-text">root:/var/www/app# vendor/bin/parallel-lint -j 4 --exclude .git --exclude vendor ./
PHP 8.1.1 | 4 parallel jobs
............................................................ 60/61 (98 %)
.                                                            61/61 (100 %)

Checked 61 files in 0.2 seconds
No syntax error found</code></pre>
<p>No further TODOs here.</p>
<!-- generated -->
<p><a id='composer-require-checker'> </a></p>
<!-- /generated -->
<h3>composer-require-checker</h3>
<p><code>composer-require-checker</code> is the CLI tool of the dependency checker
<a href="https://github.com/maglnet/ComposerRequireChecker">maglnet/ComposerRequireChecker</a>. The tool
ensures that the <code>composer.json</code> file contains all dependencies that are used in the codebase.</p>
<p>Installation via composer:</p>
<pre><code class="language-shell">make composer ARGS="require --dev maglnet/composer-require-checker"</code></pre>
<p>Run it via</p>
<pre><code class="language-text">vendor/bin/composer-require-checker check</code></pre>
<pre><code class="language-text">root:/var/www/app# vendor/bin/composer-require-checker check
ComposerRequireChecker 4.0.0@baa11a4e9e5072117e3d180ef16c07036cafa4a2
The following 1 unknown symbols were found:
+---------------------------------------------+--------------------+
| Unknown Symbol                              | Guessed Dependency |
+---------------------------------------------+--------------------+
| Symfony\Component\Console\Input\InputOption |                    |
+---------------------------------------------+--------------------+</code></pre>
<p>What's going on here?</p>
<p>We use <code>Symfony\Component\Console\Input\InputOption</code> in our <code>\App\Commands\SetupDbCommand</code> and the
code doesn't &quot;fail&quot; because <code>InputOption</code> is defined in the<code>symfony/console</code> package that is a
<strong>transitive dependency</strong> of <code>laravel/framework</code>, see the
<a href="https://github.com/laravel/framework/blob/5b113dad7d2c88e15b65d987ca63f03b2be43e6a/composer.json#L34"><code>laravel/framework composer.json</code></a>
file. </p>
<p>I.e. the <code>symfony/console</code> package <strong>does actually exist</strong> in our <code>vendor</code> directory - but
since we also use it <em>as a first-party-dependency directly in our code</em>, we must declare the
dependency explicitly. Otherwise, Laravel might at some point decide to drop <code>symfony/console</code>
and we would be left with broken code.</p>
<p>To fix this, I run</p>
<pre><code class="language-shell">make composer ARGS="require symfony/console"</code></pre>
<p>which will update the <code>composer.json</code> file and add the dependency. Running
<code>composer-require-checker</code> again will now yield no further errors.</p>
<pre><code class="language-text">root:/var/www/app# vendor/bin/composer-require-checker check
ComposerRequireChecker 4.0.0@baa11a4e9e5072117e3d180ef16c07036cafa4a2
There were no unknown symbols found.</code></pre>
<!-- generated -->
<p><a id='additional-tools-out-of-scope'> </a></p>
<!-- /generated -->
<h3>Additional tools (out of scope)</h3>
<p>In general, I'm a huge fan of code quality tools and we use them quite extensively. At some
point I'll probably dedicate a whole article to go over them in detail - but for now I'm just
gonna leave a list for inspiration:</p>
<ul>
<li><a href="https://packagist.org/packages/brianium/paratest">brianium/paratest</a>
<ul>
<li>Running PhpUnit tests in parallel</li>
</ul></li>
<li><a href="https://packagist.org/packages/malukenho/mcbumpface">malukenho/mcbumpface</a>
<ul>
<li>Update the versions in the <code>composer.json</code> file after an update</li>
</ul></li>
<li><a href="https://packagist.org/packages/qossmic/deptrac-shim">qossmic/deptrac-shim</a>
<ul>
<li>A shim for <a href="https://packagist.org/packages/qossmic/deptrac">qossmic/deptrac</a>:
A tool to define dependency layers based on e.g. namespaces</li>
</ul></li>
<li><a href="https://packagist.org/packages/icanhazstring/composer-unused">icanhazstring/composer-unused</a>
<ul>
<li>Show dependencies in the <code>composer.json</code> that are not used in the codebase</li>
</ul></li>
<li><a href="https://packagist.org/packages/roave/security-advisories">roave/security-advisories</a>
<ul>
<li>Gives a warning when packages with known vulnerabilities are used </li>
<li>Alternative: <a href="https://github.com/fabpot/local-php-security-checker/">local-php-security-checker</a></li>
</ul></li>
</ul>
<!-- generated -->
<p><a id='qa-make-targets'> </a></p>
<!-- /generated -->
<h2>QA make targets</h2>
<p>You might have noticed that <strong>all tools have their own configuration options</strong>. Instead of
remembering each of them, I'll define corresponding make targets in <code>.make/01-02-application-qa.mk</code>.
The easiest way to do so would be to &quot;hard-code&quot; the exact commands that I ran previously, e.g.</p>
<pre><code class="language-makefile">.PHONY: phpstan
phpstan:  ## Run static analyzer on all application and test files 
    @$(EXECUTE_IN_APPLICATION_CONTAINER) vendor/bin/phpstan analyse app tests --level=9</code></pre>
<p>(Please refer to the
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#run-commands-in-the-docker-containers">Run commands in the docker containers</a>
section in the previous tutorial for an explanation of the <code>EXECUTE_IN_APPLICATION_CONTAINER</code>
variable).</p>
<p>However, this implementation is quite inflexible: What if we want to check a single file or try out
other options? So let's create some variables instead:</p>
<pre><code class="language-makefile">PHPSTAN_CMD=php vendor/bin/phpstan analyse
PHPSTAN_ARGS=--level=9
PHPSTAN_FILES=$(APP_FILES) $(TEST_FILES)

.PHONY: phpstan
phpstan: ## Run static analyzer on all application and test files 
    @$(EXECUTE_IN_APPLICATION_CONTAINER) $(PHPSTAN_CMD) $(PHPSTAN_ARGS) $(PHPSTAN_FILES) </code></pre>
<p>This target allows me to override the defaults and e.g. check only the file
<code>app/Commands/SetupDbCommand.php</code> with <code>--level=1</code></p>
<pre><code class="language-shell">make phpstan PHPSTAN_FILES=app/Commands/SetupDbCommand.php PHPSTAN_ARGS="--level=1" </code></pre>
<pre><code class="language-text">$ make phpstan PHPSTAN_FILES=app/Commands/SetupDbCommand.php PHPSTAN_ARGS="--level=1" 
 1/1 [] 100%

 [OK] No errors</code></pre>
<p>The remaining tool variables can be configured in the exact same way:</p>
<pre><code class="language-makefile"># constants
 ## files
ALL_FILES=./
APP_FILES=app/
TEST_FILES=tests/

# Tool CLI config
PHPUNIT_CMD=php vendor/bin/phpunit
PHPUNIT_ARGS= -c phpunit.xml
PHPUNIT_FILES=
PHPSTAN_CMD=php vendor/bin/phpstan analyse
PHPSTAN_ARGS=--level=9
PHPSTAN_FILES=$(APP_FILES) $(TEST_FILES)
PHPCS_CMD=php vendor/bin/phpcs
PHPCS_ARGS=--parallel=$(CORES) --standard=psr12
PHPCS_FILES=$(APP_FILES)
PHPCBF_CMD=php vendor/bin/phpcbf
PHPCBF_ARGS=$(PHPCS_ARGS)
PHPCBF_FILES=$(PHPCS_FILES)
PARALLEL_LINT_CMD=php vendor/bin/parallel-lint
PARALLEL_LINT_ARGS=-j 4 --exclude vendor/ --exclude .docker --exclude .git
PARALLEL_LINT_FILES=$(ALL_FILES)
COMPOSER_REQUIRE_CHECKER_CMD=php vendor/bin/composer-require-checker
COMPOSER_REQUIRE_CHECKER_ARGS=--ignore-parse-errors</code></pre>
<!-- generated -->
<p><a id='the-qa-target'> </a></p>
<!-- /generated -->
<h3>The <code>qa</code> target</h3>
<p>From a workflow perspective I usually want to <strong>run all configured qa tools</strong> instead of each one
individually (being able to run individually is still great if a tool fails, though).</p>
<p>A trivial approach would be a new target that <strong>uses all individual tool targets as preconditions</strong>:</p>
<pre><code class="language-makefile">.PHONY: qa
qa: phpstan \
    phplint \
    composer-require-checker \
    phpcs</code></pre>
<p>But we can do better, because this target produces quite a noisy output:</p>
<pre><code class="language-text">$ make qa
 25/25 [] 100%

 [OK] No errors

PHP 8.1.1 | 4 parallel jobs
............................................................ 60/61 (98 %)
.                                                            61/61 (100 %)

Checked 61 files in 0.3 seconds
No syntax error found
ComposerRequireChecker 4.0.0@baa11a4e9e5072117e3d180ef16c07036cafa4a2
There were no unknown symbols found.
.................... 20 / 20 (100%)

Time: 576ms; Memory: 8MB</code></pre>
<p>I'd rather have something like this:</p>
<pre><code class="language-text">$ make qa
phplint                             done   took 1s
phpcs                               done   took 1s
phpstan                             done   took 3s
composer-require-checker            done   took 6s</code></pre>
<!-- generated -->
<p><a id='the-execute-function'> </a></p>
<!-- /generated -->
<h3>The <code>execute</code> &quot;function&quot;</h3>
<p>We'll make this work by <strong>suppressing the tool output</strong> and <strong>using a user-defined <code>execute</code> make
function</strong> to format all targets nicely. </p>
<p><small>Though &quot;function&quot; isn't quite correct here, because it's rather a
<a href="https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html#Multi_002dLine">multiline variable</a>
defined via <code>define ... endef</code> that is then &quot;invoked&quot; via
the <a href="https://www.gnu.org/software/make/manual/html_node/Call-Function.html">call function</a>.
</small></p>
<pre><code class="language-makefile"># File: 01-02-application-qa.mk

# call with NO_PROGRESS=true to hide tool progress (makes sense when invoking multiple tools together)
NO_PROGRESS?=false
ifeq ($(NO_PROGRESS),true)
    PHPSTAN_ARGS+= --no-progress
endif

# Use NO_PROGRESS=false when running individual tools.
# On  NO_PROGRESS=true  the corresponding tool has no output on success
#                       apart from its runtime but it will still print 
#                       any errors that occured. 
define execute
    if [ "$(NO_PROGRESS)" = "false" ]; then \
        eval "$(EXECUTE_IN_APPLICATION_CONTAINER) $(1) $(2) $(3) $(4)"; \
    else \
        START=$$(date +%s); \
        printf "%-35s" "$@"; \
        if OUTPUT=$$(eval "$(EXECUTE_IN_APPLICATION_CONTAINER) $(1) $(2) $(3) $(4)" 2&gt;&amp;1); then \
            printf " %-6s" "done"; \
            END=$$(date +%s); \
            RUNTIME=$$((END-START)) ;\
            printf " took $${RUNTIME}s\n"; \
        else \
            printf " %-6s" "fail"; \
            END=$$(date +%s); \
            RUNTIME=$$((END-START)) ;\
            printf " took $${RUNTIME}s\n"; \
            echo "$$OUTPUT"; \
            printf "\n"; \
            exit 1; \
        fi; \
    fi
endef</code></pre>
<ul>
<li>the <code>NO_PROGRESS</code> variable is set to <code>false</code> by default and will cause a target to be invoked
as before, showing all its output immediately</li>
<li>if the variable is set to <code>true</code>, the target is instead invoked via <code>eval</code> and the output is
captured in the <code>OUTPUT</code> bash variable that will only be printed if the result of the
invocation is faulty</li>
</ul>
<p>The tool targets are then adjusted to use the new function.</p>
<pre><code class="language-makefile">.PHONY: phpstan
phpstan: ## Run static analyzer on all application and test files
    @$(call execute,$(PHPSTAN_CMD),$(PHPSTAN_ARGS),$(PHPSTAN_FILES),$(ARGS))</code></pre>
<p>We can now call the <code>phpstan</code> target with <code>NO_PROGRESS=true</code> like so:</p>
<pre><code class="language-text">$ make phpstan NO_PROGRESS=true
phpstan                             done   took 4s</code></pre>
<p>An &quot;error&quot; would look likes this:</p>
<pre><code class="language-text">$ make phpstan NO_PROGRESS=true
phpstan                             fail   took 9s
 ------ ----------------------------------------
  Line   app/Providers/RouteServiceProvider.php
 ------ ----------------------------------------
  49     Cannot access property $id on mixed.
 ------ ----------------------------------------</code></pre>
<!-- generated -->
<p><a id='parallel-execution-and-a-helper-target'> </a></p>
<!-- /generated -->
<h3>Parallel execution and a helper target</h3>
<p>Technically, this also already works with the <code>qa</code> target and we can even speed up the process by
<strong>running the tools in parallel</strong> with
the <a href="https://www.gnu.org/software/make/manual/html_node/Parallel.html">-j flag for &quot;Parallel Execution&quot;</a></p>
<pre><code class="language-text">$ make -j 4 qa NO_PROGRESS=true
phpstan                            phplint                            composer-require-checker           phpcs                               done   took 5s
done   took 5s
done   took 7s
done   took 10s</code></pre>
<p>Well... not quite what we wanted. We also need to use
<a href="https://www.gnu.org/software/make/manual/html_node/Parallel-Output.html"><code>--output-sync=target</code> to controll the &quot;Output During Parallel Execution&quot;</a></p>
<pre><code class="language-text">$ make -j 4 --output-sync=target qa NO_PROGRESS=true
phpstan                             done   took 3s
phplint                             done   took 1s
composer-require-checker            done   took 5s
phpcs                               done   took 1s</code></pre>
<p>Since this is quite a mouthful to type, we'll use a helper target <code>qa-exec</code> for running the tools
and put all the inconvenient-to-type options in the final <code>qa</code> target.</p>
<pre><code class="language-makefile"># File: 01-02-application-qa.mk
#...

# variables
CORES?=$(shell (nproc  || sysctl -n hw.ncpu) 2&gt; /dev/null)

.PHONY: qa
qa: ## Run code quality tools on all files
    @"$(MAKE)" -j $(CORES) -k --no-print-directory --output-sync=target qa-exec NO_PROGRESS=true

.PHONY: qa-exec
qa-exec: phpstan \
    phplint \
    composer-require-checker \
    phpcs</code></pre>
<p>For the number of parallel processes I use <code>nproc</code> (works on Linux and Windows) resp.
<code>sysctl -n hw.ncpu</code> (works on Mac) to determine the number of available cores. If you dedicate
less resources to docker you might want to hard-code this setting to a lower value (e.g. by
adding a <code>CORES</code> variable in
the <a href="/blog/docker-from-scratch-for-php-applications-in-2022/#shared-variables-make-env"><code>.make/.env</code></a>
file).</p>
<!-- generated -->
<p><a id='sprinkle-some-color-on-top'> </a></p>
<!-- /generated -->
<h3>Sprinkle some color on top</h3>
<p>The final piece for getting to the output mentioned in the <a href="#introduction">Introduction</a> is the
bash-coloring:</p>
<p><a href="/img/php-qa-tools-make-docker/qa-tool-output.PNG"><img src="/img/php-qa-tools-make-docker/qa-tool-output.PNG" alt="QA tool output" /></a></p>
<p>To make this work, we need to understand first how colors work in bash:</p>
<blockquote>
<p>This  [coloring] can be accomplished by adding a <code>\e</code> [or <code>\033</code>] at the beginning to form an
escape sequence. The escape sequence for specifying color codes is <code>\e[COLORm</code>
(<code>COLOR</code> represents our (numeric) color code in this case).</p>
</blockquote>
<p>(via <a href="https://dev.to/ifenna__/adding-colors-to-bash-scripts-48g4">Adding colors to Bash scripts</a>)</p>
<p>E.g. the following script will print a green text:</p>
<pre><code class="language-shell">printf "\033[0;32mThis text is green\033[0m"</code></pre>
<p>So we define the required colors as variables and use them in the corresponding places in the
<a href="#the-execute-function"><code>execute</code> function</a>:</p>
<pre><code class="language-makefile"> ## bash colors
RED:=\033[0;31m
GREEN:=\033[0;32m
YELLOW:=\033[0;33m
NO_COLOR:=\033[0m

# ...

# Use NO_PROGRESS=false when running individual tools.
# On  NO_PROGRESS=true  the corresponding tool has no output on success
#                       apart from its runtime but it will still print 
#                       any errors that occured. 
define execute
    if [ "$(NO_PROGRESS)" = "false" ]; then \
        eval "$(EXECUTE_IN_APPLICATION_CONTAINER) $(1) $(2) $(3) $(4)"; \
    else \
        START=$$(date +%s); \
        printf "%-35s" "$@"; \
        if OUTPUT=$$(eval "$(EXECUTE_IN_APPLICATION_CONTAINER) $(1) $(2) $(3) $(4)" 2&gt;&amp;1); then \
            printf " $(GREEN)%-6s$(NO_COLOR)" "done"; \
            END=$$(date +%s); \
            RUNTIME=$$((END-START)) ;\
            printf " took $(YELLOW)$${RUNTIME}s$(NO_COLOR)\n"; \
        else \
            printf " $(RED)%-6s$(NO_COLOR)" "fail"; \
            END=$$(date +%s); \
            RUNTIME=$$((END-START)) ;\
            printf " took $(YELLOW)$${RUNTIME}s$(NO_COLOR)\n"; \
            echo "$$OUTPUT"; \
            printf "\n"; \
            exit 1; \
        fi; \
    fi
endef</code></pre>
<p>Please note, that i did <strong>not include the tests in the <code>qa</code> target</strong>. I like to run those
separately, because our tests usually take a lot longer to execute. So in my day-to-day work I
would run <code>make qa</code> and <code>make test</code> to ensure that code quality and tests are passing:</p>
<pre><code class="language-text">$ make qa
phplint                             done   took 1s
phpcs                               done   took 1s
composer-require-checker            done   took 14s
phpstan                             done   took 16s

$ make test
PHPUnit 9.5.19 #StandWithUkraine

.......                                                             7 / 7 (100%)

Time: 00:03.772, Memory: 28.00 MB

OK (7 tests, 13 assertions)</code></pre>
<!-- generated -->
<p><a id='further-updates-in-the-codebase'> </a></p>
<!-- /generated -->
<h2>Further updates in the codebase</h2>
<p>I've also cleaned up the codebase a little in branch
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-5-php-qa-tools-make-docker">part-5-php-qa-tools-make-docker</a>
and even though those changes have nothing to todo with &quot;QA tools&quot; I didn't want to leave them
unnoticed:</p>
<ul>
<li>removing unnecessary files (<code>.styleci.yml</code>, <code>package.json</code>, <code>webpack.mix.js</code>)</li>
<li>removing unused values from the <code>.env.example</code> file</li>
<li>run a <code>composer update</code> to get the latest Laravel version</li>
<li>add a <code>show-help</code> script to the <code>scripts</code> section of the <code>composer.json</code> file that references the
<code>Makefile</code> (see also <a href="https://twitter.com/PascalLandau/status/1518227256648343552">this discussion on Twitter</a>)
<pre><code class="language-json">{
  "scripts": {
      "show-help": [
          "make"
      ]
  },
  "scripts-descriptions": {
      "show-help": "Display available 'make' commands (we use make instead of composer scripts)."
  }
}</code></pre>
<p><a href="/img/php-qa-tools-make-docker/make-composer-scripts.gif"><img src="/img/php-qa-tools-make-docker/make-composer-scripts.gif" alt="Run make via composer script" /></a></p></li>
<li>replace <code>docker-compose</code> with <code>docker compose</code> to use <a href="https://docs.docker.com/compose/cli-command/">compose v2</a></li>
</ul>
<p>For some reason, the last point caused some trouble because Linux and Docker Desktop for Windows
require a <code>-T</code> flag for the <code>exec</code> command to disable a TTY allocation in some cases. Whereas on
Docker Desktop for Mac
<a href="https://github.com/moby/moby/issues/37366#issuecomment-527099456">the missing TTY lead to a cluttered output (&quot;staircase effect&quot;)</a>.</p>
<p>Thus I modified the <code>Makefile</code> to populate a <code>DOCKER_COMPOSE_EXEC_OPTIONS</code> variable based on the OS</p>
<pre><code class="language-makefile"># Add the -T options to "docker compose exec" to avoid the 
# "panic: the handle is invalid"
# error on Windows and Linux 
# @see https://stackoverflow.com/a/70856332/413531
DOCKER_COMPOSE_EXEC_OPTIONS=-T

# OS is defined for WIN systems, so "uname" will not be executed
OS?=$(shell uname)
ifeq ($(OS),Windows_NT)
    # Windows requires the .exe extension, otherwise the entry is ignored
    # @see https://stackoverflow.com/a/60318554/413531
    SHELL := bash.exe
else ifeq ($(OS),Darwin)
    # On Mac, the -T must be omitted to avoid cluttered output
    # @see https://github.com/moby/moby/issues/37366#issuecomment-401157643
    DOCKER_COMPOSE_EXEC_OPTIONS=
endif</code></pre>
<p>And use the variable when defining <code>EXECUTE_IN_*_CONTAINER</code> in <code>.make/02-00-docker.mk</code></p>
<pre><code class="language-makefile">ifeq ($(EXECUTE_IN_CONTAINER),true)
    EXECUTE_IN_ANY_CONTAINER:=$(DOCKER_COMPOSE) exec $(DOCKER_COMPOSE_EXEC_OPTIONS) --user $(APP_USER_NAME) $(DOCKER_SERVICE_NAME)
    EXECUTE_IN_APPLICATION_CONTAINER:=$(DOCKER_COMPOSE) exec $(DOCKER_COMPOSE_EXEC_OPTIONS) --user $(APP_USER_NAME) $(DOCKER_SERVICE_NAME_APPLICATION)
    EXECUTE_IN_WORKER_CONTAINER:=$(DOCKER_COMPOSE) exec $(DOCKER_COMPOSE_EXEC_OPTIONS) --user $(APP_USER_NAME) $(DOCKER_SERVICE_NAME_PHP_WORKER)
endif</code></pre>
<!-- generated -->
<p><a id='wrapping-up'> </a></p>
<!-- /generated -->
<h2>Wrapping up</h2>
<p>Congratulations, you made it! If some things are not completely clear by now, don't hesitate to
leave a comment. You should now have a blueprint for adding code quality tools for your dockerized
application and way to conveniently control them through a Makefile.</p>
<p>In the next part of this tutorial, we will
<a href="/blog/git-secret-encrypt-repository-docker/">set up git secret to encrypt secret values and store them directly in the git repository</a>.</p>
<p>Please subscribe to the <a href="/feed.xml">RSS feed</a> or <a href="#newsletter">via email</a> to get automatic
notifications when this next part comes out :)</p>]]></description>
                <pubDate>Mon, 25 Apr 2022 05:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/blog/php-qa-tools-make-docker/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/blog/php-qa-tools-make-docker/</guid>
            </item>
                    <item>
                <title>Run Laravel 9 on Docker in 2022 [Tutorial Part 4.3]</title>
                <description><![CDATA[<p>In this third subpart of the fourth part of this tutorial series on developing PHP on Docker we will
install <strong>Laravel and make sure our setup works for Artisan Commands, a Redis Queue and Controllers</strong>
for the front end requests.</p>
<div class="center-div">
<iframe width="560" height="315" src="https://www.youtube.com/embed/BpsBzpMD87c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<p>All code samples are publicly available in my
<a href="https://github.com/paslandau/docker-php-tutorial">Docker PHP Tutorial repository on github</a>.<br />
You find the branch for this tutorial at
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-4-3-run-laravel-9-docker-in-2022">part-4-3-run-laravel-9-docker-in-2022</a></p>
<!-- generated -->
<p><a id='published-parts-of-the-docker-php-tutorial'> </a></p>
<!-- /generated -->
<h2>Published parts of the Docker PHP Tutorial</h2>
<ul>
<li><a href="/blog/php-php-fpm-and-nginx-on-docker-in-windows-10/">Setting up PHP, PHP-FPM and NGINX for local development on Docker</a>
(2018-07-08)</li>
<li><a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
(2018-08-06)</li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
(2019-05-20)</li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
(2022-03-21)</li>
<li><a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>
(2022-03-22)</li>
<li><a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>
(2022-03-23)</li>
<li><a href="/blog/php-qa-tools-make-docker/">Set up PHP QA tools and control them via make</a>
(2022-04-25)</li>
<li><a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
(2022-04-25)</li>
<li><a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
(2022-04-25)</li>
</ul>
<p>If you want to follow along, please subscribe to the <a href="/feed.xml">RSS feed</a>
or <a href="#newsletter">via email</a>
to get automatic notifications when the next part comes out :)</p>
<!-- generated -->
<p><a id='table-of-contents'> </a></p>
<!-- /generated -->
<h2>Table of contents</h2>
<!-- toc -->
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#install-extensions">Install extensions</a></li>
<li><a href="#install-laravel">Install Laravel</a></li>
<li><a href="#update-the-php-poc">Update the PHP POC</a>
<ul>
<li><a href="#config">config</a>
<ul>
<li><a href="#database-connection">database connection</a></li>
<li><a href="#queue-connection">queue connection</a></li>
</ul></li>
<li><a href="#controllers">Controllers</a></li>
<li><a href="#commands">Commands</a></li>
<li><a href="#jobs-and-workers">Jobs and workers</a></li>
<li><a href="#tests">Tests</a></li>
</ul></li>
<li><a href="#makefile-updates">Makefile updates</a>
<ul>
<li><a href="#clearing-the-queue">Clearing the queue</a></li>
</ul></li>
<li><a href="#running-the-poc">Running the POC</a></li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
<!-- /toc -->
<!-- generated -->
<p><a id='introduction'> </a></p>
<!-- /generated -->
<h2>Introduction</h2>
<p>The goal of this tutorial is to run the
<a href="/blog/docker-from-scratch-for-php-applications-in-2022/#php-poc">PHP POC from part 4.1</a>
using Laravel as a framework instead of &quot;plain PHP&quot;.
We'll use the newest version of Laravel (Laravel 9) that was
<a href="https://laravel-news.com/laravel-9-released">released at the beginning of February 2022</a>.</p>
<!-- generated -->
<p><a id='install-extensions'> </a></p>
<!-- /generated -->
<h2>Install extensions</h2>
<p>Before Laravel can be installed, we need to add the necessary extensions of the framework (and all
its dependencies) to the <code>php-base</code> image:</p>
<pre><code># File: .docker/images/php/base/Dockerfile

# ...

RUN apk add --update --no-cache  \
        php-curl~=${TARGET_PHP_VERSION} \
</code></pre>
<!-- generated -->
<p><a id='install-laravel'> </a></p>
<!-- /generated -->
<h2>Install Laravel</h2>
<p>We'll start by
<a href="https://laravel.com/docs/9.x/installation#installation-via-composer">creating a new Laravel project with composer</a></p>
<pre><code>composer create-project --prefer-dist laravel/laravel /tmp/laravel "9.*" --no-install --no-scripts</code></pre>
<p>The files are added to <code>/tmp/laravel</code> because
<a href="https://github.com/composer/composer/issues/1135#issuecomment-10358244">composer projects cannot be created in non-empty folders</a>
, so we need to create the project in a temporary location first and move it afterwards.</p>
<p>Since I don't have PHP 8 installed on my laptop, I'll execute the command in the <code>application</code>
docker container via</p>
<pre><code>make execute-in-container DOCKER_SERVICE_NAME="application" COMMAND='composer create-project --prefer-dist laravel/laravel /tmp/laravel "9.*" --no-install --no-scripts'</code></pre>
<p>and then move the files into the application directory via</p>
<pre><code>rm -rf public/ tests/ composer.* phpunit.xml
make execute-in-container DOCKER_SERVICE_NAME="application" COMMAND="bash -c 'mv -n /tmp/laravel/{.*,*} .' &amp;&amp; rm -f /tmp/laravel"
cp .env.example .env</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li><code>composer install</code> is skipped via <code>--no-install</code> to avoid having to copy over the <code>vendor/</code> folder
(which is super slow on Docker Desktop)</li>
<li><a href="https://unix.stackexchange.com/a/127713">existing directories cannot be overwritten by <code>mv</code></a>
thus I remove <code>public/</code> and <code>tests/</code> upfront (as well as the <code>composer</code> and <code>phpunit</code> config
files)</li>
<li><code>mv</code> uses the <code>-n</code> flag so that existing files like our <code>.editorconfig</code> are not overwritten</li>
<li>I need to use <code>bash -c</code> to run the command in the container because otherwise
<a href="https://github.com/moby/moby/issues/12558#issuecomment-94775867">the <code>*</code> wildcard would have no effect in the container</a> </li>
</ul>
<p>To finalize the installation I need to install the composer dependencies and execute the
<code>create-project</code> scripts defined in
<a href="https://github.com/laravel/laravel/blob/9.x/composer.json#L45"><code>composer.json</code></a>:</p>
<pre><code>make composer ARGS=install
make composer ARGS="run-script post-create-project-cmd"</code></pre>
<p>Since our nginx configuration was already pointing to the <code>public/</code> directory, we can immediately
open <a href="http://127.0.0.1">http://127.0.0.1</a> in the browser and should see the frontpage of
a fresh Laravel installation.</p>
<!-- generated -->
<p><a id='update-the-php-poc'> </a></p>
<!-- /generated -->
<h2>Update the PHP POC</h2>
<!-- generated -->
<p><a id='config'> </a></p>
<!-- /generated -->
<h3>config</h3>
<p>We need to update the connection information for the database and the queue (previously
configured via <code>dependencies.php</code>) in the <code>.env</code> file</p>
<!-- generated -->
<p><a id='database-connection'> </a></p>
<!-- /generated -->
<h4>database connection</h4>
<pre><code>DB_CONNECTION=mysql
DB_HOST=mysql
DB_PORT=3306
DB_DATABASE=application_db
DB_USERNAME=root
DB_PASSWORD=secret_mysql_root_password</code></pre>
<!-- generated -->
<p><a id='queue-connection'> </a></p>
<!-- /generated -->
<h4>queue connection</h4>
<pre><code>QUEUE_CONNECTION=redis

REDIS_HOST=redis
REDIS_PASSWORD=secret_redis_password</code></pre>
<!-- generated -->
<p><a id='controllers'> </a></p>
<!-- /generated -->
<h3>Controllers</h3>
<p>The functionality of the previous <code>public/index.php</code> file now lives in the <code>HomeController</code> at
<code>app/Http/Controllers/HomeController.php</code></p>
<pre><code class="language-php">class HomeController extends Controller
{
    use DispatchesJobs;

    public function __invoke(Request $request, QueueManager $queueManager, DatabaseManager $databaseManager): View
    {
        $jobId = $request-&gt;input("dispatch") ?? null;
        if ($jobId !== null) {
            $job = new InsertInDbJob($jobId);
            $this-&gt;dispatch($job);

            return $this-&gt;getView("Adding item '$jobId' to queue");
        }

        if ($request-&gt;has("queue")) {

            /**
             * @var RedisQueue $redisQueue
             */
            $redisQueue = $queueManager-&gt;connection();
            $redis =  $redisQueue-&gt;getRedis()-&gt;connection();
            $queueItems = $redis-&gt;lRange("queues:default", 0, 99999);

            $content = "Items in queue\n".var_export($queueItems, true);

            return $this-&gt;getView($content);
        }

        if ($request-&gt;has("db")) {
            $items = $databaseManager-&gt;select($databaseManager-&gt;raw("SELECT * FROM jobs"));

            $content = "Items in db\n".var_export($items, true);

            return $this-&gt;getView($content);
        }
        $content = &lt;&lt;&lt;HTML
            &lt;ul&gt;
                &lt;li&gt;&lt;a href="?dispatch=foo"&gt;Dispatch job 'foo' to the queue.&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href="?queue"&gt;Show the queue.&lt;/a&gt;&lt;/li&gt;
                &lt;li&gt;&lt;a href="?db"&gt;Show the DB.&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
            HTML;

        return $this-&gt;getView($content);
    }

    private function getView(string $content): View
    {
        return view('home')-&gt;with(["content" =&gt; $content]);
    }
}
</code></pre>
<p>Its content is displayed via the <code>home</code> view located at <code>resources/views/home.blade.php</code>:</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    {!! $content !!}
    &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>The controller is added as a route in <code>routes/web.php</code>:</p>
<pre><code class="language-php">Route::get('/', \App\Http\Controllers\HomeController::class)-&gt;name("home");</code></pre>
<!-- generated -->
<p><a id='commands'> </a></p>
<!-- /generated -->
<h3>Commands</h3>
<p>We will replace the <code>setup.php</code> script with a <code>SetupDbCommand</code> that is located at
<code>app/Commands/SetupDbCommand.php</code></p>
<pre><code class="language-php">class SetupDbCommand extends Command
{
    /**
     * @var string
     */
    protected $name = "app:setup-db";

    /**
     * @var string
     */
    protected $description = "Run the application database setup";

    protected function getOptions(): array
    {
        return [
            [
                "drop",
                null,
                InputOption::VALUE_NONE,
                "If given, the existing database tables are dropped and recreated.",
            ],
        ];
    }

    public function handle()
    {
        $drop = $this-&gt;option("drop");
        if ($drop) {
            $this-&gt;info("Dropping all database tables...");

            $this-&gt;call(WipeCommand::class);

            $this-&gt;info("Done.");
        }

        $this-&gt;info("Running database migrations...");

        $this-&gt;call(MigrateCommand::class);

        $this-&gt;info("Done.");
    }
}</code></pre>
<p>Register it the <code>AppServiceProvider</code> in <code>app/Providers/AppServiceProvider.php</code></p>
<pre><code class="language-php">    public function register()
    {
        $this-&gt;commands([
            \App\Commands\SetupDbCommand::class
        ]);
    }</code></pre>
<p>and update the <code>setup-db</code> target in <code>.make/01-00-application-setup.mk</code> to run the <code>artisan</code> Command</p>
<pre><code class="language-Makefile">.PHONY: setup-db
setup-db: ## Setup the DB tables
    $(EXECUTE_IN_APPLICATION_CONTAINER) php artisan app:setup-db $(ARGS);</code></pre>
<p>We will also create a migration for the <code>jobs</code> table in
<code>database/migrations/2022_02_10_000000_create_jobs_table.php</code>:</p>
<pre><code class="language-php">return new class extends Migration
{
    public function up(): void
    {
        Schema::create('jobs', function (Blueprint $table) {
            $table-&gt;id();
            $table-&gt;string('value');
        });
    }
};</code></pre>
<!-- generated -->
<p><a id='jobs-and-workers'> </a></p>
<!-- /generated -->
<h3>Jobs and workers</h3>
<p>We will replace the <code>worker.php</code> script with <code>InsertInDbJob</code> located at
<code>app/Jobs/InsertInDbJob.php</code></p>
<pre><code class="language-php">class InsertInDbJob implements ShouldQueue
{
    use Dispatchable, InteractsWithQueue, Queueable;

    public function __construct(
        public readonly string $jobId
    ) {
    }

    public function handle(DatabaseManager $databaseManager)
    {
        $databaseManager-&gt;insert("INSERT INTO `jobs`(value) VALUES(?)", [$this-&gt;jobId]);
    }
}</code></pre>
<p>though this will &quot;only&quot; handle the insertion part. For the worker itself we will use the native
<code>\Illuminate\Queue\Console\WorkCommand</code> via</p>
<pre><code>php artisan queue:work</code></pre>
<p>We need to adjust the <code>.docker/images/php/worker/Dockerfile</code> and change</p>
<pre><code>ARG PHP_WORKER_COMMAND="php $APP_CODE_PATH/worker.php"</code></pre>
<p>to</p>
<pre><code>ARG PHP_WORKER_COMMAND="php $APP_CODE_PATH/artisan queue:work"</code></pre>
<p>Since this change takes place directly in the Dockerfile, we must now rebuild the image </p>
<pre><code>$ make docker-build-image DOCKER_SERVICE_NAME=php-worker</code></pre>
<p>and restart it</p>
<pre><code>$ make docker-up</code></pre>
<!-- generated -->
<p><a id='tests'> </a></p>
<!-- /generated -->
<h3>Tests</h3>
<p>I'd also like to take this opportunity to add a <code>Feature</code> test for the <code>HomeController</code> at
<code>tests/Feature/App/Http/Controllers/HomeControllerTest.php</code>:</p>
<pre><code class="language-php">class HomeControllerTest extends TestCase
{
    public function setUp(): void
    {
        parent::setUp();

        $this-&gt;setupDatabase();
        $this-&gt;setupQueue();
    }

    /**
     * @dataProvider __invoke_dataProvider
     */
    public function test___invoke(array $params, string $expected): void
    {
        $urlGenerator = $this-&gt;getDependency(UrlGenerator::class);

        $url = $urlGenerator-&gt;route("home", $params);

        $response = $this-&gt;get($url);

        $response
            -&gt;assertStatus(200)
            -&gt;assertSee($expected, false)
        ;
    }

    public function __invoke_dataProvider(): array
    {
        return [
            "default"           =&gt; [
                "params"   =&gt; [],
                "expected" =&gt; &lt;&lt;&lt;TEXT
                        &lt;li&gt;&lt;a href="?dispatch=foo"&gt;Dispatch job 'foo' to the queue.&lt;/a&gt;&lt;/li&gt;
                        &lt;li&gt;&lt;a href="?queue"&gt;Show the queue.&lt;/a&gt;&lt;/li&gt;
                        &lt;li&gt;&lt;a href="?db"&gt;Show the DB.&lt;/a&gt;&lt;/li&gt;
                    TEXT
                ,
            ],
            "database is empty" =&gt; [
                "params"   =&gt; ["db"],
                "expected" =&gt; &lt;&lt;&lt;TEXT
                        Items in db
                    array (
                    )
                    TEXT
                ,
            ],
            "queue is empty"    =&gt; [
                "params"   =&gt; ["queue"],
                "expected" =&gt; &lt;&lt;&lt;TEXT
                        Items in queue
                    array (
                    )
                    TEXT
                ,
            ],
        ];
    }

    public function test_shows_existing_items_in_database(): void
    {
        $databaseManager = $this-&gt;getDependency(DatabaseManager::class);

        $databaseManager-&gt;insert("INSERT INTO `jobs` (id, value) VALUES(1, 'foo');");

        $urlGenerator = $this-&gt;getDependency(UrlGenerator::class);

        $params = ["db"];
        $url    = $urlGenerator-&gt;route("home", $params);

        $response = $this-&gt;get($url);

        $expected = &lt;&lt;&lt;TEXT
                Items in db
            array (
              0 =&gt; 
              (object) array(
                 'id' =&gt; 1,
                 'value' =&gt; 'foo',
              ),
            )
            TEXT;

        $response
            -&gt;assertStatus(200)
            -&gt;assertSee($expected, false)
        ;
    }

    public function test_shows_existing_items_in_queue(): void
    {
        $queueManager = $this-&gt;getDependency(QueueManager::class);

        $job = new InsertInDbJob("foo");
        $queueManager-&gt;push($job);

        $urlGenerator = $this-&gt;getDependency(UrlGenerator::class);

        $params = ["queue"];
        $url    = $urlGenerator-&gt;route("home", $params);

        $response = $this-&gt;get($url);

        $expectedJobsCount = &lt;&lt;&lt;TEXT
                Items in queue
            array (
              0 =&gt; '{
            TEXT;

        $expected = &lt;&lt;&lt;TEXT
            \\\\"jobId\\\\";s:3:\\\\"foo\\\\";
            TEXT;

        $response
            -&gt;assertStatus(200)
            -&gt;assertSee($expectedJobsCount, false)
            -&gt;assertSee($expected, false)
        ;
    }
}</code></pre>
<p>The test checks the database as well as the queue and uses the helper methods
<code>$this-&gt;setupDatabase()</code> and <code>$this-&gt;setupQueue()</code> that I defined in the base test case at
<code>tests/TestCase.php</code> as follows</p>
<pre><code class="language-php">   /**
     * @template T
     * @param class-string&lt;T&gt; $className
     * @return T
     */
    protected function getDependency(string $className)
    {
        return $this-&gt;app-&gt;get($className);
    }

    protected function setupDatabase(): void
    {
        $databaseManager = $this-&gt;getDependency(DatabaseManager::class);

        $actualConnection  = $databaseManager-&gt;getDefaultConnection();
        $testingConnection = "testing";
        if ($actualConnection !== $testingConnection) {
            throw new RuntimeException("Database tests are only allowed to run on default connection '$testingConnection'. The current default connection is '$actualConnection'.");
        }

        $this-&gt;ensureDatabaseExists($databaseManager);

        $this-&gt;artisan(SetupDbCommand::class, ["--drop" =&gt; true]);
    }

    protected function setupQueue(): void
    {
        $queueManager = $this-&gt;getDependency(QueueManager::class);

        $actualDriver  = $queueManager-&gt;getDefaultDriver();
        $testingDriver = "testing";
        if ($actualDriver !== $testingDriver) {
            throw new RuntimeException("Queue tests are only allowed to run on default driver '$testingDriver'. The current default driver is '$actualDriver'.");
        }

        $this-&gt;artisan(ClearCommand::class);
    }

    protected function ensureDatabaseExists(DatabaseManager $databaseManager): void
    {
        $connection = $databaseManager-&gt;connection();

        try {
            $connection-&gt;getPdo();
        } catch (PDOException $e) {
            // e.g. SQLSTATE[HY000] [1049] Unknown database 'testing'
            if ($e-&gt;getCode() !== 1049) {
                throw $e;
            }
            $config             = $connection-&gt;getConfig();
            $config["database"] = "";

            $connector = new MySqlConnector();
            $pdo       = $connector-&gt;connect($config);
            $database  = $connection-&gt;getDatabaseName();
            $pdo-&gt;exec("CREATE DATABASE IF NOT EXISTS `{$database}`;");
        }
    }</code></pre>
<p>The methods ensure that the tests are only executed if the proper database connection and queue
driver is configured. This is done through environment variables and I like using
<a href="https://laravel.com/docs/9.x/testing#the-env-testing-environment-file">a dedicated <code>.env</code> file located at <code>.env.testing</code></a><br />
for all testing <code>ENV</code> values instead of defining them in the <code>phpunit.xml</code> config file via <code>&lt;env&gt;</code>
elements:</p>
<pre><code class="language-dotenv"># File: .env.testing

DB_CONNECTION=testing
DB_DATABASE=testing
QUEUE_CONNECTION=testing
REDIS_DB=1000</code></pre>
<p>The corresponding connections have to be configured in the <code>config</code> files</p>
<pre><code class="language-php"># File: config/database.php

return [
// ...
    'connections' =&gt; [
// ...
        'testing' =&gt; [
            'driver' =&gt; 'mysql',
            'url' =&gt; env('DATABASE_URL'),
            'host' =&gt; env('DB_HOST'),
            'port' =&gt; env('DB_PORT', '3306'),
            'database' =&gt; env('DB_DATABASE', 'testing'),
            'username' =&gt; env('DB_USERNAME'),
            'password' =&gt; env('DB_PASSWORD', ''),
            'unix_socket' =&gt; env('DB_SOCKET', ''),
            'charset' =&gt; 'utf8mb4',
            'collation' =&gt; 'utf8mb4_unicode_ci',
            'prefix' =&gt; '',
            'prefix_indexes' =&gt; true,
            'strict' =&gt; true,
            'engine' =&gt; null,
            'options' =&gt; extension_loaded('pdo_mysql') ? array_filter([
                PDO::MYSQL_ATTR_SSL_CA =&gt; env('MYSQL_ATTR_SSL_CA'),
            ]) : [],
        ],
    ],
// ...
    'redis' =&gt; [
// ...
        'testing' =&gt; [
            'url' =&gt; env('REDIS_URL'),
            'host' =&gt; env('REDIS_HOST', '127.0.0.1'),
            'password' =&gt; env('REDIS_PASSWORD'),
            'port' =&gt; env('REDIS_PORT', '6379'),
            'database' =&gt; env('REDIS_DB', '1000'),
        ],
    ],
];</code></pre>
<pre><code class="language-php"># File: config/queue.php

return [
// ...

    'connections' =&gt; [
// ...
        'testing' =&gt; [
            'driver' =&gt; 'redis',
            'connection' =&gt; 'testing', // =&gt; refers to the "database.redis.testing" config entry
            'queue' =&gt; env('REDIS_QUEUE', 'default'),
            'retry_after' =&gt; 90,
            'block_for' =&gt; null,
            'after_commit' =&gt; false,
        ],
    ],
];</code></pre>
<p>The tests can be executed via <code>make test</code></p>
<pre><code>$ make test
ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application php-worker vendor/bin/phpunit -c phpunit.xml
PHPUnit 9.5.13 by Sebastian Bergmann and contributors.

.......                                                             7 / 7 (100%)

Time: 00:02.709, Memory: 28.00 MB

OK (7 tests, 13 assertions)</code></pre>
<!-- generated -->
<p><a id='makefile-updates'> </a></p>
<!-- /generated -->
<h2>Makefile updates</h2>
<!-- generated -->
<p><a id='clearing-the-queue'> </a></p>
<!-- /generated -->
<h3>Clearing the queue</h3>
<p>For convenience while testing I added a make target to clear all items from the queue in
<code>.make/01-01-application-commands.mk</code></p>
<pre><code class="language-Makefile">.PHONY: clear-queue
clear-queue: ## Clear the job queue
    $(EXECUTE_IN_APPLICATION_CONTAINER) php artisan queue:clear $(ARGS)</code></pre>
<!-- generated -->
<p><a id='running-the-poc'> </a></p>
<!-- /generated -->
<h2>Running the POC</h2>
<p>Since the POC only uses <code>make</code> targets and we basically just &quot;refactored&quot; them, there is no
modification necessary to make the existing <code>test.sh</code> work:</p>
<pre><code>$ bash test.sh

  Building the docker setup

//...

  Starting the docker setup

//...

  Clearing DB

ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application application php artisan app:setup-db --drop;
Dropping all database tables...
Dropped all tables successfully.
Done.
Running database migrations...
Migration table created successfully.
Migrating: 2014_10_12_000000_create_users_table
Migrated:  2014_10_12_000000_create_users_table (64.04ms)
Migrating: 2014_10_12_100000_create_password_resets_table
Migrated:  2014_10_12_100000_create_password_resets_table (50.06ms)
Migrating: 2019_08_19_000000_create_failed_jobs_table
Migrated:  2019_08_19_000000_create_failed_jobs_table (58.61ms)
Migrating: 2019_12_14_000001_create_personal_access_tokens_table
Migrated:  2019_12_14_000001_create_personal_access_tokens_table (94.03ms)
Migrating: 2022_02_10_000000_create_jobs_table
Migrated:  2022_02_10_000000_create_jobs_table (31.85ms)
Done.

  Stopping workers

ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application php-worker supervisorctl stop worker:*;
worker:worker_00: stopped
worker:worker_01: stopped
worker:worker_02: stopped
worker:worker_03: stopped

  Ensuring that queue and db are empty

&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Items in queue
array (
)
    &lt;/body&gt;
&lt;/html&gt;
&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Items in db
array (
)
    &lt;/body&gt;
&lt;/html&gt;

  Dispatching a job 'foo'

&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Adding item 'foo' to queue
    &lt;/body&gt;
&lt;/html&gt;

  Asserting the job 'foo' is on the queue

&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Items in queue
array (
  0 =&gt; '{"uuid":"7ea63590-2a86-4739-abf8-8a059d41bd60","displayName":"App\\\\Jobs\\\\InsertInDbJob","job":"Illuminate\\\\Queue\\\\CallQueuedHandler@call","maxTries":null,"maxExceptions":null,"failOnTimeout":false,"backoff":null,"timeout":null,"retryUntil":null,"data":{"commandName":"App\\\\Jobs\\\\InsertInDbJob","command":"O:22:\\"App\\\\Jobs\\\\InsertInDbJob\\":11:{s:5:\\"jobId\\";s:3:\\"foo\\";s:3:\\"job\\";N;s:10:\\"connection\\";N;s:5:\\"queue\\";N;s:15:\\"chainConnection\\";N;s:10:\\"chainQueue\\";N;s:19:\\"chainCatchCallbacks\\";N;s:5:\\"delay\\";N;s:11:\\"afterCommit\\";N;s:10:\\"middleware\\";a:0:{}s:7:\\"chained\\";a:0:{}}"},"id":"I3k5PNyGZc6Z5XWCC4gt0qtSdqUZ84FU","attempts":0}',
)
    &lt;/body&gt;
&lt;/html&gt;

  Starting the workers

ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application php-worker supervisorctl start worker:*;
worker:worker_00: started
worker:worker_01: started
worker:worker_02: started
worker:worker_03: started

  Asserting the queue is now empty

&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Items in queue
array (
)
    &lt;/body&gt;
&lt;/html&gt;

  Asserting the db now contains the job 'foo'

&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset="utf-8"&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Items in db
array (
  0 =&gt;
  (object) array(
     'id' =&gt; 1,
     'value' =&gt; 'foo',
  ),
)
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<!-- generated -->
<p><a id='wrapping-up'> </a></p>
<!-- /generated -->
<h2>Wrapping up</h2>
<p>Congratulations, you made it! If some things are not completely clear by now, don't hesitate to
leave a comment. Laravel 9 should now be up and running on the previously set up docker
infrastructure.</p>
<p>In the next part of this tutorial, we will add some code quality tools and configure CI/CD
pipelines on Github and Gitlab.</p>
<p>Please subscribe to the <a href="/feed.xml">RSS feed</a> or <a href="#newsletter">via email</a> to get automatic
notifications when this next part comes out :)</p>]]></description>
                <pubDate>Wed, 23 Mar 2022 12:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/blog/run-laravel-9-docker-in-2022/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/blog/run-laravel-9-docker-in-2022/</guid>
            </item>
                    <item>
                <title>PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022 [Tutorial Part 4.2]</title>
                <description><![CDATA[<p>In this part of the tutorial series on developing PHP on Docker we
will <strong>setup our local development environment to be used by PhpStorm and Xdebug</strong>. We will also
ensure that we can run <strong>PHPUnit tests from the command line as well as from PhpStorm</strong> and throw
the tool <code>strace</code> into the mix for debugging long running processes.</p>
<div class="center-div">
<iframe width="560" height="315" src="https://www.youtube.com/embed/bZ1MiynqT98" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<p>All code samples are publicly available in my
<a href="https://github.com/paslandau/docker-php-tutorial">Docker PHP Tutorial repository on github</a>.<br />
You find the branch for this tutorial at
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-4-2-phpstorm-docker-xdebug-3-php-8-1-in-2022">part-4-2-phpstorm-docker-xdebug-3-php-8-1-in-2022</a></p>
<!-- generated -->
<p><a id='published-parts-of-the-docker-php-tutorial'> </a></p>
<!-- /generated -->
<h2>Published parts of the Docker PHP Tutorial</h2>
<ul>
<li><a href="/blog/php-php-fpm-and-nginx-on-docker-in-windows-10/">Setting up PHP, PHP-FPM and NGINX for local development on Docker</a>
(2018-07-08)</li>
<li><a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
(2018-08-06)</li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
(2019-05-20)</li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
(2022-03-21)</li>
<li><a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>
(2022-03-22)</li>
<li><a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>
(2022-03-23)</li>
<li><a href="/blog/php-qa-tools-make-docker/">Set up PHP QA tools and control them via make</a>
(2022-04-25)</li>
<li><a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
(2022-04-25)</li>
<li><a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
(2022-04-25)</li>
</ul>
<p>If you want to follow along, please subscribe to the <a href="/feed.xml">RSS feed</a>
or <a href="#newsletter">via email</a>
to get automatic notifications when the next part comes out :)</p>
<!-- generated -->
<p><a id='table-of-contents'> </a></p>
<!-- /generated -->
<h2>Table of contents</h2>
<!-- toc -->
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#install-tools">Install Tools</a>
<ul>
<li><a href="#install-composer">Install composer</a></li>
<li><a href="#install-xdebug">Install Xdebug</a></li>
<li><a href="#install-phpunit">Install PHPUnit</a></li>
<li><a href="#install-ssh">Install SSH</a></li>
</ul></li>
<li><a href="#setup-phpstorm">Setup PhpStorm</a>
<ul>
<li><a href="#ssh-configuration">SSH Configuration</a></li>
<li><a href="#php-interpreter">PHP Interpreter</a></li>
<li><a href="#phpunit">PHPUnit</a></li>
<li><a href="#debugging">Debugging</a>
<ul>
<li><a href="#debug-code-executed-via-phpstorm">Debug code executed via PhpStorm</a></li>
<li><a href="#debug-code-executed-via-php-fpm-cli-or-from-a-worker">Debug code executed via php-fpm, cli or from a worker</a>
<ul>
<li><a href="#php-fpm">php-fpm</a></li>
<li><a href="#cli">cli</a></li>
<li><a href="#php-workers">php-workers</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#strace">strace</a></li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
<!-- /toc -->
<!-- generated -->
<p><a id='introduction'> </a></p>
<!-- /generated -->
<h2>Introduction</h2>
<p>This article is mostly an update of
<a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
but will also cover the &quot;remaining cases&quot; of <strong>debugging php-fpm</strong> and <strong>php worker processes</strong>. </p>
<p>We will still rely on an <strong>always-running docker setup</strong> that we connect to via an SSH Configuration
instead of using the
<a href="/blog/setup-phpstorm-with-xdebug-on-docker/#run-debug-a-php-script-on-docker-server">built-in docker-compose capabilities</a>
as I feel it's closer to what we do in CI / production. However, we will <strong>not use SSH keys</strong>
any longer but simply authenticate via password. This reduces complexity and removes any
pesky warnings regarding &quot;SSH keys being exposed in a repository&quot;.</p>
<!-- generated -->
<p><a id='install-tools'> </a></p>
<!-- /generated -->
<h2>Install Tools</h2>
<!-- generated -->
<p><a id='install-composer'> </a></p>
<!-- /generated -->
<h3>Install composer</h3>
<p><a href="https://getcomposer.org/">Composer</a> is installed by pulling
<a href="https://hub.docker.com/_/composer">the official composer docker image</a> and simply &quot;copying&quot; the
composer executable over to the base php image. In addition, composer needs the extensions
<code>mbstring</code> and <code>phar</code></p>
<pre><code># File: .docker/images/php/base/Dockerfile

ARG ALPINE_VERSION
ARG COMPOSER_VERSION
FROM composer:${COMPOSER_VERSION} as composer
FROM alpine:${ALPINE_VERSION} as base

# ...

RUN apk add --update --no-cache  \
        php-mbstring~=${TARGET_PHP_VERSION} \
        php-phar~=${TARGET_PHP_VERSION} \

# ...

COPY --from=composer /usr/bin/composer /usr/local/bin/composer</code></pre>
<p>Because we want our build to be deterministic, we &quot;pin&quot; the composer version by adding a
<code>COMPOSER_VERSION</code> variable to the <code>.docker/.env</code> file </p>
<pre><code class="language-dotenv">COMPOSER_VERSION=2.2.5</code></pre>
<p>and using it in <code>.docker/docker-compose/docker-compose-php-base.yml</code>:</p>
<pre><code class="language-yaml">services:
  php-base:
    build:
      args:
        - COMPOSER_VERSION=${COMPOSER_VERSION?}</code></pre>
<!-- generated -->
<p><a id='install-xdebug'> </a></p>
<!-- /generated -->
<h3>Install Xdebug</h3>
<p>Install the extension via <code>apk</code> (only for the <code>local</code> target):</p>
<pre><code class="language-Dockerfile"># File: .docker/images/php/base/Dockerfile

FROM base as local

RUN apk add --no-cache --update \
        php-xdebug~=${TARGET_PHP_VERSION} \
    # ensure that xdebug is not enabled by default
    &amp;&amp; rm -f /etc/php8/conf.d/00_xdebug.ini</code></pre>
<p>We also don't want to enable <code>xdebug</code> immediately but only when we need it (due to the decrease
in performance when the extension is enabled), hence we remove the default config file and
disable the extension in the application <code>.ini</code> file</p>
<pre><code># File: .docker/images/php/base/conf.d/zz-app-local.ini

; Note:
; Remove the comment ; to enable debugging
;zend_extension=xdebug
xdebug.client_host=host.docker.internal
xdebug.start_with_request=yes
xdebug.mode=debug</code></pre>
<p>See <a href="/blog/setup-phpstorm-with-xdebug-on-docker/#fix-xdebug-on-phpstorm-when-run-from-a-docker">Fix Xdebug on PhpStorm when run from a Docker container</a>
for an explanation of the <code>xdebug.client_host=host.docker.internal</code> setting (previously called
<code>xdebug.remote_host</code> in xdebug &lt; 3). This will still work out of the box for Docker Desktop, but
for Linux users we need to add the
<a href="https://github.com/docker/for-linux/issues/264#issuecomment-965465879"><code>host-gateway</code> magic reference</a>
<strong>to all PHP containers</strong> (we can't add it to the php base image because this is a runtime setting):</p>
<pre><code class="language-yaml">services:
  service:
    extra_hosts:
      - host.docker.internal:host-gateway</code></pre>
<p>Finally, we need to add
<a href="https://www.jetbrains.com/help/phpstorm/debugging-a-php-cli-script.html">the environment variable <code>PHP_IDE_CONFIG</code></a>
<strong>to all PHP containers</strong>. The variable is defined as <code>PHP_IDE_CONFIG=serverName=dofroscra</code>, where
&quot;dofroscra&quot; is the name of the server that we will configure later for debugging. Because we
need the same value in multiple places, the variable is configured in <code>.docker/.env</code>:</p>
<pre><code>PHP_IDE_CONFIG=serverName=dofroscra</code></pre>
<p>And then added in
<code>.docker/docker-compose/docker-compose.local.yml</code></p>
<pre><code class="language-yaml">services:
  php-fpm:
    environment:
      - PHP_IDE_CONFIG=${PHP_IDE_CONFIG?}

  php-worker:
    environment:
      - PHP_IDE_CONFIG=${PHP_IDE_CONFIG?}

  application:
    environment:
      - PHP_IDE_CONFIG=${PHP_IDE_CONFIG?}</code></pre>
<!-- generated -->
<p><a id='install-phpunit'> </a></p>
<!-- /generated -->
<h3>Install PHPUnit</h3>
<p>PHPUnit will be installed via <code>composer</code> but will not be &quot;baked into the image&quot; for local
development. Thus, we must run <code>composer require</code> <strong>in the container</strong>. To make this more
convenient a make target for running arbitrary composer commands is added in
<code>.make/01-00-application-setup.mk</code>:</p>
<pre><code class="language-makefile">.PHONY: composer
composer: ## Run composer commands. Specify the command e.g. via ARGS="install"
    $(EXECUTE_IN_APPLICATION_CONTAINER) composer $(ARGS);</code></pre>
<p>This allows me to run <code>make composer ARGS="install"</code> from the host system to execute <code>composer install</code> in the container. In consequence, <code>composer</code> will use the PHP version and extensions of
the <code>application</code> container to install the dependencies, yet I will still see the installed files
locally because the codebase is configured as a volume for the container.</p>
<p>Before installing phpunit, we must add the required extensions <code>dom</code> and <code>xml</code> to the container</p>
<pre><code># File: .docker/images/php/base/Dockerfile

# ...

RUN apk add --update --no-cache  \
        php-dom~=${TARGET_PHP_VERSION} \
        php-xml~=${TARGET_PHP_VERSION} \</code></pre>
<p>as well as rebuild and restart the docker setup via </p>
<pre><code>make docker-build
make docker-down
make docker-up</code></pre>
<p>Now we can add phpunit via</p>
<pre><code>make composer ARGS='require "phpunit/phpunit"'</code></pre>
<p>which will create a <code>composer.json</code> file and setup up the <code>vendor/</code> directory:</p>
<pre><code>$ make composer ARGS='require "phpunit/phpunit"'
Using version ^9.5 for phpunit/phpunit
./composer.json has been created
Running composer update phpunit/phpunit
Loading composer repositories with package information
Updating dependencies
...
</code></pre>
<p>I have also added </p>
<ul>
<li>a minimal <code>phpunit.xml</code> config file</li>
<li>a test case at <code>tests/SomeTest.php</code> </li>
<li>and a new Makefile for &quot;anything related to qa&quot; at <code>.make/01-02-application-qa.mk</code>:</li>
</ul>
<pre><code class="language-Makefile">##@ [Application: QA]

.PHONY: test
test: ## Run the test suite 
    $(EXECUTE_IN_WORKER_CONTAINER) vendor/bin/phpunit -c phpunit.xml</code></pre>
<p>So I can run tests simply via <code>make test</code></p>
<pre><code>$ make test
ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application php-worker vendor/bin/phpunit
PHPUnit 9.5.13 by Sebastian Bergmann and contributors.

.                                                                   1 / 1 (100%)

Time: 00:00.324, Memory: 4.00 MB

OK (1 test, 1 assertion)</code></pre>
<!-- generated -->
<p><a id='install-ssh'> </a></p>
<!-- /generated -->
<h3>Install SSH</h3>
<p>We will execute commands from PhpStorm via ssh in the <code>application</code> container. As mentioned, we
won't use a key file for authentication but will instead simply use a password that is
configured via the <code>APP_SSH_PASSWORD</code> variable in <code>.docker/.env</code> and passed to the image in
<code>.docker/docker-compose/docker-compose.local.yml</code>. In addition, we map port <code>2222</code> from the
host system to port <code>22</code> of the application container and make sure that the codebase is shared
as a volume between host and container</p>
<pre><code class="language-yaml">  application:
    build:
      args:
        - APP_SSH_PASSWORD=${APP_SSH_PASSWORD?}
    volumes:
      - ${APP_CODE_PATH_HOST?}:${APP_CODE_PATH_CONTAINER?}
    ports:
      - "${APPLICATION_SSH_HOST_PORT:-2222}:22"</code></pre>
<p>The container already contains <code>openssh</code> and sets the password</p>
<pre><code class="language-Dockerfile">ARG BASE_IMAGE
FROM ${BASE_IMAGE} as base

FROM base as local

RUN apk add --no-cache --update \
        openssh

ARG APP_SSH_PASSWORD
RUN echo "$APP_USER_NAME:$APP_SSH_PASSWORD" | chpasswd 2&gt;&amp;1

# Required to start sshd, otherwise the container will error out on startup with the message
# "sshd: no hostkeys available -- exiting."
# @see https://stackoverflow.com/a/65348102/413531 
RUN ssh-keygen -A

# we use SSH deployment configuration in PhpStorm for local development
EXPOSE 22

CMD ["/usr/sbin/sshd", "-D"]</code></pre>
<!-- generated -->
<p><a id='setup-phpstorm'> </a></p>
<!-- /generated -->
<h2>Setup PhpStorm</h2>
<p>We will configure a remote PHP interpreter that uses an SSH connection to run commands in the
<code>application</code> container. Before,
<a href="/blog/setup-phpstorm-with-xdebug-on-docker/#configure-the-deployment-configuration">we have been using an <code>SFTP Deployment configuration</code></a>
, which was kinda confusing (&quot;What is SFTP doing here?&quot;), so we will use an
<a href="https://www.jetbrains.com/help/phpstorm/create-ssh-configurations.html">SSH Configuration</a>
instead and configure the path mappings in the <strong>Cli Interpreter</strong> interface</p>
<!-- generated -->
<p><a id='ssh-configuration'> </a></p>
<!-- /generated -->
<h3>SSH Configuration</h3>
<p>At <code>File | Settings | Tools | SSH Configurations</code> create a new SSH Configuration named
&quot;Docker PHP Tutorial&quot; with the following settings </p>
<ul>
<li>Host: 127.0.0.1</li>
<li>Port: see <code>APPLICATION_SSH_HOST_PORT</code> in <code>.docker/docker-compose/docker-compose.local.yml</code></li>
<li>User name: see <code>APP_USER_NAME</code> in <code>.make/.env</code></li>
<li>Authentication type: Password</li>
<li>Password: see <code>APP_SSH_PASSWORD</code> in <code>.docker/.env</code></li>
</ul>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-ssh-configuration.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-ssh-configuration.PNG" alt="PhpStorm SSH Configuration" title="PhpStorm SSH Configuration" /></a></p>
<!-- generated -->
<p><a id='php-interpreter'> </a></p>
<!-- /generated -->
<h3>PHP Interpreter</h3>
<p>At <code>File | Settings | PHP</code> add a new PHP CLI interpreter that uses the new SSH Configuration</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-cli-interpreter.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-cli-interpreter.PNG" alt="PhpStorm new CLI interpreter" title="PhpStorm new CLI interpreter" /></a></p>
<p>In addition, we define the <strong>path to the xdebug extension</strong> because it is disabled by default but
PhpStorm can enable it automatically if required. You can find the path in the <code>application</code>
container via</p>
<pre><code>root:/var/www/app# php -i | grep extension_dir
extension_dir =&gt; /usr/lib/php8/modules =&gt; /usr/lib/php8/modules
root:/var/www/app# ll /usr/lib/php8/modules | grep xdebug
-rwxr-xr-x    1 root     root        303936 Jan  9 00:21 xdebug.so</code></pre>
<p>We still need to
<a href="/blog/setup-phpstorm-with-xdebug-on-docker/#fix-xdebug-on-phpstorm-when-run-from-a-docker-container">Fix Xdebug on PhpStorm when run from a Docker container</a>
by adding a custom PHP option for <code>xdebug.client_host=host.docker.internal</code>. That's the same value
we use in <code>.docker/images/php/base/conf.d/zz-app-local.ini</code>.</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-cli-interpreter-xdebug.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-cli-interpreter-xdebug.PNG" alt="PhpStorm Xdebug settings for the CLI interpreter" title="PhpStorm Xdebug settings for the CLI interpreter" /></a></p>
<p>In the interpreter overview we must now configure the <strong>path mappings</strong> so that PhpStorm knows
&quot;which local file belongs to which remote one&quot;. The remote folder is defined in <code>.docker/.env</code> via</p>
<pre><code class="language-dotenv">APP_CODE_PATH_CONTAINER=/var/www/app</code></pre>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-cli-interpreter-path-mappings.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-cli-interpreter-path-mappings.PNG" alt="PhpStorm path mappings for the CLI interpreter" title="PhpStorm path mappings for the CLI interpreter" /></a></p>
<p>Afterwards we can set a breakpoint e.g. in <code>setup.php</code> and start debugging:</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint.PNG" alt="PhpStorm debugging breakpoint" title="PhpStorm debugging breakpoint" /></a></p>
<p>The screenshot shows that PhpStorm adds the Xdebug extension that we defined previously.</p>
<!-- generated -->
<p><a id='phpunit'> </a></p>
<!-- /generated -->
<h3>PHPUnit</h3>
<p><code>phpunit</code> is configured via <code>File | Settings | PHP | Test Frameworks</code>. First, we select the
interpreter that we just added</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-phpunit-interpreter.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-phpunit-interpreter.PNG" alt="Set up phpunit in PhpStorm" title="Set up phpunit in PhpStorm" /></a></p>
<p>Then, we add the paths to the composer autoload script and the <code>phpunit.xml</code> configuration file.</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-phpunit-settings.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-phpunit-settings.PNG" alt="phpunit settings in PhpStorm" title="phpunit settings in PhpStorm" /></a></p>
<p>PhpStorm will now execute tests using the PHP interpreter in the <code>application</code> container</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-run-phpunit-test.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-run-phpunit-test.PNG" alt="Run a phpunit test in PhpStorm" title="Run a phpunit test in PhpStorm" /></a></p>
<!-- generated -->
<p><a id='debugging'> </a></p>
<!-- /generated -->
<h3>Debugging</h3>
<p>First of all, if you haven't already please also take a look at the
<a href="https://xdebug.org/docs/step_debug">official xdebug documentation</a>. Derick is doing a great job
at explaining xdebug in detail including some helpful videos like
<a href="https://www.youtube.com/watch?v=4opFac50Vwo">Xdebug 3: Xdebug with Docker and PhpStorm in 5 minutes</a></p>
<!-- generated -->
<p><a id='debug-code-executed-via-phpstorm'> </a></p>
<!-- /generated -->
<h4>Debug code executed via PhpStorm</h4>
<p>This should already work out of the box. Simply set a break point, right-click on a file and choose
&quot;Debug '...'&quot;</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint.PNG" alt="PhpStorm debugging breakpoint" title="PhpStorm debugging breakpoint" /></a></p>
<!-- generated -->
<p><a id='debug-code-executed-via-php-fpm-cli-or-from-a-worker'> </a></p>
<!-- /generated -->
<h4>Debug code executed via php-fpm, cli or from a worker</h4>
<p>For code that is executed &quot;directly&quot; by a container without PhpStorm, we first need to enable
<code>xdebug</code> in the container by removing the <code>;</code> in front of the extension in
<code>/etc/php8/conf.d/zz-app-local.ini</code></p>
<pre><code>; Note:
; Remove the comment ; to enable debugging
zend_extension=xdebug</code></pre>
<p>To make this a little more convenient, we use dedicated make recipes for those actions in
<code>.make/01-01-application-commands.mk</code></p>
<pre><code class="language-Makefile">.PHONY: execute-in-container
execute-in-container: ## Execute a command in a container. E.g. via "make execute-in-container DOCKER_SERVICE_NAME=php-fpm COMMAND="echo 'hello'"
    @$(if $(DOCKER_SERVICE_NAME),,$(error DOCKER_SERVICE_NAME is undefined))
    @$(if $(COMMAND),,$(error COMMAND is undefined))
    $(EXECUTE_IN_CONTAINER) $(COMMAND);

.PHONY: enable-xdebug
enable-xdebug: ## Enable xdebug in the given container specified by "DOCKER_SERVICE_NAME". E.g. "make enable-xdebug DOCKER_SERVICE_NAME=php-fpm"
    "$(MAKE)" execute-in-container APP_USER_NAME="root" DOCKER_SERVICE_NAME=$(DOCKER_SERVICE_NAME) COMMAND="sed -i 's/.*zend_extension=xdebug/zend_extension=xdebug/' '/etc/php8/conf.d/zz-app-local.ini'"

.PHONY: disable-xdebug
disable-xdebug: ## Disable xdebug in the given container specified by "DOCKER_SERVICE_NAME". E.g. "make enable-xdebug DOCKER_SERVICE_NAME=php-fpm"
    "$(MAKE)" execute-in-container APP_USER_NAME="root" DOCKER_SERVICE_NAME=$(DOCKER_SERVICE_NAME) COMMAND="sed -i 's/.*zend_extension=xdebug/;zend_extension=xdebug/' '/etc/php8/conf.d/zz-app-local.ini'"</code></pre>
<p>To capture incoming requests, we need to make PhpStorm listen for PHP Debug connections via
<code>Run | Start Listening for PHP Debug Connections</code>. </p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-start-listening-for-debug-connections.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-start-listening-for-debug-connections.PNG" alt="PhpStorm: Start Listening for PHP Debug Connections" title="PhpStorm: Start Listening for PHP Debug Connections" /></a></p>
<p>The corresponding ports are configured at <code>File | Settings | PHP | Debug</code>. In Xdebug &lt; 3 the
default port was <code>9000</code> and in <a href="https://xdebug.org/docs/all_settings#client_port">Xdebug 3 it is <code>9003</code></a> </p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-ports.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-ports.PNG" alt="PhpStorm: configure xdebug ports" title="PhpStorm: configure xdebug ports" /></a></p>
<p>Finally, we need to add a server via <code>File | Settings | PHP | Servers</code></p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-server.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-server.PNG" alt="PhpStorm: configure a server" title="PhpStorm: configure a server" /></a></p>
<p>The name of the server must match the value of the <code>serverName</code> key in the environment variable
<code>PHP_IDE_CONFIG</code> that we configured previously as <code>serverName=dofroscra</code>.</p>
<!-- generated -->
<p><a id='php-fpm'> </a></p>
<!-- /generated -->
<h5>php-fpm</h5>
<p>For <code>php-fpm</code> we must
<a href="https://stackoverflow.com/a/43076457">restart the <code>php-fpm</code> process without restarting the container</a>
after we have activated <code>xdebug</code> via</p>
<pre><code>kill -USR2 1</code></pre>
<p>Since this is a pain to remember, we add a make target in <code>.make/01-01-application-commands.mk</code></p>
<pre><code class="language-Makefile"># @see https://stackoverflow.com/a/43076457
.PHONY: restart-php-fpm
restart-php-fpm: ## Restart the php-fpm service
    "$(MAKE)" execute-in-container DOCKER_SERVICE_NAME=$(DOCKER_SERVICE_NAME_PHP_FPM) COMMAND="kill -USR2 1"</code></pre>
<p>So we can now simply run</p>
<pre><code>make enable-xdebug DOCKER_SERVICE_NAME=php-fpm
make restart-php-fpm</code></pre>
<p>Setting a breakpoint in <code>public/index.php</code> and opening <a href="http://127.0.0.1/">http://127.0.0.1/</a> in
a browser or via <code>curl http://127.0.0.1/</code> will halt the execution as expected.</p>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint-php-fpm.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint-php-fpm.PNG" alt="PhpStorm debugging breakpoint for php-fpm" title="PhpStorm debugging breakpoint for php-fpm" /></a></p>
<!-- generated -->
<p><a id='cli'> </a></p>
<!-- /generated -->
<h5>cli</h5>
<p>Instead of triggering a PHP script via HTTP request, we can also run CLI scripts - think of the
<code>make setup-db</code> target for instance. To debug such invocations, we need to follow the same steps
as before:</p>
<ul>
<li>enable the <code>xdebug</code> extension in the <code>application</code> container</li>
<li>&quot;Listening for PHP Debug Connections&quot; from PhpStorm</li>
</ul>
<p>Running the following make targets will trigger a breakpoint in <code>setup.php</code>:</p>
<pre><code>make enable-xdebug DOCKER_SERVICE_NAME=application
make setup-db</code></pre>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint-cli.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint-cli.PNG" alt="PhpStorm debugging breakpoint for cli" title="PhpStorm debugging breakpoint for cli" /></a></p>
<!-- generated -->
<p><a id='php-workers'> </a></p>
<!-- /generated -->
<h5>php-workers</h5>
<p>And finally the same thing for long running PHP processes (aka workers). Just as before:</p>
<ul>
<li>enable the <code>xdebug</code> extension in the <code>php-worker</code> container</li>
<li>&quot;Listening for PHP Debug Connections&quot; from PhpStorm</li>
<li>restart the php workers  </li>
</ul>
<p>Running the following make targets will trigger a breakpoint in <code>worker.php</code>:</p>
<pre><code>make enable-xdebug DOCKER_SERVICE_NAME=php-worker
make restart-workers</code></pre>
<p><a href="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint-php-worker.PNG"><img src="/img/phpstorm-docker-xdebug-3-php-8-1-in-2022/phpstorm-xdebug-breakpoint-php-worker.PNG" alt="PhpStorm debugging breakpoint for php-workers" title="PhpStorm debugging breakpoint for php-workers" /></a></p>
<!-- generated -->
<p><a id='strace'> </a></p>
<!-- /generated -->
<h2>strace</h2>
<p><a href="https://strace.io/">strace</a> is a great tool for debugging long running processes that I've
adopted after reading <a href="https://derickrethans.nl/what-is-php-doing.html">What is PHP doing?</a>. I've
added it to the php base image:</p>
<pre><code class="language-Dockerfile">RUN apk add --update --no-cache \
        strace</code></pre>
<p>You can attach to any running process via <code>sudo strace -p $processId</code> - BUT that doesn't work
out of the box on docker and will fail with the error message</p>
<pre><code>strace: attach: ptrace(PTRACE_SEIZE, 1): Operation not permitted</code></pre>
<p>This is caused by a security measure from docker and
<a href="https://stackoverflow.com/a/46676868">can be circumvented</a> by adding</p>
<pre><code class="language-yaml">services:
  service:
    cap_add:
      - "SYS_PTRACE"
    security_opt:
      - "seccomp=unconfined"</code></pre>
<p>in <code>.docker/docker-compose/docker-compose.local.yml</code> <strong>to all PHP containers</strong>. After
rebuilding and restarting the docker setup, you can now e.g. log in the <code>php-worker</code> container
and run <code>strace</code> on a php worker process:</p>
<pre><code>application:/var/www/app# ps aux
PID   USER     TIME  COMMAND
    1 applicat  0:00 {supervisord} /usr/bin/python3 /usr/bin/supervisord
    7 applicat  0:00 php /var/www/app/worker.php
    8 applicat  0:00 php /var/www/app/worker.php
    9 applicat  0:00 php /var/www/app/worker.php
   10 applicat  0:00 php /var/www/app/worker.php
   11 applicat  0:00 bash
   20 applicat  0:00 ps aux
application:/var/www/app# sudo strace -p 7
strace: Process 7 attached
restart_syscall(&lt;... resuming interrupted read ...&gt;) = 0
poll([{fd=4, events=POLLIN|POLLPRI|POLLERR|POLLHUP}], 1, 0) = 0 (Timeout)
sendto(4, "*2\r\n$4\r\nRPOP\r\n$5\r\nqueue\r\n", 25, MSG_DONTWAIT, NULL, 0) = 25
poll([{fd=4, events=POLLIN|POLLPRI|POLLERR|POLLHUP}], 1, 0) = 1 ([{fd=4, revents=POLLIN}])
recvfrom(4, "$", 1, MSG_PEEK, NULL, NULL) = 1</code></pre>
<!-- generated -->
<p><a id='wrapping-up'> </a></p>
<!-- /generated -->
<h2>Wrapping up</h2>
<p>Congratulations, you made it! If some things are not completely clear by now, don't hesitate to
leave a comment. Apart from that, you should now have a fully configured development setup that
works with PhpStorm as your IDE.</p>
<p>In the next part of this tutorial, we will
<a href="/blog/run-laravel-9-docker-in-2022/">use a fresh installation of Laravel on top of our setup</a>.</p>
<p>Please subscribe to the <a href="/feed.xml">RSS feed</a> or <a href="#newsletter">via email</a> to get automatic
notifications when this next part comes out :)</p>]]></description>
                <pubDate>Tue, 22 Mar 2022 11:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/</guid>
            </item>
                    <item>
                <title>Docker from scratch for PHP 8.1 Applications in 2022 [Tutorial Part 4.1]</title>
                <description><![CDATA[<p>In the fourth part of this tutorial series on developing PHP on Docker we will revisit the previous
tutorials and update some things to be up-to-date in 2022. The article will be split in 3
subparts:</p>
<ul>
<li>Part 4.1: Update the code structure (<strong>this article</strong>)
<ul>
<li>we'll also introduce three new containers (PHP workers, MySQL and redis) and add a small proof
of concept to tie all containers together</li>
</ul></li>
<li>Part 4.2: Add the tools for local development (
<a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>,
<strong>available at 2022-03-22</strong>)
<ul>
<li>make the setup work with PhpStorm, including the ability to execute phpunit tests and run
xdebug for all php containers (application, fpm and php workers)</li>
</ul></li>
<li>Part4.3: Include Laravel (
<a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>,
<strong>available at 2022-03-23</strong>)
<ul>
<li>refactor the code to use Commands, Controllers, Queues, etc.</li>
</ul></li>
</ul>
<div class="center-div">
<iframe width="560" height="315" src="https://www.youtube.com/embed/NuSWKx9FSso" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<p>All code samples are publicly available in my
<a href="https://github.com/paslandau/docker-php-tutorial">Docker PHP Tutorial repository on github</a>.<br />
You find the branch for this tutorial at
<a href="https://github.com/paslandau/docker-php-tutorial/tree/part-4-1-docker-from-scratch-for-php-applications-in-2022">part-4-1-docker-from-scratch-for-php-applications-in-2022</a></p>
<!-- generated -->
<p><a id='published-parts-of-the-docker-php-tutorial'> </a></p>
<!-- /generated -->
<h2>Published parts of the Docker PHP Tutorial</h2>
<ul>
<li><a href="/blog/php-php-fpm-and-nginx-on-docker-in-windows-10/">Setting up PHP, PHP-FPM and NGINX for local development on Docker</a>
(2018-07-08)</li>
<li><a href="/blog/setup-phpstorm-with-xdebug-on-docker/">Setting up PhpStorm with Xdebug for local development on Docker</a>
(2018-08-06)</li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
(2019-05-20)</li>
<li><a href="/blog/docker-from-scratch-for-php-applications-in-2022/">Docker from scratch for PHP 8.1 Applications in 2022</a>
(2022-03-21)</li>
<li><a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">PhpStorm, Docker and Xdebug 3 on PHP 8.1 in 2022</a>
(2022-03-22)</li>
<li><a href="/blog/run-laravel-9-docker-in-2022/">Run Laravel 9 on Docker in 2022</a>
(2022-03-23)</li>
<li><a href="/blog/php-qa-tools-make-docker/">Set up PHP QA tools and control them via make</a>
(2022-04-25)</li>
<li><a href="/blog/git-secret-encrypt-repository-docker/">Use git-secret to encrypt secrets in the repository</a>
(2022-04-25)</li>
<li><a href="/blog/ci-pipeline-docker-php-gitlab-github/">Create a CI pipeline for dockerized PHP Apps</a>
(2022-04-25)</li>
</ul>
<p>If you want to follow along, please subscribe to the <a href="/feed.xml">RSS feed</a>
or <a href="#newsletter">via email</a>
to get automatic notifications when the next part comes out :)</p>
<!-- generated -->
<p><a id='table-of-contents'> </a></p>
<!-- /generated -->
<h2>Table of contents</h2>
<!-- toc -->
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#local-docker-setup">Local docker setup</a></li>
<li><a href="#docker">Docker</a>
<ul>
<li><a href="#docker-compose">docker-compose</a>
<ul>
<li><a href="#docker-env-file-and-required-env-variables"><code>.docker/.env</code> file and required ENV variables</a></li>
</ul></li>
<li><a href="#images">Images</a>
<ul>
<li><a href="#php-images">PHP images</a>
<ul>
<li><a href="#env-vs-arg">ENV vs ARG</a></li>
</ul></li>
<li><a href="#image-naming-convention">Image naming convention</a></li>
<li><a href="#environments-and-build-targets">Environments and build targets</a></li>
</ul></li>
</ul></li>
<li><a href="#makefile">Makefile</a>
<ul>
<li><a href="#make-mk-includes"><code>.make/*.mk</code> includes</a></li>
<li><a href="#shared-variables-make-env">Shared variables: <code>.make/.env</code></a></li>
<li><a href="#enforce-required-parameters">Enforce required parameters</a></li>
</ul></li>
<li><a href="#make-docker-3">Make + Docker = &lt;3</a>
<ul>
<li><a href="#ensuring-the-build-order">Ensuring the build order</a></li>
<li><a href="#run-commands-in-the-docker-containers">Run commands in the docker containers</a></li>
</ul></li>
<li><a href="#php-poc">PHP POC</a></li>
<li><a href="#wrapping-up">Wrapping up</a></li>
</ul>
<!-- /toc -->
<!-- generated -->
<p><a id='introduction'> </a></p>
<!-- /generated -->
<h2>Introduction</h2>
<p>If you have read the previous
tutorial <a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>
you might encounter some significant changes. The tutorial was published over 2 years ago,
Docker has evolved and I have learned more about it. Plus, I gathered practical
experience (good and bad) with the previous setup. I would now consider most of the points under
<a href="/blog/structuring-the-docker-setup-for-php-projects/#fundamentals-on-building-the-containers">Fundamentals on building the containers</a>
as either &quot;not required&quot; or simply &quot;overengineered / too complex&quot;. To be concrete:</p>
<ul>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#setting-the-timezone">Setting the timezone</a>
<ul>
<li>not required if the default is already UTC (which is almost always the case)</li>
</ul></li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#synchronizing-file-and-folder-ownership-on-shared-volumes">Synchronizing file and folder ownership on shared volumes</a>
<ul>
<li>this is only an issue if files need to be <strong>modified</strong> by containers and the host system - which
is only really relevant for the PHP containers</li>
<li>in addition, I would recommend adding a completely new user (e.g. <code>application</code>) instead of
re-using an existing one like <code>www-data</code> - this simplifies the whole user setup <em>a lot</em></li>
</ul></li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#modifying-configuration-files">Modifying configuration files</a>
<ul>
<li>just use <code>sed</code> - no need for a dedicated script</li>
</ul></li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#installing-php-extensions">Installing php extensions</a>
<ul>
<li>see <a href="#php-images">PHP images</a> - will now be done via <code>apk add</code></li>
</ul></li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#installing-common-software">Installing common software</a>
<ul>
<li>see <a href="#php-images">PHP images</a> - since there is only one base image there is no need for a
dedicated script</li>
</ul></li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#cleaning-up">Cleaning up</a>
<ul>
<li>didn't really make sense because the &quot;cleaned up files&quot; were already part of a previous layer</li>
<li>we might &quot;bring it back&quot; later when we optimize the image size to speed up the pushing/pulling
of the images to/from the registry</li>
</ul></li>
<li><a href="/blog/structuring-the-docker-setup-for-php-projects/#providing-host-docker-internal-for-linux-host-systems">Providing host.docker.internal for linux host systems</a>
<ul>
<li>can now be done via
the <a href="https://github.com/docker/for-linux/issues/264#issuecomment-965465879"><code>host-gateway</code> magic reference</a>
<pre><code class="language-yaml">services:
 myservice:
      extra_hosts:
        - host.docker.internal:host-gateway</code></pre></li>
<li>thus, no custom entrypoint is required any longer</li>
</ul></li>
</ul>
<!-- generated -->
<p><a id='local-docker-setup'> </a></p>
<!-- /generated -->
<h2>Local docker setup</h2>
<p>The goal of this part is the introduction of a working local setup <strong>without development tools</strong>. In
other words: We want the bare minimum to have something running locally.</p>
<p>The main components are:</p>
<ul>
<li>the <code>make</code> setup in the <code>Makefile</code> and in the <code>.make/</code> directory</li>
<li>the docker setup in the <code>.docker/</code> directory</li>
<li>some PHP files that act as a POC for the end2end functionality of the docker setup</li>
</ul>
<p>Check out the code via</p>
<pre><code>git checkout part_4_section_1_docker_from_scratch_for_php_applications_in_2022_code_structure</code></pre>
<p>initialize it via</p>
<pre><code>make make-init
make docker-build</code></pre>
<p>and run it via</p>
<pre><code>make docker-up</code></pre>
<p>Now you can access the web interface via <a href="http://127.0.0.1">http://127.0.0.1</a>. The following
diagram shows how the containers are connected</p>
<p><a href="/img/docker-from-scratch-for-php-applications-in-2022/docker-containers.PNG"><img src="/img/docker-from-scratch-for-php-applications-in-2022/docker-containers.PNG" alt="Docker container connections" title="Docker container connections" /></a></p>
<p>See also the <a href="#php-poc">PHP POC</a> for a full test of the setup.</p>
<!-- generated -->
<p><a id='docker'> </a></p>
<!-- /generated -->
<h2>Docker</h2>
<p>The docker setup consists of</p>
<ul>
<li>an nginx container as a webserver</li>
<li>a MySQL database container</li>
<li>a Redis container that acts as a queue</li>
<li>a php base image that is used by
<ul>
<li>a php worker container that spawns multiple PHP worker processes via <code>supervisor</code></li>
<li>a php-fpm container as a backend for the nginx container</li>
<li>an application container that we use to run commands</li>
</ul></li>
</ul>
<p><a href="/img/docker-from-scratch-for-php-applications-in-2022/docker-images.PNG"><img src="/img/docker-from-scratch-for-php-applications-in-2022/docker-images.PNG" alt="Docker images" title="Docker images" /></a></p>
<p>We keep the <a href="/blog/structuring-the-docker-setup-for-php-projects/#the-docker-folder"><code>.docker/</code> directory from the previous tutorial</a>
, though it will be split into <code>docker-compose/</code> and <code>images/</code> like so:</p>
<pre><code>.
 .docker/
     docker-compose/
    |    docker-compose.yml
    |    &lt;other docker-compose files&gt;
     images/
    |    nginx/
    |   |    Dockerfile
    |   |    &lt;other files for the nginx image&gt;
    |    &lt;other folders for docker images&gt;
     .env
     .env.example</code></pre>
<!-- generated -->
<p><a id='docker-compose'> </a></p>
<!-- /generated -->
<h3>docker-compose</h3>
<p>All images are <strong>build</strong> via <code>docker-compose</code> because the <code>docker-compose.yml</code> file(s) provide a nice
abstraction layer for the build configuration. In addition, we can also use it to <strong>orchestrate</strong> the
containers, i.e. control volumes, port mappings, networking, etc. - as well as start and stop them
via <code>docker-compose up</code> and <code>docker-compose down</code>.</p>
<p>FYI: Even though it is <em>convenient</em> to use <code>docker-compose</code> for both things, I found it also to make
the setup more complex than it needs to be when running things later in production (when we are
<em>not</em> using <code>docker-compose</code> any longer). I believe the problem here is that some modifications are
ONLY required for building while others are ONLY required for running - and combining both in the
same file yields a certain amount of noise. But: It is what it is.</p>
<p>We use three separate <code>docker-compose.yml</code> files:</p>
<ul>
<li>docker-compose.yml
<ul>
<li>contains all information valid for all environments</li>
</ul></li>
<li>docker-compose.local.yml
<ul>
<li>contains information specific to the <code>local</code> environment,
see <a href="#environments-and-build-targets">Environments and build targets</a></li>
</ul></li>
<li>docker-compose-php-base.yml
<ul>
<li>contains information for building the php base image, see <a href="#php-images">PHP images</a></li>
</ul></li>
</ul>
<!-- generated -->
<p><a id='docker-env-file-and-required-env-variables'> </a></p>
<!-- /generated -->
<h4><code>.docker/.env</code> file and required ENV variables</h4>
<p>In our docker setup we basically have 3 different types of variables:</p>
<ol>
<li>variables that <strong>depend on the local setup</strong> of an individual developer, e.g. the
<code>NGINX_HOST_HTTP_PORT</code> on the host machine (because the default one might already be in use)</li>
<li>variables that <strong>are used in multiple images</strong>, e.g. the location of the codebase within a
container's file system</li>
<li>variables that <strong>hold information that is &quot;likely to change&quot;</strong>, e.g. the exact version of a base
image</li>
</ol>
<p>Since - again - we strive to retain a single source of truth, we extract the information as
variables and put them in a <code>.docker/.env</code> file. In a perfect world, I would like to separate these
different types in different files - but <code>docker-compose</code> only allows a single <code>.env</code> file, see
e.g. <a href="https://github.com/docker/compose/issues/6170#issuecomment-443523663">this comment</a>.
If the file does not exist, it is copied from <code>.docker/.env.example</code>.</p>
<p>The variables are then used in the <code>docker-compose.yml</code> file(s). I found it to be &quot;the least
painful&quot; to always use
the <a href="https://docs.docker.com/compose/environment-variables/#substitute-environment-variables-in-compose-files"><code>?</code> modifier on variables</a>
so that <code>docker-compose</code> <strong>fails immediately if the variable is missing</strong>.</p>
<p>Note: Some variables are expected to be passed via environment variables when <code>docker-compose</code>
is invoked (i.e. they are required but not defined in the <code>.env</code> file; see also
<a href="#shared-variables-make-env">Shared variables: <code>.make/.env</code></a></p>
<!-- generated -->
<p><a id='images'> </a></p>
<!-- /generated -->
<h3>Images</h3>
<p>For <strong>MySQL</strong> and <strong>redis</strong> we do not use custom-built images but instead <strong>use the official ones
<em>directly</em></strong> and configure them through environment variables when starting the containers. In
production, we won't use docker anyway for these services but instead rely on the managed versions,
e.g.</p>
<ul>
<li>redis =&gt; <a href="https://cloud.google.com/memorystore/docs/redis">Memorystore for Redis (GCP)</a> or
<a href="https://aws.amazon.com/de/elasticache/redis/">ElastiCache fr Redis (AWS)</a></li>
<li>mysql =&gt; <a href="https://cloud.google.com/sql/docs/mysql">Cloud SQL for MySQL (GCP)</a> or
<a href="https://aws.amazon.com/de/rds/mysql/">RDS for MySQL (AWS)</a></li>
</ul>
<p>The remaining containers are defined in their respective subdirectories in the <code>.docker/images/</code>
directory, e.g. the image for the <code>nginx</code> container is build via the <code>Dockerfile</code> located in
<code>.docker/images/nginx/Dockerfile</code>.</p>
<!-- generated -->
<p><a id='php-images'> </a></p>
<!-- /generated -->
<h4>PHP images</h4>
<p>We need 3 different PHP images (fpm, workers, application) and use a slightly different approach
than
in <a href="/blog/structuring-the-docker-setup-for-php-projects/">Structuring the Docker setup for PHP Projects</a>:</p>
<p>Instead of using the <a href="https://hub.docker.com/_/php">official PHP base images</a> (i.e. cli or fpm), we
use a &quot;plain&quot; alpine base image and install PHP and the required extensions manually in it. This
allows us to build a common base image for all PHP images. Benefits:</p>
<ul>
<li>a central place for shared tools and configuration (no more need for a <code>.shared/</code> directory)</li>
<li>reduced image size when pushing the individual images (the base image is recognized as a layer and
thus &quot;already exists&quot;)</li>
<li>installing extensions via <code>apk add</code> is <strong>a lot</strong> faster than via <code>docker-php-ext-install</code></li>
</ul>
<p>This new approach has two major downsides:</p>
<ul>
<li>we depend on the alpine release cycle of PHP (and PHP extensions)</li>
<li>the image build process is more complex, because we must build the base image first before we can
build the final images</li>
</ul>
<p>Fortunately, both issues can be solved rather easily:</p>
<ul>
<li><a href="https://github.com/codecasts/php-alpine">codecasts/php-alpine</a> maintains an <code>apk</code> repository with
the latest PHP versions for alpine</li>
<li>we use a dedicated <code>make</code> target to build the images instead of invoking <code>docker-compose</code>
directly - this enables us to define a &quot;build order&quot; (base first, rest after) while still having
to run only a single command as a developer
(see <a href="#ensuring-the-build-order">Ensuring the build order</a>)</li>
</ul>
<!-- generated -->
<p><a id='env-vs-arg'> </a></p>
<!-- /generated -->
<h5>ENV vs ARG</h5>
<p>I've noticed that some build arguments are required in multiple PHP containers, e.g. the name of the
application user defined in the <code>APP_USER_NAME</code> ENV variable. The username is needed</p>
<ul>
<li>in the base image to create the user</li>
<li>in the fpm image to define the user that runs the fpm processes (see <code>php-fpm.d/www.conf</code>)</li>
<li>in the worker image to define the user that runs the worker processes (
see <code>supervisor/supervisord.conf</code>)</li>
</ul>
<p>Instead of passing the name to all images via build argument, i.e.</p>
<ul>
<li>define it explicitly under <code>services.*.build.args</code> in the <code>docker-compose.yml</code> file</li>
<li>&quot;retrieve&quot; it in the Dockerfile via <code>ARG APP_USER_NAME</code></li>
</ul>
<p>I've opted to make the username available as an <code>ENV</code> variable in the base image via</p>
<pre><code>ARG APP_USER_NAME
ENV APP_USER_NAME=${APP_USER_NAME}</code></pre>
<p>and thus be able to access it in the child images directly, I can now write</p>
<pre><code>RUN echo ${APP_USER_NAME}</code></pre>
<p>instead of</p>
<pre><code>ARG APP_USER_NAME
RUN echo ${APP_USER_NAME}</code></pre>
<p>I'm not 100% certain that I like this approach as I'm more or less &quot;abusing&quot; ENV variables in ways
that they are likely not intended (&quot;Why would the username need to be stored as an ENV variable?&quot;) -
but I also don't see any other practical downside yet.</p>
<!-- generated -->
<p><a id='image-naming-convention'> </a></p>
<!-- /generated -->
<h4>Image naming convention</h4>
<p>Defining a <a href="https://windsock.io/referencing-docker-images/">fully qualified name for images</a> will
make it much easier to reference the images later, e.g. when pushing them to the registry.</p>
<p>The naming convention for the images is
<code>$(DOCKER_REGISTRY)/$(DOCKER_NAMESPACE)/$(DOCKER_SERVICE_NAME)-$(ENV)</code>, e.g.</p>
<pre><code>                   docker.io/dofroscra/nginx-local
$(DOCKER_REGISTRY)---^          ^        ^     ^        docker.io
$(DOCKER_NAMESPACE)-------------^        ^     ^        dofroscra
$(DOCKER_SERVICE_NAME)-------------------^     ^        nginx
$(ENV)-----------------------------------------^        local</code></pre>
<p>and it is used as value for <code>services.*.image</code>, e.g. for <code>nginx</code></p>
<pre><code class="language-yaml">services:
  nginx:
    image: ${DOCKER_REGISTRY?}/${DOCKER_NAMESPACE?}/nginx-${ENV?}:${TAG?}</code></pre>
<p>In case you are wondering: <code>dofroscra</code> stems from <strong>Do</strong>cker <strong>Fro</strong>m <strong>Scra</strong>tch</p>
<!-- generated -->
<p><a id='environments-and-build-targets'> </a></p>
<!-- /generated -->
<h4>Environments and build targets</h4>
<p>Our final goal is a setup that we can use for</p>
<ul>
<li>local development</li>
<li>in a CI/CD pipeline</li>
<li>in production</li>
</ul>
<p>and even though we strive to for
a <a href="https://12factor.net/dev-prod-parity">parity between those different environments</a>, there will be
differences due to fundamentally different requirements. E.g.</p>
<ul>
<li>on <em>production</em> I want a container <strong>including the sourcecode without any test dependencies</strong></li>
<li>on <em>CI</em> I want a container <strong>including the sourcecode WITH test dependencies</strong></li>
<li>on <em>local</em> I want a container <strong>that mounts the sourcecode from my host (including
dependencies)</strong></li>
</ul>
<p>This is reflected through the <code>ENV</code> environment variable. We use it in two places:</p>
<ol>
<li>as part of the image name as a suffix of the service name
(see <a href="#image-naming-convention">Image naming convention</a>)</li>
<li>to specify
the <a href="https://docs.docker.com/engine/reference/commandline/build/#specifying-target-build-stage---target">target build stage</a></li>
</ol>
<p>See the <code>docker-compose-php-base.yml</code> file for example:</p>
<pre><code>services:
  php-base:
    image: ${DOCKER_REGISTRY?}/${DOCKER_NAMESPACE?}/php-base-${ENV?}:${TAG?}
    build:
      dockerfile: images/php/base/Dockerfile
      target: ${ENV?}</code></pre>
<p>Using <strong>multiple targets in the same Dockerfile</strong> enables us to keep a <strong>common base</strong> but also
include <strong>environment specific instructions</strong>. See the Dockerfile of the <code>php-base</code> image for
example</p>
<pre><code class="language-Dockerfile">ARG ALPINE_VERSION
FROM composer:${COMPOSER_VERSION} as composer
FROM alpine:${ALPINE_VERSION} as base

RUN apk add --update --no-cache \
        bash

WORKDIR $APP_CODE_PATH

FROM base as local

RUN apk add --no-cache --update \
        mysql-client \</code></pre>
<ul>
<li>it first defines a <code>base</code> stage that includes software required in all environments</li>
<li>and then defines a <code>local</code> stage that adds additionally a <code>mysql-client</code> that helps us to debug
connectivity issues</li>
</ul>
<p>After the build for <code>local</code> is finished, we end up with an image called <code>php-base-local</code> that used
the <code>local</code> build stage as target build stage.</p>
<!-- generated -->
<p><a id='makefile'> </a></p>
<!-- /generated -->
<h2>Makefile</h2>
<p>In the following section I will introduce a couple of commands, e.g. for building and running
containers. And to be honest, I find it kinda challenging to keep them in mind without having to
look up the exact options and arguments. I would usually create a helper function or an alias in my
local .bashrc file in a situation like that - but that wouldn't be available to other members of
the team then and it would be very specific to this one project.</p>
<p>Instead we'll use a self-documenting Makefile that
<a href="/blog/structuring-the-docker-setup-for-php-projects/#using-make-as-central-entry-point">acts as the central entrypoint in the application</a>.
Since Makefiles tend to grow over time, I've adopted some strategies to keep them
&quot;sane&quot; via includes, shared variables and better error handling.</p>
<!-- generated -->
<p><a id='make-mk-includes'> </a></p>
<!-- /generated -->
<h3><code>.make/*.mk</code> includes</h3>
<p>Over time the <code>make</code> setup will grow substantially, thus we split it into multiple <code>.mk</code> files in
the <code>.make/</code> directory. The individual files are prefixed with a number to ensure their order when
we include them in the main <code>Makefile</code> via</p>
<pre><code>include .make/*.mk</code></pre>
<pre><code>.
 .make/
     01-00-application-setup.mk
     01-01-application-commands.mk
     02-00-docker.mk</code></pre>
<!-- generated -->
<p><a id='shared-variables-make-env'> </a></p>
<!-- /generated -->
<h3>Shared variables: <code>.make/.env</code></h3>
<p>We try to make <strong>shared variables</strong> available here, because we can then pass them on to individual
commands as a prefix, e.g.</p>
<pre><code class="language-makefile">.PHONY: some-target
some-target: ## Run some target
    ENV_FOO=BAR some_command --baz</code></pre>
<p>This will make the <code>ENV_FOO</code> available as environment variable to <code>some_command</code>.</p>
<p>Shared variables are used by different components, and we always try to maintain only a <strong>single
source of truth</strong>. An example would be the <code>DOCKER_REGISTRY</code> variable that we need to define the
<a href="#image-naming-convention">image names of our docker images</a> in the <code>docker-compose.yml</code> files but
also when pushing/pulling/deploying images via make targets later. In this case, the variable is
required by <code>make</code> as well as <code>docker-compose</code>.</p>
<p>To have a clear separation between variables and &quot;code&quot;, we use a <code>.env</code> file located
at <code>. make/.env</code>. It can be initialized via</p>
<pre><code>make make-init</code></pre>
<p>by copying the <code>.make/.env.example</code> to <code>.make/.env</code>.</p>
<pre><code>.
 .make/
     .make/.env.example
     .make/.env</code></pre>
<p>The file is included in the main <code>Makefile</code> via</p>
<pre><code>-include .make/.env</code></pre>
<p>The <code>-</code> prefix ensures that make doesn't fail if the file does not exist (yet), see
<a href="https://www.gnu.org/software/make/manual/html_node/Include.html">GNU make: Including Other Makefiles</a></p>
<!-- generated -->
<p><a id='enforce-required-parameters'> </a></p>
<!-- /generated -->
<h3>Enforce required parameters</h3>
<p>We kinda &quot;abuse&quot; make for executing arbitrary commands (instead of building artifacts) and some of
those commands require parameters that can be
<a href="https://stackoverflow.com/a/2826178/413531">passed as command arguments</a> in the form</p>
<pre><code>make some-target FOO=bar</code></pre>
<p>There is no way to &quot;define&quot; those parameters as we would in a method signature - but we can still
ensure to fail as early as possible if a parameter is missing via</p>
<pre><code class="language-makefile">@$(if $(FOO),,$(error FOO is empty or undefined))</code></pre>
<p>See
also <a href="https://stackoverflow.com/a/10858332/413531">SO: How to abort makefile if variable not set?</a></p>
<p>We use this technique for example to ensure that all required variables are defined when we execute
docker targets via the <code>validate-docker-variables</code> precondition target:</p>
<pre><code class="language-makefile">.PHONY: validate-docker-variables
validate-docker-variables: 
    @$(if $(TAG),,$(error TAG is undefined))
    @$(if $(ENV),,$(error ENV is undefined))
    @$(if $(DOCKER_REGISTRY),,$(error DOCKER_REGISTRY is undefined - Did you run make-init?))
    @$(if $(DOCKER_NAMESPACE),,$(error DOCKER_NAMESPACE is undefined - Did you run make-init?))
    @$(if $(APP_USER_NAME),,$(error APP_USER_NAME is undefined - Did you run make-init?))
    @$(if $(APP_GROUP_NAME),,$(error APP_GROUP_NAME is undefined - Did you run make-init?))

.PHONY:docker-build-image
docker-build-image: validate-docker-variables
    $(DOCKER_COMPOSE) build $(DOCKER_SERVICE_NAME)</code></pre>
<!-- generated -->
<p><a id='make-docker-3'> </a></p>
<!-- /generated -->
<h2>Make + Docker = &lt;3</h2>
<p>We already introduced quite some complexity into our setup:</p>
<ul>
<li>&quot;global&quot; variables (shared between <code>make</code> and <code>docker</code>)</li>
<li>multiple <code>docker-compose.yml</code> files</li>
<li>build dependencies</li>
</ul>
<p>Bringing it all together &quot;manually&quot; is quite an effort and prone to errors. But we can nicely tuck
the complexity away in <code>.make/02-00-docker.mk</code> by defining the two variables
<code>DOCKER_COMPOSE</code> and <code>DOCKER_COMPOSE_PHP_BASE</code></p>
<pre><code class="language-makefile">DOCKER_DIR:=./.docker
DOCKER_ENV_FILE:=$(DOCKER_DIR)/.env
DOCKER_COMPOSE_DIR:=$(DOCKER_DIR)/docker-compose
DOCKER_COMPOSE_FILE:=$(DOCKER_COMPOSE_DIR)/docker-compose.yml
DOCKER_COMPOSE_FILE_LOCAL:=$(DOCKER_COMPOSE_DIR)/docker-compose.local.yml
DOCKER_COMPOSE_FILE_PHP_BASE:=$(DOCKER_COMPOSE_DIR)/docker-compose-php-base.yml
DOCKER_COMPOSE_PROJECT_NAME:=dofroscra_$(ENV)

DOCKER_COMPOSE_COMMAND:=ENV=$(ENV) \
 TAG=$(TAG) \
 DOCKER_REGISTRY=$(DOCKER_REGISTRY) \
 DOCKER_NAMESPACE=$(DOCKER_NAMESPACE) \
 APP_USER_NAME=$(APP_USER_NAME) \
 APP_GROUP_NAME=$(APP_GROUP_NAME) \
 docker-compose -p $(DOCKER_COMPOSE_PROJECT_NAME) --env-file $(DOCKER_ENV_FILE)

DOCKER_COMPOSE:=$(DOCKER_COMPOSE_COMMAND) -f $(DOCKER_COMPOSE_FILE) -f $(DOCKER_COMPOSE_FILE_LOCAL)
DOCKER_COMPOSE_PHP_BASE:=$(DOCKER_COMPOSE_COMMAND) -f $(DOCKER_COMPOSE_FILE_PHP_BASE)</code></pre>
<ul>
<li><code>DOCKER_COMPOSE</code> uses <code>docker-compose.yml</code> and extends it with <code>docker-compose.local.yml</code></li>
<li><code>DOCKER_COMPOSE_PHP_BASE</code> uses only <code>docker-compose-php-base.yml</code></li>
</ul>
<p>The variables can then be used later in make recipes.</p>
<!-- generated -->
<p><a id='ensuring-the-build-order'> </a></p>
<!-- /generated -->
<h3>Ensuring the build order</h3>
<p>As mentioned under <a href="#php-images">PHP images</a>, we need to build images in a certain order and use
the following make targets:</p>
<pre><code class="language-makefile">.PHONY: docker-build-image
docker-build-image: ## Build all docker images OR a specific image by providing the service name via: make docker-build DOCKER_SERVICE_NAME=&lt;service&gt;
    $(DOCKER_COMPOSE) build $(DOCKER_SERVICE_NAME)

.PHONY: docker-build-php
docker-build-php: ## Build the php base image
    $(DOCKER_COMPOSE_PHP_BASE) build $(DOCKER_SERVICE_NAME_PHP_BASE)

.PHONY: docker-build
docker-build: docker-build-php docker-build-image ## Build the php image and then all other docker images</code></pre>
<p>As a developer, I can now simply run <code>make docker-build</code> - which will first build the <code>php-base</code>
image via <code>docker-build-php</code> and then build all the remaining images via <code>docker-build-image</code>
(by not specifying the <code>DOCKER_SERVICE_NAME</code> variable, <code>docker-compose</code> will build <strong>all</strong> services
listed in the <code>docker-compose.yml</code> files).</p>
<p>I would argue that the make recipes themselves are quite readable and easy to understand but when
we run
them with the <a href="https://www.gnu.org/software/make/manual/html_node/Options-Summary.html"><code>-n</code> option</a>
to only &quot;Print the recipe that would be executed, but not execute it&quot;, we get a feeling for the
complexity:</p>
<pre><code>$ make docker-build -n
ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose-php-base.yml build php-base
ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml build</code></pre>
<!-- generated -->
<p><a id='run-commands-in-the-docker-containers'> </a></p>
<!-- /generated -->
<h3>Run commands in the docker containers</h3>
<p>Tooling is an important part in the development workflow. This includes things like linters, static
analyzers and testing tools but also &quot;custom&quot; tools geared towards your specific workflow. Those
tools usually <strong>require a PHP runtime</strong>. For now, we only have a single &quot;tool&quot; defined in the
file <code>setup.php</code>. It ensures that a table called <code>jobs</code> is created.</p>
<p>To run this tool, we must first start the docker setup via <code>make docker-up</code> and then execute the
script in the <code>application</code> container. The corresponding target is defined in
<code>.make/01-00-application-setup.mk</code>:</p>
<pre><code class="language-makefile">.PHONY: setup-db
setup-db: ## Setup the DB tables
    $(EXECUTE_IN_APPLICATION_CONTAINER) php setup.php $(ARGS);</code></pre>
<p>which essentially translates to</p>
<pre><code>docker-compose exec -T --user application application php setup.php</code></pre>
<p>if we are outside of a container and to</p>
<pre><code>php setup.php</code></pre>
<p>if we are inside a container. That's quite handy, because we can <strong>run the tooling directly from the
host system</strong> without having to log into a container.</p>
<p>The &quot;magic&quot; happens in the <code>EXECUTE_IN_APPLICATION_CONTAINER</code> variable that is defined in
<code>.make/02-00-docker.mk</code> as</p>
<pre><code class="language-makefile">EXECUTE_IN_WORKER_CONTAINER?=
EXECUTE_IN_APPLICATION_CONTAINER?=

EXECUTE_IN_CONTAINER?=
ifndef EXECUTE_IN_CONTAINER
    # check if 'make' is executed in a docker container, 
    # see https://stackoverflow.com/a/25518538/413531
    # `wildcard $file` checks if $file exists, 
    # see https://www.gnu.org/software/make/manual/html_node/Wildcard-Function.html
    # i.e. if the result is "empty" then $file does NOT exist 
    # =&gt; we are NOT in a container
    ifeq ("$(wildcard /.dockerenv)","")
        EXECUTE_IN_CONTAINER=true
    endif
endif
ifeq ($(EXECUTE_IN_CONTAINER),true)
    EXECUTE_IN_APPLICATION_CONTAINER:=$(DOCKER_COMPOSE) exec -T --user $(APP_USER_NAME) $(DOCKER_SERVICE_NAME_APPLICATION)
    EXECUTE_IN_WORKER_CONTAINER:=$(DOCKER_COMPOSE) exec -T --user $(APP_USER_NAME) $(DOCKER_SERVICE_NAME_PHP_WORKER)
endif</code></pre>
<p>We can take a look via <code>-n</code> again to see the resolved recipe on the host system</p>
<pre><code>pascal.landau:/c/_codebase/dofroscra# make setup-db ARGS=--drop -n
ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application application php setup.php --drop</code></pre>
<p>Within a container it looks like this:</p>
<pre><code>root:/var/www/app# make setup-db ARGS=--drop -n
php setup.php --drop;</code></pre>
<!-- generated -->
<p><a id='php-poc'> </a></p>
<!-- /generated -->
<h2>PHP POC</h2>
<p>To ensure that everything works as expected, the repository contains a minimal PHP proof of concept.
By default, port 80 from the host ist forwarded to port 80 of the <code>nginx</code> container.</p>
<p>FYI: I would also recommend to add the following entry
<a href="https://www.howtogeek.com/howto/27350/beginner-geek-how-to-edit-your-hosts-file/">in the hosts file on the host machine</a></p>
<pre><code>127.0.0.1 app.local</code></pre>
<p>so that we can access the application via <a href="http://app.local">http://app.local</a> instead
of <a href="http://127.0.0.1">http://127.0.0.1</a>.</p>
<p>The files of the POC essentially ensure that the container connections outlined in
<a href="#local-docker-setup">Local docker setup</a> work as expected:</p>
<p><a href="/img/docker-from-scratch-for-php-applications-in-2022/docker-containers.PNG"><img src="/img/docker-from-scratch-for-php-applications-in-2022/docker-containers.PNG" alt="Docker container connections" title="Docker container connections" /></a></p>
<ul>
<li><code>dependencies.php</code>
<ul>
<li>returns configured <code>Redis</code> and <code>PDO</code> objects to talk to the queue and the database</li>
</ul></li>
<li><code>setup.php</code>
<ul>
<li>=&gt; <em>ensures that <code>application</code> can talk to <code>mysql</code></em></li>
</ul></li>
<li><code>public/index.php</code>
<ul>
<li>is the web root file that can be accessed via <a href="http://app.local">http://app.local</a>
<ul>
<li>=&gt; <em>ensures that <code>nginx</code> and <code>php-fpm</code> are working</em></li>
</ul></li>
<li>contains 3 different &quot;routes&quot;:
<ul>
<li><a href="http://app.local?dispatch=some-job-id">http://app.local?dispatch=some-job-id</a>
<ul>
<li>dispatches a new &quot;job&quot; with the id <code>some-job-id</code> on the queue to be picked up by a
worker
<ul>
<li>=&gt; <em>ensures that <code>php-fpm</code> can talk to <code>redis</code></em></li>
</ul></li>
</ul></li>
<li><a href="http://app.local?queue">http://app.local?queue</a>
<ul>
<li>shows the content of the queue</li>
</ul></li>
<li><a href="http://app.local?db">http://app.local?db</a>
<ul>
<li>shows the content of the database
<ul>
<li>=&gt; <em>ensures that <code>php-fpm</code> can talk to <code>mysql</code></em></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><code>worker.php</code>
<ul>
<li>is started as daemon process in the <code>php-worker</code> container</li>
<li>checks the redis datasbase <code>0</code> for the key <code>"queue"</code> every second</li>
<li>if a value is found it is stored in the <code>jobs</code> table of the database
<ul>
<li>=&gt; <em>ensures that <code>php-worker</code> can talk to <code>redis</code> and <code>mysql</code></em></li>
</ul></li>
</ul></li>
</ul>
<p>A full test scenario is defined in <code>test.sh</code> and looks like this:</p>
<pre><code>$ bash test.sh

  Building the docker setup

//...

  Starting the docker setup

//...

  Clearing DB

ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application application php setup.php --drop;
Dropping table 'jobs'
Done
Creating table 'jobs'
Done

  Stopping workers

ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application php-worker supervisorctl stop worker:*;
worker:worker_00: stopped
worker:worker_01: stopped
worker:worker_02: stopped
worker:worker_03: stopped

  Ensuring that queue and db are empty

Items in queue
array(0) {
}
Items in db
array(0) {
}

  Dispatching a job 'foo'

Adding item 'foo' to queue

  Asserting the job 'foo' is on the queue

Items in queue
array(1) {
  [0]=&gt;
  string(3) "foo"
}

  Starting the workers

ENV=local TAG=latest DOCKER_REGISTRY=docker.io DOCKER_NAMESPACE=dofroscra APP_USER_NAME=application APP_GROUP_NAME=application docker-compose -p dofroscra_local --env-file ./.docker/.env -f ./.docker/docker-compose/docker-compose.yml -f ./.docker/docker-compose/docker-compose.local.yml exec -T --user application php-worker supervisorctl start worker:*;
worker:worker_00: started
worker:worker_01: started
worker:worker_02: started
worker:worker_03: started

  Asserting the queue is now empty

Items in queue
array(0) {
}

  Asserting the db now contains the job 'foo'

Items in db
array(1) {
  [0]=&gt;
  string(3) "foo"
}
</code></pre>
<!-- generated -->
<p><a id='wrapping-up'> </a></p>
<!-- /generated -->
<h2>Wrapping up</h2>
<p>Congratulations, you made it! If some things are not completely clear by now, don't hesitate to
leave a comment. Apart from that, you should now have a running docker setup and the means to
&quot;control&quot; it conveniently via <code>make</code>.</p>
<p>In the next part of this tutorial, we will
<a href="/blog/phpstorm-docker-xdebug-3-php-8-1-in-2022/">configure PhpStorm as our IDE to use the docker setup</a>.</p>
<p>Please subscribe to the <a href="/feed.xml">RSS feed</a> or <a href="#newsletter">via email</a> to get automatic
notifications when this next part comes out :)</p>]]></description>
                <pubDate>Mon, 21 Mar 2022 10:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/blog/docker-from-scratch-for-php-applications-in-2022/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/blog/docker-from-scratch-for-php-applications-in-2022/</guid>
            </item>
                    <item>
                <title>BigQuery: Monitor Query Costs via INFORMATION_SCHEMA</title>
                <description><![CDATA[<p>Cost monitoring in Google BigQuery can be a difficult task, especially within a growing organization and
lots of (independent) stakeholders that have access to the data. If your organization is not using
reserved slots (<a href="https://cloud.google.com/bigquery/pricing#flat_rate_pricing">flat-rate pricing</a>)
but is billed by the number of bytes processed
(<a href="https://cloud.google.com/bigquery/pricing#on_demand_pricing">on-demand pricing</a>),
costs can get quickly out of hand, and we need the means to investigate or &quot;debug&quot; the BigQuery
usage in order to understand:</p>
<ul>
<li><strong>who</strong> ran queries with a high cost</li>
<li><strong>what</strong> were the exact queries</li>
<li><strong>when</strong> did those queries run (and are they maybe even running regularly) </li>
</ul>
<p>Previously, we had to manually set up query logging via Stackdriver as explained in the article
<a href="https://cloud.google.com/blog/products/data-analytics/taking-a-practical-approach-to-bigquery-cost-monitoring">Taking a practical approach to BigQuery cost monitoring</a>
but in late 2019 BigQuery introduced
<a href="https://cloud.google.com/bigquery/docs/information-schema-intro"><code>INFORMATION_SCHEMA</code> views</a>
as a beta feature that also contain data about BigQuery jobs via the
<a href="https://cloud.google.com/bigquery/docs/information-schema-jobs"><code>INFORMATION_SCHEMA.JOBS_BY_*</code> views</a>
and became <a href="https://cloud.google.com/bigquery/docs/release-notes#June_16_2020">generally available (GA) at 2020-06-16</a></p>
<h2>Examples</h2>
<pre><code>SELECT 
  creation_time,
  job_id,
  project_id,
  user_email,
  total_bytes_processed,
  query
FROM
  `region-us`.INFORMATION_SCHEMA.JOBS_BY_USER

SELECT * FROM `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT

SELECT * FROM `region-us`.INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION</code></pre>
<h2>Working Example</h2>
<script src="https://gist.github.com/paslandau/980f251cbbb2f0dddff9da6425007e3f.js"><script src="https://gist.github.com/paslandau/980f251cbbb2f0dddff9da6425007e3f.js"></script></script>
<ul>
<li>this query will select the most interesting fields in terms of cost monitoring from the <code>INFORMATION_SCHEMA.JOBS_BY_USER</code>
view for all jobs that have been run in region US in the currently selected project</li>
<li>the <code>cost_in_dollar</code> is estimate by calculating the <code>total_bytes_processed</code> in Terabyte and
multiplying the result with $5.00 (which corresponds to the cost as of today 2020-06-22).
Also, we only take those costs into account if the query was not answered from the cache
(see the <code>cache_hit != true</code> condition)</li>
<li>the <code>creation_time</code> is converted to our local timezone</li>
<li>the results are restricted to the past 30 days by using the <code>WHERE</code> clause to filter
on the partition column <code>creation_time</code></li>
<li>feel free to replace <code>JOBS_BY_PROJECT</code> with <code>JOBS_BY_USER</code> or <code>JOBS_BY_ORGANIZATION</code></li>
</ul>
<h2>Run on BigQuery</h2>
<p><a href="https://console.cloud.google.com/bigquery?sq=580364496687:b0c09fa64661413eb91f5e7e0fcedebd">Open in BigQuery UI</a></p>
<p><a href="/img/bigquery-snippets/monitor-query-costs/monitor-query-costs-bigquery-example.png"><img src="/img/bigquery-snippets/monitor-query-costs/monitor-query-costs-bigquery-example.png" alt="BigQuery UI: Monitor query costs in BigQuery example" title="BigQuery UI: Monitor query costs in BigQuery example" /></a></p>
<h2>Notes</h2>
<p>While playing around with the <code>INFORMATION_SCHEMA</code> views I've hit a couple of gotchas:</p>
<ul>
<li>the different views <a href="https://cloud.google.com/bigquery/docs/information-schema-jobs?hl=en#required_permissions">require different permissions</a></li>
<li>the views are regionalized, i.e. we <strong>must</strong> prefix the region (see <code>region-us</code> in the view specification) and
must run the job <em>in that region</em> (e.g. from the BigQuery UI via
<a href="https://cloud.google.com/bigquery/docs/running-queries#queries"><code>More &gt; Query Settings &gt; Processing location</code></a>)</li>
<li>it is not possible to <strong>mix multiple regions</strong> in the query, because a query with processing location <code>US</code>
can only access resources in location <code>US</code>. Though it would be very helpful for organizations that actively use different locations,
something like this is not possible:
<pre><code>SELECT * FROM 
(SELECT * `region-us`.INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION)
UNION ALL
(SELECT * `region-eu`.INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION)</code></pre></li>
<li>data is currently only kept for the past 180 days</li>
<li>the <code>JOBS_BY_USER</code> view seems to &quot;match&quot; the user based on the email address. My user email adress is a <code>@googlemail.com</code>
address; in the user column it is stored as <code>@gmail.com</code>. Thus, I get no results when using <code>JOBS_BY_USER</code></li>
<li><code>JOBS_BY_USER</code> and <code>JOBS_BY_PROJECT</code> will use the currently selected project by default. A different
project (e.g. <code>other-project</code>) can be specified via 
<pre><code>SELECT * FROM `other-project.region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT</code></pre></li>
<li>the full <code>query</code> is not available for <code>JOBS_BY_ORGANIZATION</code></li>
</ul>
<h2>Use Cases</h2>
<p>I use this approach in our organization to set up a view based on <code>INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION</code>
that is then used as a data source for <a href="https://datastudio.google.com/">Google DataStudio</a>.
This allows me to get a quick high level overview
over all query costs and further enables me to drill down deeper if I need to. I can even find the exact
queries via their <code>job_id</code>.</p>
<p><a href="/img/bigquery-snippets/monitor-query-costs/bigquery-cost-dashboard.png"><img src="/img/bigquery-snippets/monitor-query-costs/bigquery-cost-dashboard.png" alt="BigQuery cost monitoring dashboard" title="BigQuery cost monitoring dashboard" /></a></p>]]></description>
                <pubDate>Mon, 22 Jun 2020 10:40:00 +0000</pubDate>
                <link>https://www.pascallandau.com/bigquery-snippets/monitor-query-costs/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/bigquery-snippets/monitor-query-costs/</guid>
            </item>
                    <item>
                <title>BigQuery: Calculate the MEDIAN in BigQuery</title>
                <description><![CDATA[<p>There is no <code>MEDIAN()</code> function in Google BigQuery, but we can still calculate the MEDIAN
with the
<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#percentile_cont"><code>PERCENTILE_CONT(x, 0.5)</code></a> or
<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#percentile_disc"><code>PERCENTILE_DISC(x, 0.5)</code></a>
functions. The difference between those two functions is the linear interpolation that is applied
when using <code>PERCENTILE_CONT(x, 0.5)</code> - so that's probably what you want when dealing with numeric
values. Take the numbers <code>1,2,3,4</code> for example:</p>
<ul>
<li><code>PERCENTILE_CONT(x, 0.5)</code> yields <code>2.5</code> (as the 50% percentile is exactly between 2 and 3)</li>
<li><code>PERCENTILE_DISC(x, 0.5)</code> yields <code>2</code> (as the 50% percentile is &gt;= 2)</li>
</ul>
<h2>Example</h2>
<pre><code>SELECT 
  PERCENTILE_CONT(x, 0.5) OVER() AS median_cont,
  PERCENTILE_DISC(x, 0.5) OVER() AS median_disc
FROM
  UNNEST([1,2,3,4]) as x 
LIMIT 1</code></pre>
<p><strong>Result</strong></p>
<table>
<thead>
<tr>
<th style="text-align: right;">median_cont</th>
<th style="text-align: right;">median_disc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right;">2.5</td>
<td style="text-align: right;">2</td>
</tr>
</tbody>
</table>
<p><strong>Caution</strong>: As of today (2020-06-20), BigQuery only supports <code>PERCENTILE_CONT</code> and <code>PERCENTILE_DISC</code> for window functions
(hence the <code>OVER()</code> clause and the <code>LIMIT 1</code> in the example above):</p>
<blockquote>
<p>PERCENTILE_CONT is under development, and we will publish the documentation once it is GA. We will support it as analytic function first, and we plan to support it as aggregate function (allowing GROUP BY) later.</p>
</blockquote>
<p>Source: <a href="https://stackoverflow.com/a/45579962/413531">SO: percentile functions with GROUPBY in BigQuery</a></p>
<p>The more common use case is probably to calculate the median as a result of a <code>GROUP BY</code> statement.
I.e. I would <em>like</em> to write something like this to get the median of <code>quantity</code> per <code>product_id</code>.</p>
<pre><code>SELECT
  product_id, 
  PERCENTILE_CONT(quantity, 0.5) AS median
GROUP BY
  product_id</code></pre>
<p>Right now, that is only possible for the average via
<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#avg"><code>AVG()</code></a>
but not for the median. But we can still work around that limitation by using the
<code>PERCENTILE_CONT</code> function on a window partitioned by <code>product_id</code>, then group by the <code>product_id</code>
(to get only one row per <code>product_id</code>)
and resolve a single median value via <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#any_value"><code>ANY_VALUE()</code></a>.</p>
<h2>Working Example</h2>
<script src="https://gist.github.com/paslandau/14940ec0fd34dc30b36377886c308ab3.js"><script src="https://gist.github.com/paslandau/14940ec0fd34dc30b36377886c308ab3.js"></script></script>
<h2>Run on BigQuery</h2>
<p><a href="https://console.cloud.google.com/bigquery?sq=580364496687:0c40a54f0d044cbebdc2745860a75490">Open in BigQuery UI</a></p>
<p><a href="/img/bigquery-snippets/calculate-median/calculate-median-bigquery-example.png"><img src="/img/bigquery-snippets/calculate-median/calculate-median-bigquery-example.png" alt="BigQuery UI: MEDIAN in BigQuery example" title="BigQuery UI: MEDIAN in BigQuery example" /></a></p>
<h2>Links</h2>
<ul>
<li><a href="https://stackoverflow.com/a/29095240/413531">Answer to &quot;How to calculate median of a numeric sequence in Google BigQuery efficiently?&quot; on Stackoverflow</a></li>
</ul>
<h2>Notes</h2>
<p>There is also the <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#approx_quantiles"><code>APPROX_QUANTILES()</code></a>
function (mentioned <a href="https://stackoverflow.com/a/39843565/413531">here</a>) that <em>can</em> by applied to a <code>GROUP BY</code>. I didn't have a practical use case for approximate functions
yet, though. Thus, I don't know the implications of &quot;not using an exact calculation&quot; and rather mention
this for the sake of completeness. Example:</p>
<pre><code>SELECT
  product_id, 
  APPROX_QUANTILES(quantity, 100)[OFFSET(50)] as approx_median
GROUP BY
  product_id</code></pre>]]></description>
                <pubDate>Sat, 20 Jun 2020 12:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/bigquery-snippets/calculate-median/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/bigquery-snippets/calculate-median/</guid>
            </item>
                    <item>
                <title>BigQuery: Use expression subqueries for querying nested and repeated fields</title>
                <description><![CDATA[<p>BigQuery allows to define <a href="https://cloud.google.com/bigquery/docs/nested-repeated">nested and repeated fields</a>
in a table. Although this is very powerful, it makes it much more complex to retrieve the
data if one is not used to such structures. Especially beginners tend to use an
<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/arrays#flattening_arrays"><code>UNNEST</code> statement</a>
on the nested fields, followed by a huge
<code>GROUP BY</code> statement on the not-originally-repeated fields. Imho, using
<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/expression_subqueries?hl=en">expression subqueries</a>
is oftentimes the better approach here.</p>
<h2>Code</h2>
<pre><code>SELECT
  id,
  (SELECT value from t.repeated_fields LIMIT 1)
FROM
  table t  </code></pre>
<p><strong>Caution</strong>: When using expression subqueries, you need to make sure that the result is a single value (scalar or array), otherwise you will
get the error message</p>
<blockquote>
<p>Scalar subquery produced more than one element</p>
</blockquote>
<p>In the example code above this is ensured by enforcing one result via <code>LIMIT 1</code>.</p>
<h2>Working Example</h2>
<script src="https://gist.github.com/paslandau/03c73ee5eef2ce217af82a8f7edcb125.js"><script src="https://gist.github.com/paslandau/03c73ee5eef2ce217af82a8f7edcb125.js"></script></script>
<h2>Run on BigQuery</h2>
<p><a href="https://console.cloud.google.com/bigquery?sq=106862046541:a3ca0564513344a2981ac658365112c1">Open in BigQuery Console</a></p>
<p><a href="/img/bigquery-snippets/expression-subqueries-for-nested-repeated-fields/expression-subquery-example.png"><img src="/img/bigquery-snippets/expression-subqueries-for-nested-repeated-fields/expression-subquery-example.png" alt="BigQuery Console: How to use expression subqueries for nested and repeated fields example" title="BigQuery Console: How to use expression subqueries for nested and repeated fields example" /></a></p>
<h2>Links</h2>
<ul>
<li><a href="https://gist.github.com/paslandau/03c73ee5eef2ce217af82a8f7edcb125">Gist on Github</a></li>
<li><a href="https://console.cloud.google.com/bigquery?sq=106862046541:a3ca0564513344a2981ac658365112c1">Example on BigQuery</a></li>
</ul>
<h2>Use cases</h2>
<p>The most prominent use case is probably the <a href="https://support.google.com/analytics/answer/3437719?hl=en">BigQuery export schema of Google Analytics</a>.
To be honest, I also feel that the schema is not very friendly for newcomers with its ~30 RECORD-type (nested) fields and 300+ columns.</p>
<p>In a nutshell, each row represents one <a href="https://support.google.com/analytics/answer/2731565?hl=en">session</a>.
A session consists of multiple hits. Those hits are also available in the nested and repeated <code>hits</code> field. But wait, there is more...
Each hit can have a number of so called <code>customDimensions</code> (meta data that can be attached to each hit). So the resulting table structue looks something
like this:</p>
<pre><code>- field_1
- field_2
- hits
  - field_1 
  - field_2
  - customDimensions
    - index 
    - value </code></pre>
<p>The following example uses the public <a href="https://support.google.com/analytics/answer/7586738?hl=en">Google Analytics sample dataset for BigQuery</a> and shows
a couple of sample expression subqueries</p>
<pre><code>SELECT 
  fullVisitorId,
  visitStartTime,
  TIMESTAMP_SECONDS(visitStartTime) as started_at,
  TIMESTAMP_SECONDS(visitStartTime + CAST( (SELECT time from t.hits ORDER BY hitNumber DESC LIMIT 1) /1000 AS INT64)) as ended_at,
  (SELECT COUNT(*) from t.hits) as hit_count,
  (SELECT page.hostname || page.pagePath from t.hits WHERE isEntrance = TRUE) as landing_page,
  (
    SELECT  
      (SELECT COUNT(*) from h.customDimensions) 
    FROM 
      t.hits h
    WHERE 
      hitNumber = 1
   ) as customDimension_count_of_first_hit, 
FROM 
  `bigquery-public-data.google_analytics_sample.ga_sessions_20170801` t
ORDER BY
  visitStartTime asc</code></pre>]]></description>
                <pubDate>Fri, 29 May 2020 14:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/bigquery-snippets/expression-subqueries-for-nested-repeated-fields/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/bigquery-snippets/expression-subqueries-for-nested-repeated-fields/</guid>
            </item>
                    <item>
                <title>BigQuery: Use &quot;temporary tables&quot; via WITH (named subqueries)</title>
                <description><![CDATA[<p>In Google BigQuery we can define named subqueries via <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax?hl=en#with_clause"><code>WITH</code> clauses</a>.
Those <code>WITH</code> clauses are a very comfortable way to structure complex queries as it allows to reference those queries like actual tables later on.</p>
<p><strong>Note</strong>: BigQuery also supports <em>actcual</em> temporary tables via <code>CREATE TEMPORARY TABLE</code>. See the official documention on
<a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#temporary_tables">temporary tables</a> for further infos.
This is out of scope for this snippet, though.</p>
<h2>Code</h2>
<pre><code>WITH filtered_data as (
  SELECT 
    id
  FROM
    table
  WHERE
    id BETWEEN 5 and 10
)
SELECT
  *
FROM
  filtered_data  </code></pre>
<h2>Working Example</h2>
<script src="https://gist.github.com/paslandau/662a42456dc9dc77b6cbdb1d6acb8c99.js"><script src="https://gist.github.com/paslandau/662a42456dc9dc77b6cbdb1d6acb8c99.js"></script></script>
<h2>Run on BigQuery</h2>
<p><a href="https://console.cloud.google.com/bigquery?sq=106862046541:96765412c1ea44a8b5a85cb697c3c945">Open in BigQuery Console</a></p>
<p><a href="/img/bigquery-snippets/use-temporary-tables-with-named-subquery/use-temporary-tables-via-with-named-subqueries-example.png"><img src="/img/bigquery-snippets/use-temporary-tables-with-named-subquery/use-temporary-tables-via-with-named-subqueries-example.png" alt="BigQuery Console: How to use temporay tables via WITH named subqueries example" title="BigQuery Console: How to use temporay tables via WITH named subqueries example" /></a></p>
<h2>Links</h2>
<ul>
<li><a href="https://gist.github.com/paslandau/662a42456dc9dc77b6cbdb1d6acb8c99">Gist on Github</a></li>
<li><a href="https://console.cloud.google.com/bigquery?sq=106862046541:96765412c1ea44a8b5a85cb697c3c945">Example on BigQuery</a></li>
<li><a href="https://stackoverflow.com/a/38149549/413531">Answer to &quot;How to create temporary table in Google BigQuery&quot; on Stackoverflow</a></li>
</ul>
<h2>Use cases</h2>
<p>Named subqueries are a great way to structure complex queries and give sub-results a meaningful name.
When working with partitioned tables, I always use temporary tables via WITH to make sure I restrict the query to
scan only a limited number of partitions.</p>
<p>Conceptual example:</p>
<pre><code>DECLARE from_date TIMESTAMP DEFAULT "2018-04-09";
DECLARE to_date TIMESTAMP DEFAULT "2018-04-10";

WITH huge_table_partition as(
  SELECT 
    *
  FROM 
    huge_table
  WHERE
    _PARTITIONTIME BETWEEN from_date AND to_date
)

SELECT 
  *
FROM
  huge_table_partition</code></pre>]]></description>
                <pubDate>Fri, 29 May 2020 13:00:00 +0000</pubDate>
                <link>https://www.pascallandau.com/bigquery-snippets/use-temporary-tables-with-named-subquery/?utm_source=blog&amp;utm_medium=rss&amp;utm_campaign=development-feed</link>
                <guid isPermaLink="true">https://www.pascallandau.com/bigquery-snippets/use-temporary-tables-with-named-subquery/</guid>
            </item>
            </channel>
</rss>
